---
authors: [Valerio Galano]
title: "Come funziona ChatGPT (o un Large Language Model in generale)?"
layout: episode
episode_type: full
series: []
categories: [podcast]
tags: [chatgpt,divulgazione,gpt,largelanguagemodel,llm]
seasons: 2
number: 118
date: Fri, 05 May 2023 11:30:01 +0000
audio: "episodes/PIC118.mp3"
audio_duration: 2484
audio_size: 39729109
transcript: transcripts/srt/PIC118.srt
url: /episodes/118
aliases: 
  - /118
image: "covers/PIC118.png"
explicit: "false"
draft: false
type: podcast
---
Fino ad ora ho preferito evitare l'argomento ChatGPT perché sentivo di non avere granché da aggiungere al fiume di parole già spese. Ora però credo di aver riflettuto a sufficienza e spero di aver messo insieme un po' di idee interessanti.<br />
<br />
<a href="https://pensieriincodice.it/" target="_blank" rel="noreferrer noopener">Pensieri in codice</a><br />
<br />
Sostenitori di oggi:<br />
Edoardo Secco, Carlo Tomas<br />
<br />


{{< support >}}

Attrezzatura utilizzata:<br />
<a href="https://amzn.to/3862ZRf" target="_blank" rel="noreferrer noopener">Shure Microfono Podcast USB MV7 </a><br />
<a href="https://amzn.to/3rysTFP" target="_blank" rel="noreferrer noopener">Neewer NW-5 Pannello fonoassorbente</a> <br />
<br />
<br />
<br />
Fonti:<br />
<a href="https://amzn.to/3GRAJmW" target="_blank" rel="noreferrer noopener">https://amzn.to/3GRAJmW</a> - The Mathematical Theory of Communication (Claude Shannon)<br />
<a href="https://arxiv.org/pdf/2212.03551.pdf" target="_blank" rel="noreferrer noopener">https://arxiv.org/pdf/2212.03551.pdf</a> - Talking About Large Language Models<br />
<a href="https://amzn.to/3KPBC0q" target="_blank" rel="noreferrer noopener">https://amzn.to/3KPBC0q</a> - 9 algoritmi che hanno cambiato il futuro (John MacCormick)<br />
<a href="https://www.newyorker.com/science/annals-of-artificial-intelligence/what-kind-of-mind-does-chatgpt-have" target="_blank" rel="noreferrer noopener">https://www.newyorker.com/science/annals-of-artificial-intelligence/what-kind-of-mind-does-chatgpt-have</a> - What Kind of Mind Does ChatGPT Have?<br />
<a href="https://docs.google.com/viewer?a=v&amp;pid=sites&amp;srcid=ZGVmYXVsdGRvbWFpbnxwb2xpbW9kZWxsYXppb25lfGd4Ojc0YWZlNWM2N2QyNWRj" target="_blank" rel="noreferrer noopener">https://docs.google.com/viewer?a=v&amp;pid=sites&amp;srcid=ZGVmYXVsdGRvbWFpbnxwb2xpbW9kZWxsYXppb25lfGd4Ojc0YWZlNWM2N2QyNWRj</a><br />
<a href="https://www.guerredirete.it/chatgpt-cosa-puo-fare-e-non-puo-fare/" target="_blank" rel="noreferrer noopener">https://www.guerredirete.it/chatgpt-cosa-puo-fare-e-non-puo-fare/</a><br />
<a href="https://swizec.com/blog/building-apps-with-openai-and-chatgpt/" target="_blank" rel="noreferrer noopener">https://swizec.com/blog/building-apps-with-openai-and-chatgpt/</a><br />
<a href="https://news.microsoft.com/source/features/ai/openai-azure-supercomputer/" target="_blank" rel="noreferrer noopener">https://news.microsoft.com/source/features/ai/openai-azure-supercomputer/</a><br />
<br />


{{< credits season="season2" >}}

<!-- more -->

## Testo dell'episodio

Sono passati ormai quasi sei mesi da quando si è scatenato l'enorme interesse di massa
per ChatGPT e le sue innumerevoli applicazioni e qui su Pensieri in Codice la vita è trascorsa
serena e tranquilla nonostante tutto il tumulto e l'entusiasmo che imperversava all'esterno.
Ora però che il clamore iniziale è un po' scemato, che il fumo del sensazionalismo ha
iniziato un po' a diradarsi direi che è arrivato anche per noi il momento di unirci alla festa
ovviamente nel nostro stile usando la testa e con elegante ritardo. Benvenuti su Pensieri
in Codice il podcast dove si ragiona da informatici con Valerio Galano. Nel caso tu abbia vissuto su
un eremo o nel mezzo dell'oceano pacifico negli ultimi sei mesi devi sapere che ChatGPT è un
tipo particolare di chatbot basato su quella che ad oggi in tanti ancora si ostinano a chiamare
intelligenza artificiale. Gli utenti di questo software infatti possono scrivere frasi o domande
di ogni genere ed il bot risponde un po' come ci si aspetterebbe da un'entità intelligente ma in
realtà ChatGPT è di fatto un'interfaccia realizzata per chattare con un tipo particolare di applicazione
di machine learning che prende il nome di Large Language Model. Questo specifico LLM, quello che
fa funzionare ChatGPT intendo, è stato battezzato dai suoi creatori GPT e non è certo il primo del
suo genere ad essere stato realizzato fino ad ora. Come vedremo a breve infatti la tecnologia
di cui stiamo parlando non è particolarmente moderna e nemmeno esclusiva di questo bot. Ne
esistono molti e tanto per fare un nome illustre Google ha sviluppato la sua versione che ha
chiamato BARD ma la novità è che fino ad ora un lavoro di questo tipo non era mai stato applicato
su così larga scala e poi messo a disposizione degli utenti in modo così semplice e gratuito.
ChatGPT quindi non è tanto il primo esempio della sua categoria quanto piuttosto il primo ad aver
raggiunto e colpito fortemente così tante persone anche al di fuori della ristretta
cerchia degli addetti ai lavori facendo parlare di sé così in lungo e in largo. Realizzato
dall'americana OpenAI il servizio è stato mostrato al grande pubblico a fine novembre
2022 con una versione beta per poi essere dichiarato stabile verso la fine di marzo
di quest'anno e l'entusiasmo globale è stato enorme in cinque giorni ha raggiunto un milione
di utenti registrati e tanto per intenderci Instagram ci ha messo cinque mesi a conseguire
lo stesso obiettivo. Un LLM come GPT che di fatto è il perno centrale di ChatGPT è dunque un sistema
in grado di accettare gli input più disparati e sulla base di questi rispondere a tono in
linguaggio umano pertanto la possibilità di interagire con esso attraverso un semplice
meccanismo di chat ha giustamente scatenato un entusiasmo notevole. Inoltre GPT è stato reso
disponibile anche tramite API cioè quei meccanismi dedicati agli sviluppatori e utilizzabili in modo
programmatico e ciò ha permesso a tanti di integrarlo all'interno di altri servizi o software.
Quindi fermiamoci un secondo e facciamo un attimo ordine nei termini che in questo episodio ci
serviranno. Dunque GPT è il motore, ChatGPT è l'interfaccia che permette di chattare con il
motore e ancora le API sono altre interfacce che permettono di utilizzare il motore attraverso altri
software. Ok? Come accennavamo poco fa quindi fin da subito ChatGPT ha stupito il mondo con le sue
capacità dialettiche, devo dire onestamente superiori anche a quelle di una certa fetta di
umani, ma ad ogni modo ciò ha fatto sì che le persone iniziassero ad utilizzarlo per gli scopi
più disparati dal semplice svago allo studio del sistema stesso fino ad applicazioni professionali
e di supporto nel proprio lavoro. Data la disponibilità delle API poi la corsa ad
inventarsi un modo per sfruttare le sue grandi capacità è stata ed è tuttora a dir poco
roccambolesca, è stato integrato nei più disparati software e servizi e come spesso accade in questi
casi qualcuno ha quasi subito individuato un utilizzo sensato per lo strumento dando vita
a sinergie proficue o a una serie di esperimenti interessanti mentre al contrario molti altri hanno
frainteso in parte o in toto la possibilità di questo motore e hanno prodotto storture e
abberrazioni senza senso. Gli esempi in entrambe le direzioni sono moltissimi e sono certo che di
giorno in giorno ne vedremo sempre di nuovi. Tanti hanno semplicemente deciso di giocare con
chat gpt di provare i più disparati esperimenti cercando di sondarne i limiti e le possibilità
cercando di forzarlo a funzionare in modi diversi da quelli per i quali è stato programmato potremmo
dire hanno cercato di hackerarlo. Si tratta di comportamenti mossi da una sana curiosità e sono
perfettamente comprensibili. Molti altri poi hanno capito immediatamente il fatto che se
correttamente indirizzato e supervisionato questo può essere di ampio supporto in varie attività in
particolare quelle creative di ricerca e catalogazione delle informazioni. Tra i soli esempi di cui mi è
capitato di leggere ho visto utenti fargli scrivere testi base per descrizioni, storie,
copioni, articoli, algoritmi, itinerari di viaggio senza contare chi utilizzandolo in connubio con
altri strumenti simili in grado di generare ad esempio immagini, musiche o altro, ha dato vita a
tanti prodotti interessanti app, siti web, la redazione di guerre di rete ad esempio ha progettato
un intero gioco da tavolo in un pomeriggio. Certo intendiamoci tutti i risultati da rifinire a volte
da correggere in minore o maggior parte ma in effetti quasi sempre un buon punto da cui partire
per produrre un qualcosa. Tuttavia purtroppo c'è stato anche chi ha pensato di usare questo
strumento in modi che definire discutibili è poco. L'evidente potenza del sistema ha suscitato in
alcuni la spinta a cercare impieghi che generino un tornaconto personale a scapito di fattori come
l'etica tanto per dirne una. Anche questo è nella natura umana lo capisco ma per fortuna non di
tutti gli umani. Ma anche di questi casi si sono visti esempi di ogni tipo, progettazione di campagne
di phishing, scrittura di fake news, produzione di algoritmi con i più disparati bias o pregiudizi,
redazione di strategie di attacco per la diffusione di malware, tutte cose simpatiche insomma. Ma in
tutto questo marasma a mio parere le storture peggiori sono quelle che si sono verificate e se
ne verificheranno sicuramente altre in futuro quando gli utilizzi aberranti sono derivati non
dall'intenzione di creare qualcosa di orribile quanto piuttosto dalla scarsa conoscenza e
consapevolezza di come funzioni effettivamente lo strumento, di cosa possa e non possa fare o di
quanto sia attendibile nel fare quello che gli si chiede di fare. Quello che sto cercando di dire
è che è fisiologico ci sarà sempre qualcuno che utilizza uno strumento perfini magari poco etici
o addirittura poco legali ma con piena intenzione e cognizione di causa. Questo fatto lo dobbiamo
accettare e di conseguenza gestire come società ma i comportamenti forse più pericolosi sono
quelli non previsti, quelli derivati da aspetti non considerati. E così ad esempio una società
che gestisce un servizio di supporto psicologico online ha ben pensato di provare su un gruppo di
utenti cavie a rispondere al primo livello di richieste utilizzando un bot basato su gpt senza
nel fare ciò chiedersi quanto potrebbe essere dannosa una risposta potenzialmente fuori luogo
data ad utenti che per la natura del servizio probabilmente sono già fragili in partenza. Oppure
altro esempio molti che utilizzano chat gpt come motore di ricerca o compagno di discussione per
risolvere i più disparati problemi hanno sistematicamente condiviso informazioni sensibili
personali o professionali o della propria azienda senza dal canto loro chiedersi dove queste vengano
archiviate chi possa avervi accesso. Ora anche gli esempi in tal senso sarebbero tantissimi ma
sinceramente non mi interessa in questo momento fare un elenco di storture a una sorta di bestiario
delle aberrazioni nate da gpt quello che piuttosto vorrei fare è provare a evidenziare quali sono
secondo me le cause di fondo di questo genere di comportamenti e dare il mio piccolo contributo per
contrastarle perché ritengo che sia questo il modo migliore per ridurre i comportamenti più
pericolosi in assoluto cioè quelli involontari. Nel suo celebre testo le leggi fondamentali della
stupidità umana il professor Cipolla come corollario alla quinta legge afferma che lo
stupido è più pericoloso del bandito riassumendo proprio il senso di quanto ho cercato di spiegare
fino ad ora lo stupido è colui che agisce male ma senza rendersene conto mentre il bandito è colui
le cui azioni seppur malvagie sono ben controllate indirizzate. Ad una prima superficiale occhiata
questo corollario potrebbe sembrare già riassumere interamente il nocciolo del problema d'altronde noi
informatici siamo abituati a questo genere di reazione a volte a torto a volte a ragione
l'utonto è proprio questo no? Quell'utente che non è in grado di utilizzare uno strumento
tecnologico non perché esso sia troppo complicato bensì perché è lui ad essere troppo stupido per
capirlo sarebbe facile considerare uno stupido colui che ha pensato di integrare gpt nel proprio
business che magari richiede competenze di tutt'altro genere o di farsi difendere in
tribunale da chat gpt o di chiedergli consigli di trading o altro ma quando la manifestazione di
stupidità è così su larga scala come è accaduto e sta accadendo giorno dopo giorno con chat gpt
e i suoi derivati forse è il caso di chiedersi se si parla ancora di utonti se effettivamente è solo
di stupidità si tratti può essere davvero la causa di tante storture ricondotta solo ed
unicamente alla stupidità dei vari utilizzatori anche se parliamo di persone molto abili nei
rispettivi campi inclini a sperimentare le novità e abituati ad utilizzare la tecnologia non è che
magari il problema sotto sotto risiede altrove probabilmente avrai già sentito nominare la terza
legge di clark che recita qualunque tecnologia sufficientemente avanzata è indistinguibile
dalla magia e se ci pensi è vero si tratta di un concetto molto attuale che una volta chiarito
addovere il significato del termine magia si adatta particolarmente a tantissime situazioni
del nostro tempo tuttavia io sono anche convinto che guardare il mondo con il solo ausilio di una
tale concezione della tecnologia porti a vedere il tutto attraverso un potente filtro una sorta
di limite che spinge a sottovalutare altri aspetti secondo me molto importanti della
questione molti fanno risalire la nascita del concetto di computer alla prima metà del 1800
ad opera del matematico inglese charles babbage che realizzò per primo il progetto di un calcolatore
programmabile quella che lui stesso chiamò la macchina analitica il suo progetto mai realizzato
nella realtà se non come tributo al genio molti anni dopo derivava da un altro strumento meno
evoluto sempre ideato dallo stesso scienziato ma di cui egli era stato in grado di realizzare almeno
un prototipo i costi per la produzione delle migliaia di ingranaggi necessari per le sue
macchine e poi per il loro successivo assemblaggio era proibitivo e babbage organizzava incontri
periodici nella sua residenza londinese per mostrare a nobili ed intellettuali di tutta
l'inghilterra il suo prototipo al fine di cercare di creare interesse e raccogliere fondi a questi
incontri nonostante vi partecipassero le persone più istruite di tutto il regno e parliamo di
un'epoca nella quale solo un bambino su 11 riceveva un'istruzione formale capitava spesso
che qualcuno vedendo in funzione la macchina differenziale intenta ad eseguire i propri
conti la definisse macchina intelligente o addirittura facesse domande del tipo ma se io
inserisco i numeri errati il risultato sarà comunque corretto ecco esistono tantissime
testimonianze del fatto che ogni volta babbage ben lungi dal considerarli stupidi si affrettava a
ridimensionare le impressioni e le aspettative di questi entusiasti intellettuali spiegando loro
che la macchina non era né intelligente né in grado di pensare ma solo di fare determinati
calcoli che venivano per essa programmati anche per via di questa sua onestà intellettuale babbage
non riuscì mai a realizzare i suoi progetti dato che non riuscì mai ad ottenere sufficienti
sovvenzioni pubbliche o private che fossero oggi invece mi sembra proprio che l'atteggiamento la
retorica e il marketing che girano intorno a questi strumenti di machine learning siano
orientati esattamente nel verso opposto che ci vogliono far credere in qualche modo che essi
siano in grado di pensare e risolvere problemi in autonomia lo stesso chat gpt se lo hai provato
l'avrai notato è implementato per dare l'impressione all'utente di stare dialogando con una sorta di
intelligenza di qualche tipo usa perfino tecniche visive tipiche dei film o dei videogiochi normalmente
infatti la risposta ad un prompt data da un software è solitamente immediata viene elaborato il
risultato e poi mostrato nel modo più rapido possibile in chat gpt invece le parole compaiono
una per volta come a dare l'impressione di stare comunicando con un'intelligenza aliena da film
di fantascienza come a farci credere che stia pensando o formulando le frasi secondo me è
proprio questo atteggiamento a generare confusione nel grande pubblico soprattutto nelle persone meno
tecnicamente preparate sull'argomento sono questi ed altri trucchi della stessa risma come ad esempio
continuare a martellare sul termine intelligenza artificiale che fanno apparire questa tecnologia
più come una magia o nel caso specifico come una intelligenza invece di diffondere la conoscenza
si diffonde il mito ma per come la vedo io basta scalfire la superficie del problema dissipare
l'aura di trascendenza per dare a chiunque gli strumenti per capire una tecnologia non serve
diventarne degli esperti ma basta capirne almeno i concetti di base e quindi oggi voglio provare
a fare proprio questo voglio provare a sfatare un pochino del mito e ad intaccarne le fige
partiamo subito con il dire che io non sono né un esperto di machine learning né ho avuto mai
accesso a chissà quali informazioni riservate su chat gpt lo spunto per questo episodio mi è stato
dato da un articolo del new yorker che ti lascio in descrizione insieme con tutte le altre fonti che
ho utilizzato secondo l'autore dell'articolo e anche secondo me il modo migliore per capire i
concetti di base di una tecnologia è provare ad affrontare superare almeno dal punto di vista
teorico i vari ostacoli che essa pone ai suoi progettisti ovviamente noi non saremo in grado
di implementare il nostro bot nella mezz'ora che durerà questo episodio di pensieri in codice ma
individuare e risolvere teoricamente i problemi ci permetterà da una parte di contestualizzare le
caratteristiche del prodotto e dall'altra di comprendere le scelte fatte da coloro che quei
problemi li hanno realmente affrontati dunque come punto di partenza torniamo a ribadire che
un bot come chat gpt si basa essenzialmente sull'utilizzo di un tipo di machine learning
chiamato large language model che in pratica è una rete neurale ad apprendimento automatico allenata
su una quantità enorme di dati di fatto il bot funge da interfaccia per la rete neurale e permette
di ricevere gli input dagli utenti e di restituire agli stessi output per i nostri scopi di oggi ti
anticipo già che non sarà necessario capire in dettaglio come funziona una rete neurale o un'
interfaccia tutto quello che faremo sarà descrivere i vari passaggi necessari al bot per produrre una
risposta a partire da una domanda e sempre per semplicità ci limiteremo a considerare solo le
funzioni inerenti il testo ignorando tutto ciò che riguarda le modalità di funzionamento di
algoritmi per gestire musica immagini eccetera quindi il concetto di base è un testo in input
produce un testo in output coerente con l'input ricevuto come possiamo fare a realizzare una cosa
del genere beh come prima cosa abbiamo detto di avere a disposizione una grande quantità di
dati no proviamo innanzitutto a capire come sfruttare quelli per farlo e tanto per ribadire
che questa tecnologia è tutt'altro che nuova partiamo da un grande classico dell'informatica
il testo intitolato è mathematical theory of communication scritto da Claude Shannon che è
il matematico che per primo ha descritto la teoria della gestione dell'informazione praticamente la
base dell'informatica moderna in questo paper oltre a tantissima matematica ovviamente si può
trovare anche la descrizione di un interessante esperimento di generazione del testo Shannon
scrive nel 1948 e all'epoca non immagina le dimensioni alle quali sarebbe potuta arrivare
una banca dati nel 2023 o cosa sarà internet o ancora di quanta potenza di calcolo avremmo
potuto disporre noi al giorno d'oggi quindi formula tutto il suo ragionamento considerando come base
di informazioni disponibili la sua libreria personale tutto il discorso è ovviamente in
scala rispetto a quelli che sono i numeri di un moderno large language model ma nonostante ciò
tutto funziona perfettamente e come bonus lo si può mettere in pratica anche senza l'ausilio di
un computer basta semplicemente avere qualche libro in casa come prima cosa Shannon sceglie
una parola da cui iniziare la generazione del testo e la scrive su un foglio per semplicità
sceglie una delle parole più comuni della sua lingua l'articolo a questo punto sceglie un
libro a caso dalla libreria e lo apre ad una pagina sempre a caso legge il testo finché non arriva
alla parola e a quel punto scrive sul suo foglio la prima parola che viene subito dopo che nel
suo esempio è head testa il testo sul foglio diventa quindi the head e lui ripete il processo
partendo però questa volta dalla parola head la cerca in una pagina a caso di un libro a caso e
quando la trova ricopia sul suo foglio la parola che appare subito dopo la terza parola e quindi
hand e congiunzione il matematico continua così per un po e alla fine arriva a formulare la frase
the head and in frontal attack on an english writer that the character of this point is
therefore another method e ok la frase in sé non ha tantissimo senso sono d'accordo ma l'algoritmo
messo a punto è un'ottima base da cui possiamo partire noi per realizzare il nostro semplice
llm casalingo per migliorare la ricerca del testo generato possiamo usare un semplice trucco che
pur rendendo un po più complicata la ricerca ha però il vantaggio di aumentare le probabilità
di prelevare parole maggiormente senzate possiamo invece di ricercare una singola parola ad ogni
iterazione cercarne gruppi di due tre o anche più quindi se il testo che vogliamo generare deve
parlare ad esempio della razza di cane pastore tedesco potremmo scrivere sul nostro foglietto
le parole di partenza il pastore tedesco è e poi scorrere le pagine del libro finché non troviamo
esattamente le tre parole pastore tedesco è per poi come prima prelevare la successiva e aggiungere
al nostro testo proviamo dunque ad applicare il nuovo algoritmo e a scopo esemplificativo
facciamo finta che la parola trovata sia una l'articolo indeterminativo femminile la frase
diventerebbe il pastore tedesco è una mentre la prossima chiave di ricerca diventerebbe tedesco
è una perché stiamo cercando sempre tre parole per volta procediamo così prendendo libri e
pagine a caso per 3 4 5 10 100 volte dipende da quanto vogliamo che il nostro testo sia lungo
con quest'altra modifica applicata all'algoritmo l'attenenza delle parole fra loro è dunque
aumentata ma scommetto già che starai iniziando ad intuire che per ottenere dei risultati decenti
serve una quantità di libri quindi una base dati molto grande se avessimo infatti pochi libri
considerando la complessità delle nuove chiavi di ricerca finiremmo per capitare sempre sulle
stesse pagine e quindi automaticamente ci troveremmo a ricopiare più o meno pedissequamente
il testo di un certo libro oppure nella peggiore delle ipotesi potremmo non trovare nessun gruppo
di parole che soddisfi la ricerca e in tal caso dovremmo semplicemente rinunciare ma anche così
con molti libri a disposizione resta comunque un problema di fondo certi gruppi di parole possono
portare a ricercare nell'intero database senza dare risultati quindi per produrre noi un algoritmo
robusto ci serve di inventarci una strategia che ci eviti di andare a comporre delle chiavi di
ricerca troppo insolite o impossibili da trovare per ampliare il ventaglio di possibili risultati
allora cambiamo leggermente il nostro approccio innanzitutto passiamo dal cercare esattamente un
gruppo di parole al cercare quelle stesse parole in ordine sparso all'interno di gruppetti poco
grandi in pratica in questo modo riusciamo ad individuare anche le chiavi di ricerca che
somigliano alla nostra non per forza solo quelle identiche inoltre invece di accodare immediatamente
la parola al nostro testo appena incontriamo un risultato della nostra ricerca annotiamola
da qualche parte poi continuiamo a cercare la stessa chiave in altri libri o pagine e ogni
volta che incontriamo una parola candidata ad entrare a far parte del nostro testo annotiamola
insieme alle altre alla fine ovviamente otterremo non più una sola parola ma una lista di candidate
e per scegliere fra queste quale sia la più adatta possiamo allora predisporre un sistema
di classifica basato su dei voti che daremo ad ogni parola banalmente quella con il voto più
alto verrà selezionata per entrare a far parte del testo che stiamo generando il voto può essere
calcolato in base ai fattori che più riteniamo appropriati come ad esempio il numero di volte
in cui la parola appare nella lista o la quantità di parole che la precedono o la seguono fino al
punto il numero di pagina in cui è stata trovata il numero di recensioni positive che il libro ha
su amazon qualsiasi criterio o insieme di criteri che vogliamo insomma una volta trasformata la
ricerca diretta in un sistema di votazione otteniamo ben due vantaggi rispetto all'algoritmo
precedente il primo consiste nell'eliminare le ricerche che non diano risultati che è appunto
il problema da cui siamo partiti il bacino di scelta infatti riduce la componente di casualità
permettendo di evitare di selezionare parole poco adatte utilizzate in modi inconsueti o poco comuni
in più però otteniamo anche un secondo vantaggio che ci apre un nuovo orizzonte di possibilità le
regole di votazione che abbiamo aggiunto infatti ci permettono di applicare le più disparate
regolazioni al nostro motore di ricerca cambiare le regole ci permetterà di cambiare il risultato di
poco o di tanto a seconda delle necessità se ad esempio prediligeremo regole che si basano su un
criterio di autorevolezza dei testi in cui cerchiamo il risultato sarà di maggiore
attendibilità mentre se prediligeremo testi più antichi il linguaggio sarà più arcaico e così via
siamo dunque giunti a saper generare dei testi in linguaggio naturale partendo da un gruppo di
parole e attenendoci ad una serie di indicazioni o regole ma quello che vogliamo fare in realtà non
è solo creare un software in grado di ciarlare all'infinito il nostro scopo è programmare un
bot che dialoghi con il proprio utente seguendo il classico approccio botta e risposta quindi
dobbiamo fare in modo che il software sia in grado di capire ciò che gli viene detto anche se qui
capire è fra due virgolette belle grandi nel nostro caso infatti capire vuol dire in realtà
selezionare semplicemente le parole più importanti della richiesta ed utilizzarle come gruppo di
partenza per indirizzare la ricerca così come l'abbiamo descritta fino ad ora valutare l'input
in questo modo non solo ci permetterà di creare testi che suonino naturali ma che siano anche
sensati rispetto a quanto richiesto dall'utente per effettuare questa scrematura esistono vari
metodi e tanto per capire il concetto te ne descrivo uno dei più semplici che ho visto anche
applicare durante un workshop qualche mese fa anche se nella realtà quello di chat gpt è più
complesso di così il processo consiste in pratica nell'utilizzare un dizionario che cataloga le
parole di una lingua in base all'utilità le parole meno utili come ad esempio gli articoli vengono
scartate una dopo l'altra fino a raggiungere una frase spesso sgrammaticata ma questo non importa
che soddisfi però un certo livello di importanza una volta effettuata questa operazione possiamo
considerare il risultato come input di partenza per la nostra generazione del testo è controintuitivo
ma funziona il nostro bot sembrerebbe a questo punto completo almeno da un punto di vista teorico
ma se hai provato ad utilizzare chat gpt o hai letto un po di esperimenti fatti da altri saprai
certamente che esso è in grado di fare molto di più che rispondere con un testo sensato ad una
domanda è in grado di eseguire compiti come scrivere poesie rispondere in altre lingue
formulare una lista di istruzioni enunciandole come farebbe dante nella divina commedia e tante
altre cose simili sono questi forse gli aspetti che più di tutti hanno tratto in inganno tante
persone dando l'impressione che per svolgere compiti del genere sia necessaria una sorta di
intelligenza simile a quella umana ma in verità per raggiungere un tale livello di complessità
al nostro bot non serve pensare non gli serve ragionare né inventare alcunché basta solo che
noi aumentiamo il numero di testi a cui attingere da una parte e il numero di regole del sistema di
voting dall'altra per il numero di testi beh openai sfruttando un super elaboratore realizzato
appositamente da microsoft ha potuto dare in passo a chat gpt una quantità enorme di dati non che pare
tutto il web disponibile fino a qualche mese fa mentre noi dal canto nostro per il nostro
esperimento mentale dobbiamo semplicemente immaginare di avere a disposizione una biblioteca
che comprenda gran parte dello scibile umano cartaceo o digitale che sia per il numero di
regole invece il discorso è un po più complesso sarebbe umanamente impossibile progettare tutte
quelle necessarie a coprire ogni possibile combinazione di richieste potrebbe sempre
arrivare qualcuno a chiedere di progettare un codice di leggi per una società in cui le
giraffe sono la specie più evoluta e dominante ad esempio quindi appare subito chiaro che stilare a
mano un catalogo completo di regole è praticamente irrealizzabile considerando che la loro quantità
sarebbe enorme e la complessità di una singola regola potrebbe anche essere notevole ma la
soluzione è in realtà molto più semplice di quanto possa sembrare serve infatti un bel po di
potenza di calcolo ma si può fare in modo che il bot generi da solo tutte le regole di cui ha
bisogno il concetto è noto come auto apprendimento non è nulla di nuovo nel campo dei large language
model e supergio funziona in questo modo si mette a lavorare un sistema su un gruppo di regole
presso che casuali e utilizzando una selezione di testi dalla base dati si fa in modo che il
sistema corregga poco a poco le regole so che sembra impossibile ma facciamo un semplice esempio
prendiamo la prima frase della divina commedia che tutti conosciamo che nel mezzo del cammin
di nostra vita mi ritrovai per una selva oscura che la dritta via era smarrita l'idea è quella
di provare a cercare le parole della frase ad esempio cercando nel cammin di nostra ci
aspetteremo di individuare la parola vita ma con le regole casuali impostate inizialmente
immaginiamo che il nostro llm tiri fuori per qualche motivo la parola nonna chissà da quale
testo a questo punto essendo in fase di auto apprendimento l'algoritmo confronterà automaticamente
la risposta nonna con la parola vita che sa essere quella giusta si accorgerà che le due non
coincidono e che quindi la ricerca ha prodotto un risultato sbagliato e come conseguenza cambierà
leggermente alcune regole e riproverà andrà avanti così a provare e riprovare per centinaia di volte
finché la parola che viene fuori dalla ricerca non sarà effettivamente vita ripetendo questa operazione
per un numero sufficiente di volte su un numero sufficiente di esempi dove sufficiente vuol dire
milioni o addirittura miliardi il catalogo delle regole diverrà sempre più grande e accurato e nel
momento in cui noi chiederemo al nostro bot di scrivere la ricetta della carbonara in terzine
dantesche lui sarà in grado di selezionare una serie di parole che si adattino a rispondere
alla nostra domanda. Infine giuro è l'ultimo passaggio abbiamo finito dobbiamo mettere ora
tutto insieme e ricapitolare il processo. Il nostro bot riceve un testo in input e lo prepara facendolo
passare attraverso una rete neurale che come una versione potentissima dei dizionari menzionati
prima seleziona le parole più importanti assegnando a ciascuna un valore di importanza appunto un peso
una volta ottenuto questo elenco di parole pesate esso viene utilizzato per avviare una ricerca nel
large language model che grazie ai pesi riesce anche a selezionare quali regole far prevalere
durante l'esecuzione. Al termine di tutto questo processo la ricerca produce una parola questa
parola viene aggiunta al testo in input e tutto il giro ricomincia da capo considerando l'elenco
aggiornato ad ogni iterazione il testo diventa più lungo di una parola finché non viene generato
un testo di risposta con le caratteristiche richieste. Chiaramente ho dovuto sorvolare
su tanti aspetti e semplificarne altri ma tutto sommato a questo punto se mi sono spiegato a
dovere dovrebbe essere chiaro un fatto abbastanza importante e cioè che un bot come chat gpt o in
generale un llm come gpt o bardo quello che sia non crea proprio nulla semplicemente imita è di
fatto un selezionatore di parole su base statistica molto grande molto potente ma niente più di questo
copia manipola e unisce testi che già esistono non è minimamente in grado di pensare o di formulare
idee ma nemmeno di capire il senso dei testi che riceve in input o di quelli che genera in output
ed è questo forse il punto cruciale di tutto l'episodio per come è stato ampiamente descritto
per come è stato posto in termini grafici e per come è stato pubblicizzato e diffuso chat gpt
trasmette un'enorme sicurezza la sicurezza che trasmette una persona molto intelligente ed esperta
dell'argomento di cui sta parlando ma la verità è che si tratta solamente di una facciata una bugia
sorretta unicamente dal fatto che statisticamente molto spesso una parola ne segue un'altra rosso
di sera ecco se hai pensato bel tempo si spera hai applicato lo stesso principio ho voluto fare
tutto questo discorso e provare a descrivere come funziona il sistema gpt perché ritengo importante
che chi ci ha e ci avrà a che fare in qualche modo tenga sempre bene a mente i suoi limiti
viviamo in un periodo storico molto importante stiamo attraversando un momento fantastico per
ciò che riguarda il progresso tecnologico anche e soprattutto nel campo del machine learning fino
a pochi anni fa mancavano gli strumenti hardware ma ora ci sono le risorse in termini di ricerca
quantità di dati addestramento e potenza di calcolo non oso neanche immaginare cosa accadrà
tra dieci anni ma è proprio per questo motivo che dobbiamo essere consapevoli questi llm stanno
venendo integrati in moltissimi strumenti che utilizziamo anche noi ogni giorno e che utilizzano
le persone che prendono le decisioni pertanto dobbiamo abituarci tutti ad usarli correttamente
il prima possibile è questo il momento di porci le domande giuste come utenti di iniziare a
sviluppare i giusti anticorpi altrimenti ci troveremo catapultati in un mondo che non capiremo
come funziona e di cui non sappiamo utilizzare correttamente gli oggetti le applicazioni reali
già si vedono microsoft sta correndo ad integrare gpt nel suo motore di ricerca bing in office 365
google fa lo stesso con bard in gmail nella sua suite da ufficio e in realtà pare anche che i
risultati siano molto incoraggianti perché no? noi però dobbiamo evitare di abbandonarci alla
pigrizia ed accontentarci immediatamente di delegare le nostre decisioni a questi sistemi
dobbiamo capire e ricordare che chissà quello che sta facendo siamo sempre noi bard o gpt per
quanto possano diventare sofisticati almeno per ora non hanno idea di quello che fanno e per i
fini per i quali sono stati pensati in effetti nemmeno è importante che lo capiscano per tutti
questi motivi usarli come base di partenza per qualcosa può rivelarsi veramente utile in termini
di produttività di comodità eccetera ma prendere per buone le loro creazioni senza
valutarle prima attentamente beh questo potrebbe rivelarsi una follia
bene anche oggi l'episodio è giunto al termine io non ho più voce ma spero di
averti portato come al solito un contenuto interessante e spero anche di averlo spiegato
in maniera sufficientemente chiara perché l'argomento è bel lungi dall'essere semplice
prima di chiudere come ormai di consuetudine ringrazio edoardo e carlo per la loro donazione
mensile e se anche tu apprezzi quello che faccio ti invito a fare come loro e dimostrarlo
concretamente ricorda nessuna cifra è troppo bassa e puoi star certo che verrà utilizzata
per migliorare questo progetto la verità è che io ho tante idee ma ho anche capito che non
posso fare tutto da solo ti anticipo già che il primo obiettivo a cui sto lavorando è quello
di eliminare la pubblicità per rimuovere il tracciamento la profilazione ma un po di supporto
è indispensabile sul sito pensieriincodice.it trovi tutti i link utili per donazioni affiliazioni
gruppo e canale telegram eccetera a proposito di telegram l'ingresso nel gruppo è impostato su
autorizzazione perché purtroppo su telegram c'è un serio problema di bot ti consiglio quindi di
scrivermi se vuoi entrare per velocizzare le procedure di verifica mi trovi facilmente
cercando chiocciola valerio galano direttamente nella casella di ricerca telegram infine non
dimenticare di condividere l'episodio con amici parenti gruppi eccetera come al solito far crescere
gli ascoltatori è sempre l'obiettivo primario e a te non costa nulla grazie dunque per aver
ascoltato fin qui grazie alla mia voce per aver retto fino alla fine ci sentiamo ad un prossimo
episodio e non dimenticare mai che un informatico risolve problemi a volte anche usando il computer

