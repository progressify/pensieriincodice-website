text: "
## Intro

Sono passati ormai quasi sei mesi da quando si è scatenato l'enorme interesse di massa per ChatGPT e le sue innumerevoli applicazioni, e qui su Pensieri in codice la vita è trascorsa serena e tranquilla nonostante tutto il tumulto e l'entusiasmo che imperversava all'esterno.

Ora, però, che il clamore iniziale è un po' scemato, che il fumo del sensazionalismo ha iniziato un po' a diradarsi, direi che è arrivato anche per noi il momento di unirci alla festa.

Ovviamente, nel nostro stile: usando la testa e con elegante ritardo.

## Cos'è ChatGPT

Nel caso in cui tu abbia vissuto su un eremo e nel mezzo dell'oceano Pacifico negli ultimi sei mesi, devi sapere che ChatGPT è un tipo particolare di chatbot bastato su quella che, ad oggi, in tanti ancora si ostinano a chiamare *Intelligenza* Artificiale: gli utenti di questo software, infatti, possono scrivere frasi o domande di ogni genere ed il bot risponde un po' come ci si aspetterebbe da un'entità intelligente.

In realtà, però, ChatGPT è di fatto un'interfaccia realizzata per chattare con un tipo particolare di applicazione di Machine Learning che prende il nome di Large Language Model.

Questo specifico LLM, quello che fa funzionare chatGPT, intendo,è stato battezzato dai suoi creatori GPT e non è certo il primo del suo genere realizzato fino ad ora.

Come vedremo a breve, infatti, la tecnologia di cui stiamo parlando non è particolarmente moderna, e nemmeno esclusiva di questo bot (ne esistono molti e tanto per fare un altro nome illustre, Google ha sviluppato la sua versione che ha chiamato Bard), ma la novità è che fino ad ora un lavoro di questo tipo non era mai stato applicato su così larga scala e poi messo a disposizione degli utenti in modo così semplice e gratuito.

Quindi ChatGPT non è tanto il primo esempio della sua categoria, quanto piuttosto il primo ad aver raggiunto e colpito fortemente così tante persone anche al di fuori della ristretta cerchia degli addetti ai lavori, facendo parlare di sé così in lungo e in largo.

Realizzato dalla americana OpenAI, il servizio è stato mostrato al grande pubblico a fine Novembre 2022 con una versione beta per essere poi dichiarato stabile verso la fine di Marzo di quest'anno.

L'entusiasmo globale è stato enorme! In 5 giorni ha raggiunto 1 milione di utenti registrati: tanto per intenderci, Instagram ci ha messo 5 mesi a conseguire lo stesso obiettivo.

Un LLM come GPT, che di fatto è il perno centrale di ChatGPT, è un sistema in grado di accettare gli input più disparati e, sulla base di questi, rispondere a tono in linguaggio umano. Pertanto, la possibilità di interagire con esso attraverso un semplice meccanismo di chat, ha giustamente scatenato un entusiasmo notevole.

Inoltre, GPT è stato reso disponibile anche tramite delle API, cioè quei meccanismi dedicati agli sviluppatori e utilizzabili in modo programmatico, e ciò ho permesso a tanti di integrarlo all'interno di altri servizi o software.

Quindi, fermiamoci un secondo e facciamo un attimo ordine nei termini che un questo episodio ci serviranno: GPT è il motore; ChatGPT è l'interfaccia che permette di chattare con il motore; e ancora, le API sono altre interfacce per permettono di utilizzare il motore attraverso altri software.

Come accennavamo quindi poco fa, fin da subito, ChatGPT ha stupito il mondo con la sue capacità dialettiche, devo dire onestamente superiori anche a quelle di una certa fetta di umani :D. E ciò ha fatto si' che le persone iniziassero ad utilizzarlo per gli scopi più disparati: dal semplice svago, allo studio del sistema stesso, fino ad applicazioni professionali e di supporto nel proprio lavoro.

Data la disponibilità delle API, poi, la corsa ad inventarsi un modo per sfruttare le sue grandi capacità è stata ed è tutt'ora, a dir poco rocambolesca.

È stato integrato nei più disparati software e servizi e, come sempre accade in questi casi, qualcuno ha quasi subito individuato un utilizzo sensato dello strumento, dando vita a sinergie proficue o a tutta una serie di esperimenti interessanti; mentre, al contrario, molti altri hanno frainteso, in parte o in toto, le possibilità di questo motore e hanno prodotto storture e aberrazioni senza senso.

Gli esempi, in entrambe le direzioni, sono moltissimi e sono certo che di giorno in giorno ne vedremo di nuovi.

Tanti hanno semplicemente deciso di giocare con ChatGPT, di provare i più disparati esperimenti: cercando di sondarne i limiti e le possibilità, cercando di forzarlo a funzionare in modi diversi da quelli per i quali è stato programmato, potremmo dire che hanno provato ad hackerarlo. Si tratta di comportamenti mossi da una sana curiosità e perfettamente comprensibili.

Molti altri hanno compreso immediatamente il fatto che se correttamente indirizzato e supervisionato, può essere di ampio supporto in varie attività: in particolare quelle creative o di ricerca e catalogazione delle informazioni.

Tra i soli esempi di cui mi è capitato di leggere, ho visto utenti fargli scrivere testi base per descrizioni, storie, copioni, articoli, algoritmi, itinerari di viaggio. Senza contare chi, utilizzandolo in connubio con gli altri strumenti simili, in grado di generare, ad esempio, immagini, musiche e altro, ha dato vita a tanti prodotti interessanti: app, siti Web, la redazione di Guerre di Rete ha progettato un intero gioco da tavolo in un pomeriggio.

Certo, tutti risultati da rifinire, a volte da correggere in minore o maggior parte, ma, in effetti, quasi sempre un buon punto da cui partire per produrre qualcosa.

Purtroppo però, c'è stato anche chi ha pensato di usare questo strumento in modi che definire *discutibili* è poco. L'evidente potenza del sistema ha suscitato, in alcuni, la spinta a cercare impieghi che generino tornaconto a scapito di fattori come l'etica, tanto per dirne una. Anche questo è nella natura umana, lo capisco... ma per fortuna non di tutti gli umani.

Anche di questi si sono visti esempi di ogni tipo: progettazione di campagne di phishing, scrittura di fake news, produzione di algoritmi con i più disparati bias o pregiudizi, redazione di strategie di attacco per la diffusione di malware. Tutte cose simpatiche, insomma.

Ma in tutto questo marasma, a mio parere, le storture peggiori sono quelle che si sono verificate, e se ne verificheranno sicuramente altre in futuro, quando gli utilizzi aberranti sono derivati, non dall'intenzione di creare qualcosa di orribile, quanto piuttosto dalla scarsa conoscenza e consapevolezza di come funzioni effettivamente lo strumento; di cosa possa e non possa fare; o di quanto sia attendibile nel fare quello che si tenta di fargli fare.

Quello che intendo dire è che, è fisiologico che ci sarà sempre qualcuno che utilizza uno strumento per fini magari poco etici o addirittura poco legali, ma con piena intenzione e cognizione di causa: questo fatto lo sobbiamo accettare e, di conseguenza, gestire come società. Ma i comportamenti forse più pericolosi, sono quelli non previsti; quelli derivanti dagli aspetti non considerati.

E così, ad esempio, una società che gestisce un servizio di supporto psicologico online ha ben pensato di provare, su un gruppo di utenti-cavie, a rispondere al primo livello di richieste utilizzando un bot basato su GPT, senza, nel fare ciò, chiedersi quanto potrebbe essere dannosa una prima risposta potenzialmente fuori luogo data ad ad utenti che, per la natura del servizio offerto, probabilmente sono già fragili in partenza.

Oppure, altro esempio, molti che utilizzano ChatGPT come *motore di ricerca* o *compagno di discussione* per risolvere i più disparati problemi, hanno sistematicamente condiviso informazioni sensibili personali o professionali o della propria azienda, senza, dal canto loro, chiedersi dove queste vengano archiviate e chi possa avervi accesso.

Ora: gli esempi in tal senso sono, anch'essi, tantissimi, ma sinceramente non mi interessa, in questo momento, fare un elenco di storture o una sorta di bestiario delle aberrazioni nate da ChatGPT. Quello che piuttosto vorrei fare è provare ad evidenziare quali sono, secondo me, le cause di fondo di questo genere di comportamenti e dare il mio piccolo contributo per contrastarle, perché ritengo che sia questo il modo migliore per ridurre i comportamenti più pericolosi in assoluto, quelli involontari.

Nel suo celebre testo *Le leggi fondamentali della stupidità umana*, Il professor Cipolla, come corollario alla quinta legge, afferma che *Lo stupido è più pericoloso del bandito.*, riassumendo proprio il senso di quanto ho cercato di spiegare poco fa. Lo stupido è colui che agisce male senza rendersene conto, mentre il bandito è colui le cui azioni, seppur malvagie, sono ben controllate ed indirizzate.

E ad una prima e superficiale occhiata, questo corollario potrebbe sembrare già riassumere interamente il nocciolo del problema. D'altronde, noi informatici siamo abituati a questo genere di reazione, a volte a torto, a volte a ragione: l'utonto è proprio questo, no? Quell'utente che non è in grado di utilizzare uno strumento tecnologico non perché esso è troppo complicato, bensì perché è lui ad essere troppo stupido per capirlo.

Sarebbe facile considerare uno stupido, colui che ha pensato di integrare GPT nel proprio business che magari richiede competenze di tutt'altro genere, o di farsi difendere in tribunale da ChatGPT o di chiedergli consigli di trading e altro. Ma quando la manifestazione di stupidità è così su larga scala come è accaduto e sta accadendo giorno dopo giorno con ChatGPT e i suoi derivati, forse è il caso di chiedersi se si parla di ancora di utonti, se effettivamente solo di stupidità si tratti.

Può essere, davvero, la causa di tante storture ricondotta solo ed unicamente alla stupidita dei vari utilizzatori? Anche se parliamo di persone molto abili nei rispettivi campi, inclini a sperimentare le novità e abituati ad utilizzare la tecnologia? Non è che magari il problema, sotto sotto, risieda altrove?

## È importante capire come funzionano le cose

Probabilmente avrai già sentito nominare la terza legge di Clarke che recita *Qualunque tecnologia sufficientemente avanzata è indistinguibile dalla magia*.

E, se ci pensi, è vero: si tratta di un concetto molto attuale che, una volta chiarito a dovere il significato del termine *magia*, si adatta particolarmente a tantissime situazioni del nostro tempo.

Tuttavia, io sono anche convinto che guardare il mondo con il solo ausilio di una tale concezione della tecnologia, porti a vedere il tutto attraverso un potente filtro: una sorta di limite che spinge a sottovalutare altri aspetti, secondo me molto importanti, della questione.

Molti fanno risalire la nascita del concetto di computer alla prima metà del 1800, ad opera del matematico inglese Charles Babbage che realizzò per primo il progetto di un calcolatore programmabile: quella che chiamò la macchina analitica.

Il suo progetto, mai realizzato nella realtà se non come tributo al genio molti anni dopo, derivava da un'altro strumento, meno evoluto, sempre ideato dallo stesso scienziato, ma di cui era stato in grado di realizzare almeno un prototipo.

I costi per la produzione delle migliaia di ingranaggi necessari per le sue macchine e poi per il loro successivo assemblaggio era proibitivo e Babbage organizzava incontri periodici nella sua residenza londinese per mostrare a nobili e intellettuali di tutta l'Inghilterra il suo prototipo, al fine proprio di creare interesse e raccogliere fondi.

A questi incontri, nonostante vi partecipassero le persone più istruite di tutto il Regno (e parliamo in un'epoca nella quale solo 1 bambino su 11 riceveva un'istruzione formale) capitava spesso che qualcuno, vedendo in funzione la macchina differenziale intenta ad eseguire dei conti, la definisse *macchina intelligente* o addirittura facesse domande del tipo *ma se inserisco dei numeri errati, il risultato sarà comunque corretto?*.

Ecco, esistono tantissime testimonianze del fatto che ogni volta, Babbage, ben lungi da considerarli stupidi, si affrettava a ridimensionare le impressioni e le aspettative di questi entusiasti intellettuali, spiegando loro che la macchina non era né intelligente né in grado di pensare, ma solo di fare determinati calcoli che venivano per essa programmati.

Anche per via di questa sua *onestà intellettuale*, Babbage non riuscì mai a realizzare i suoi progetti, dato che non riuscì mai ad ottenere sufficienti sovvenzioni pubbliche o private che fossero.

Oggi invece, mi sembra proprio che l'atteggiamento, la retorica e il marketing che girano introno a questi strumenti di Machine Learning siano orientati esattamente nel verso opposto e ci vogliano in qualche modo far credere che essi siano in grado di pensare e risolvere i problemi in autonomia.

Lo stesso ChatGPT, se lo hai provato l'avrai notato, è implementato per dare l'impressione all'utente di stare dialogando con un intelligenza di qualche sorta: usa persino tecniche visive tipiche dei film o dei videogiochi.

Normalmente, infatti, la risposta ad un prompt data da un software è immediata: viene elaborato il risultato e poi mostrato nel modo più rapido possibile. In ChatGPT, invece, le parole compaiono una per volta, come a darci l'impressione di stare comunicando con un'intelligenza aliena da film di fantascienza; come a farci credere che stia pensando e formulando le frasi.

Secondo me, è proprio questo atteggiamento a generare confusione nel grande pubblico, soprattutto nelle persone meno tecnicamente preparate sull'argomento. Sono questi e gli altri trucchi della stessa risma, come ad esempio continuare a martellare sul termine *Intelligenza Artificiale*, che fanno apparire questa *tecnologia* più come una *magia* o, nel caso specifico come una *intelligenza*.

Invece di diffondere la conoscenza, si diffonde il mito.

Ma per come la vedo io, basta scalfire la superficie del problema, dissipare l'aura di trascendenza, per dare a chiunque gli strumenti per capire una tecnologia. Non serve diventare degli esperti: basta capirne almeno i concetti di base.

E quindi oggi voglio provare a fare proprio questo: voglio provare a sfatare un pochino del mito. Ad intaccarne l'effige.

## Large Language Model: come funzionano

Partiamo subito con il dire che io non sono né un esperto di Machine Learning, né ho mai avuto accesso a chissà quali informazioni riservate su ChatGPT. Lo spunto per questo episodio mi è stato dato da un articolo del New Yorker che ti lascio in descrizione insieme a tutte le altre fonti che ho utilizzato.

Secondo l'autore dell'articolo, e anche secondo me, il miglior modo per capire i concetti di base di una tecnologia è provare ad affrontare e superare, almeno dal punto di vista teorico, i vari ostacoli che essa pone ai suoi progettisti.

Ovviamente noi non saremo in grado di implementare il nostro bot nella mezz'ora che dovrebbe durare questo podcast, ma individuare e risolvere teoricamente i problemi, ci permetterà, da una parte, di contestualizzare le caratteristiche del prodotto e, dall'altra, di comprendere le scelte fatte da coloro che quei problemi li hanno realmente affrontati.

Come punto di partenza, torniamo dunque a ribadire che un bot come ChatGPT si basa essenzialmente sull'utilizzo di un tipo di Machine Learning chiamato Large Language Model, che, in pratica è una rete neurale ad apprendimento automatico allenata su una quantità enorme di dati. Di fatto, il bot funge da interfaccia per la rete neurale e le permette di ricevere gli input dagli utenti e di restituire agli stessi gli output.

Tuttavia, per il nostro scopo di oggi, ti anticipo già che non sarà necessario capire in dettaglio come funziona una rete neurale o un'interfaccia. Tutto quello che faremo sarà descrivere i vari passaggi necessari al bot per produrre una risposta a partire da una domanda e, sempre per semplicità, ci limiteremo a considerare solo le funzionalità inerenti il testo, ignorando tutto ciò che riguarda le modalità di funzionamento di algoritmi per gestire immagini, musica, ecc.

Quindi, il concetto di base è: un testo in input produce un testo in output coerente con l'input ricevuto.

Come possiamo fare a realizzare una cosa del genere?

Beh come prima cosa, abbiamo detto di avere a disposizione una grande quantità di dati, no? Proviamo innanzitutto a capire come sfruttare quelli.

Per farlo, e tanto per ribadire che questa tecnologia è tutt'altro che nuova, partiamo da un grande classico dell'informatica: il testo intitolato A Mathematical Theory of Communication scritto da Claude Shannon, che è il matematico che per primo ha descritto la teoria della gestione dell'informazione: praticamente la base dell'informatica moderna.

In questo paper, oltre a tanta matematica, ovviamente, si può trovare anche la descrizione di un interessante esperimento di generazione del testo.

Shannon scrive nel 1948 e all'epoca non immagina le dimensioni alle quali sarebbe potuta arrivare una banca dati nel 2023, o cosa sarà Internet, o ancora di quanta potenza di calcolo avremmo potuto disporre noi al giorno d'oggi, quindi formula tutto il suo ragionamento considerando come base di informazioni disponibili la sua libreria personale.

Il discorso è ovviamente in scala rispetto a quelli che sono i numeri di un moderno Large Language Model, ma, nonostante ciò funziona perfettamente e, come bonus, lo si può mettere in pratica anche senza l'ausilio di un computer: basta semplicemente avere qualche libro in casa.

Come prima cosa, Shannon sceglie una parola da cui iniziare la generazione del testo e la scrive su un foglio. Per semplicità sceglie una delle più comuni della sua lingua: l'articolo *the*.

A questo punto, sceglie un libro a caso dalla libreria, e lo apre ad una pagina, sempre a caso. Legge il testo finché non arriva alla parola *the* e a quel punto scrive sul suo foglio la prima parola che viene subito dopo, che nel suo esempio è *head* (testa).

Il testo sul foglio diventa quindi *the head* e lui ripete il processo partendo però questa volta dalla parola *head*. La cerca in una pagina a caso di un libro a caso e, quando la trova, ricopia sul suo foglio la parola che appare subito dopo. La terza parola è quindi *and* (e congiunzione).

Continua così per un po', e alla fine arriva a formulare la frase “The head and in frontal attack on an English writer that the character of this point is therefore another method.*

La frase in sé non ha tantissimo senso, sono d'accordo, ma l'algoritmo messo a punto è un'ottima base da cui possiamo partire noi per realizzare il nostro semplice LLM casalingo.

Per migliorare la logica del testo generato possiamo usare un semplice trucco che, pur rendendo un po' più complicata la ricerca, ha però il vantaggio di aumentare la probabilità di prelevare parole maggiormente sensate: possiamo, invece di ricercare una singola parola ad ogni iterazione, cercarne gruppi di due, tre o anche di più.

Quindi, se il testo che vogliamo generare, deve parlare, ad esempio, della razza di cane pastore tedesco, potremmo scrivere sul nostro foglietto le parole di partenza *il pastore tedesco è* e poi scorrere le pagine del libro finché non troviamo esattamente le tre parole *pastore tedesco è* per poi, come prima, prelevare la successiva e aggiungerla al nostro testo.

Applichiamo il nuovo algoritmo e, a scopo esemplificativo, facciamo finta che la parola trovata sia *una* (l'articolo indeterminativo femminile). La frase diventerebbe *il pastore tedesco è una*, mentre la prossima chiave di ricerca diventerebbe *tedesco è una*, perché stiamo sempre cercando tre parole per volta.

Procediamo così, prendendo libri e pagine a caso, per tre, quattro, cinque, dieci o cento volte, dipende da quanto vogliamo che il nostro testo sia lungo.

Con quest'altra modifica applicata all'algoritmo, l'attinenza delle parole fra loro è dunque aumentata ma scommetto già che stai iniziando ad intuire che per ottenere dei risultati decenti, serve una quantità di libri, quindi una base dati, molto grande.

Se avessimo, infatti, pochi libri, considerando la complessità delle nuove chiavi di ricerca, finiremmo per capitare sempre sulle stesse pagine e quindi, automaticamente, ci troveremmo ricopiare più o meno pedissequamente il testo del libro. Oppure, nella peggiore delle ipotesi, potremmo non trovare nessun gruppo di parole che soddisfi la ricerca, e in tal caso dovremmo semplicemente rinunciare.

Ma anche con molti moltissimi libri a disposizione, resta un problema di fondo: certi gruppi di parole possono portare a ricercare nell'intero database senza dare risultati, quindi, per produrre un algoritmo robusto, ci serve di inventarci una strategia che ci eviti di andare a comporre delle chiavi di ricerca troppo insolite o impossibili da trovare.

Per ampliare il ventaglio di possibili risultati, allora, cambiamo leggermente approccio: innanzitutto, passiamo dal cercare esattamente un gruppo di parole al cercare quelle stesse parole in ordine sparso all'interno di gruppetti poco più grandi.

In pratica in questo modo riusciamo ad individuare anche le chiavi di ricerca che somigliano alla nostra, non per forza solo quelle identiche.

Poi, invece di accodare immediatamente la parola al nostro testo appena incontriamo un risultato per la nostra ricerca, annotiamola da qualche parte.

Poi continuiamo a cercare la stessa chiave in altri libri o pagine e ogni volta che incontriamo una parola candidata ad entrare a far parte del nostro testo, la annotiamo insieme alle altre.

Alla fine, ovviamente, otterremo non più una sola parola ma una lista di candidate. E per scegliere fra queste quale sia la più adatta, possiamo allora predisporre un sistema di classifica basato su dei voti che daremo ad ogni parola: banalmente quella con il voto più alto, verrà selezionata per entrare a far parte del testo che stiamo generando.

Il voto può essere calcolato in base ai fattori che riteniamo più appropriati, come ad esempio il numero di volte in cui la parola appare nella lista, o la quantità di parole che la precedono o la seguono fino al punto, il numero di pagina in cui è stata trovata, il numero di recensioni positive che il libro ha su Amazon, qualsiasi criterio o insieme di criteri che vogliamo, insomma.

Una volta trasformata la ricerca diretta in un sistema di votazione, otteniamo ben due vantaggi rispetto all'algoritmo precedente.

Il primo consiste nell'eliminare le ricerche che non diano risultati, appunto il problema da cui siamo partiti: il bacino di scelta, infatti, riduce la componente di casualità, permettendoci di evitare di selezionare parole poco adatte, utilizzate in modi inconsueti o poco comuni.

In più, però, otteniamo anche un secondo vantaggio che ci apre un nuovo orizzonte di possibilità: le regole di votazione che abbiamo aggiunto, ci permettono, infatti, di applicare le più disparate regolazioni al nostro motore di ricerca!

Cambiare le regole ci permetterà di cambiare il risultato di poco o tanto a seconda delle necessità. Se ad esempio prediligeremo regole che si basano su un criterio di autorevolezza dei testi in cui cerchiamo, il risultato sarà di maggiore attendibilità; mentre se prediligeremo testi più antichi, il linguaggio sarà più arcaico, e così via.

Siamo giunti dunque a saper generare dei testi in linguaggio naturale partendo da un gruppo di parole e attenendoci ad una serie di indicazioni o regole, ma quello che vogliamo creare non è solo un software in grado ci ciarlare all'infinito; il nostro scopo è programmare un bot che dialoghi con il proprio utente seguendo il classico approccio botta e risposta.

Quindi, dobbiamo fare in modo che il software sia in grado di *capire* ciò che gli viene chiesto. *Capire* fra due virgolette belle grandi.

Nel nostro caso, infatti, *capire* vuol dire, in realtà, selezionare semplicemente le parole più importanti della richiesta ed utilizzarle come gruppo di partenza per indirizzare la ricerca così come l'abbiamo descritta fino ad ora: valutare l'input in questo modo ci permetterà non solo di creare dei testi che suonino naturali, ma che siano anche sensati rispetto a quanto richiesto dall'utente.

Per effettuare questa scrematura esistono vari metodi. Tanto per capire il concetto, te ne descrivo uno dei più semplici, che ho visto anche applicare durante un workshop qualche mese fa, anche se nella realtà, quello di ChatGPT è più complesso di così.

Il processo consiste nell'utilizzare un dizionario che cataloga le parole di una lingua in base all'utilità: le parole meno utili, come ad esempio gli articoli, vengono scartate una dopo l'altra fino a raggiungere una frase (spesso sgrammaticata, ma questo non importa) che soddisfi un certo livello di importanza.

Una volta effettuata questa operazione, possiamo considerare il risultato come input di partenza per la generazione del testo. È contro intuitivo ma funziona.

Il nostro bot sembrerebbe a questo punto completo, almeno dal punto i vista teorico ma se hai provato ad utilizzare ChatGPT o hai letto un po' di esperimenti fatti da altri, saprai certamente che esso è in grado di fare molto di più che rispondere con un testo sensato ad una domanda.

È in grado di eseguire compiti come scrivere poesie, rispondere in altre lingue, formulare una lista di istruzioni enunciandole come farebbe Dante nella Divina Commedia e tante cose simili.

Sono questi forse gli aspetti che, più di tutti, hanno tratto in inganno tante persone, dando l'impressione che per svolgere compiti del genere sia necessaria una sorta di intelligenza simile a quella umana.

Ma in verità per raggiungere un tale livello di complessità, al nostro bot non serve *pensare*. Non gli serve *ragionare* né *inventare* alcunché. Basta solo che noi aumentiamo il numero di testi a cui attingere, da una parte, e il numero di regole del sistema di voting, dall'altra.

Per il numero di testi, beh OpenAI, sfruttando un super elaboratore realizzato appositamente da Microsoft, ha potuto dare in pasto a ChatGPT una quantità enorme di dati, nonché, pare, praticamente tutto il Web pubblicamente disponibile fino a pochi mesi fa.

Dal canto nostro, invece, dal nostro punto di vista, per il nostro esperimento mentale, dobbiamo semplicemente immaginare di avere a disposizione una biblioteca che comprenda gran parte dello scibile umano, cartaceo o digitale che sia.

Per il numero di regole invece, il discorso è un po' più complesso: sarebbe umanamente impossibile progettare tutte quelle necessarie a coprire ogni possibile combinazione di richieste. Potrebbe sempre arrivare qualcuno a chiedere di progettare un codice di leggi per una società in cui le giraffe sono la specie più evoluta e dominante, ad esempio.

Appare, quindi, subito chiaro che stilare a mano un catalogo completo di regole è praticamente irrealizzabile, considerando che la loro quantità sarebbe enorme e la complessità di una singola regola potrebbe anche essere notevole.

Ma la soluzione è, in realtà, molto più semplice di quanto possa sembrare: serve, infatti, un bel po' di potenza di calcolo, ma si può fare in modo che il bot generi da solo tutte le regole di cui ha bisogno.

Il concetto è noto come auto-apprendimento, non è nulla di nuovo nel campo dei Large Language Model e su per giù funziona in questo modo: si mette a lavorare il sistema su un gruppo di regole pressoché casuali e, utilizzando una selezione di testi della base dati, si fa in modo che il sistema corregga a poco a poco le regole.

So che sembra impossibile ma facciamo un semplice esempio con la Divina Commedia: la prima frase che tutti conosciamo è *Nel mezzo del cammin di nostra vita, mi ritrovai per una selva oscura, ché la diritta via era smarrita.*

L'idea è quella di provare a cercare le parole della frase: ad esempio, cercando *nel mezzo del cammin di nostra*, ci aspetteremo di individuare subito la parola *vita*. Ma con le regole casuali impostate inizialmente, immaginiamo che il nostro LLM tiri fuori la parola *nonna* da chissà quale altro testo.

A questo punto, essendo in fase di auto apprendimento, l'algoritmo confronterà automaticamente la risposta *nonna* con la parola *vita* che sa essere quella corretta. Si accorgerà che le due non coincidono e che quindi la ricerca ha prodotto un risultato sbagliato e come conseguenza cambierà leggermente alcune regole e riproverà.

Andrà avanti a riprovare per centinaia di volte finché la parola che viene fuori dalla ricerca non sarà effettivamente *vita*.

Ripetendo questa operazione per un numero sufficiente di volte, su un numero sufficiente di esempi (dove sufficiente vuol dire milioni o miliardi), il catalogo delle regole diverrà sempre più grande e accurato e nel momento in cui noi chiederemo al nostro bot di scrivere la ricetta della carbonara in terzine dantesche, lui sarà in grado di selezionare una serie di parole che si adattino a rispondere alla nostra domanda.

Infine (è l'ultimo passaggio, giuro) dobbiamo mettere ora tutto insieme e ricapitolare il processo.

Il nostro bot riceve un testo in input e lo prepara facendolo passare attraverso una rete neurale che, come una versione potentissima dei dizionari menzionati prima, seleziona le parole più importanti assegnando a ciascuna un valore di importanza, un peso.

Una volta ottenuto questo elenco di parole pesate, esso viene utilizzato per avviare una ricerca nel Large Language Model, che, grazie ai pesi, riesce anche a selezionare quali regole far prevalere durante l'esecuzione.

Al termine di tutto questo processo, la ricerca produce una parola.

Questa parola viene inserita nel testo di input e tutto il giro ricomincia da capo considerando l'elenco aggiornato.

Ad ogni iterazione il testo diventa più lungo di una parola, finché non viene generato un testo di risposta con le caratteristiche richieste.

## ChatGPT non crea, imita

Chiaramente, ho dovuto sorvolare su tanti aspetti e semplificarne altri, ma tutto sommato, a questo punto, se mi sono spiegato a dovere, dovrebbe essere chiaro un fatto abbastanza importante: e cioè che un bot come ChatGPT o, in generale un LLM come GPT o Bard, non crea proprio nulla. Semplicemente imita.

È, di fatto, un selezionatore di parole su base statistica. Molto grande, molto potente, ma niente più di questo. Copia, manipola e unisce testi che già esistono.

Non è in grado minimamente di pensare, di formulare idee e nemmeno di capire il senso dei testi che riceve in input, o di quelli che genera in output.

Ed è questo forse il punto cruciale di tutto l'episodio: per come è stato ampiamente descritto, per come è stato posto in termini grafici, per come è stato pubblicizzato e diffuso, ChatGPT trasmette un'enorme sicurezza, la sicurezza che trasmette una persona molto intelligente ed esperta dell'argomento di cui sta parlando.

Ma la realtà è che si tratta di solamente di una facciata, un bugia sorretta unicamente dal fatto che statisticamente molto spesso una determinata parola ne segue un altra.

*Rosso di sera*... ecco, se hai pensato *bel tempo si spera*, hai applicato lo stesso principio.

Ho voluto fare tutto questo discorso e provare a descrivere come funziona il sistema GPT perché ritengo importante che chi ci ha o avrà a che fare un qualche modo tenga sempre bene a mente i suoi limiti.

Viviamo in un periodo storico molto importante, stiamo attraversando un momento fantastico per ciò che riguarda il progresso tecnologico, anche e soprattutto nel campo del machine learning.

Fino a pochi anni fa mancavano gli strumenti hardware, ma ora ci sono le risorse in termini di ricerca, quantità dati, addestramento e potenza di calcolo. Non oso nemmeno immaginare cosa accadrà da qui a 10 anni.

Ma è proprio per questo motivo che dobbiamo essere consapevoli: questi llm stanno venendo integrati in moltissimi strumenti che utilizziamo anche noi ogni giorno, e che utilizzano le persone che prendono le decisioni; pertanto dobbiamo abituarci tutti ad usarli correttamente il prima possibile.

È il momento di porci le domande giuste come utenti, di iniziare a sviluppare i giusti anticorpi, altrimenti ci troveremo catapultati in un nuovo mondo che non capiremo come funziona e di cui non sappiamo utilizzare correttamente gli oggetti.

Le applicazioni reali già si vedono: Microsoft sta correndo ad integrare il GPT nel suo motore di ricerca Bing, in Office 365. Google fa lo stesso con Bard in Gmail, e nella sua suite da ufficio. E pare anche che i risultati siano molto incoraggianti, perché no!

Dobbiamo però evitare di abbandonarci alla pigrizia ed accontentarci immediatamente di delegare le nostre decisioni a questi sistemi. Dobbiamo capire e ricordare che *chi sa quello che sta facendo* siamo sempre noi.

Bard o GPT, per quanto possano diventare sofisticati, almeno per ora non hanno idea di quello che fanno. E, per i fini per i quali sono stati pensati, in effetti nemmeno è importante che lo capiscano.

Per tali motivi, usarli come base di partenza per qualcosa, può rivelarsi veramente utile in termini di produttività e comodità. Ma prendere per buone le loro creazioni senza valutarle prima attentamente, beh questo potrebbe rivelarsi una follia.

## Conclusione

Anche oggi l'episodio è giunto al termine. Io spero di averti portato come al solito un contenuto interessante e spero di averlo spiegato in maniera sufficientemente chiara. L'argomento è ben lungi dall'essere semplice.

Prima di chiudere, come ormai di consuetudine ringrazio Edoardo e a Carlo per la loro donazione mensile. E se anche tu apprezzi quello che faccio, ti invito a fare come loro e dimostrarlo concretamente: nessuna cifra è troppo bassa, e puoi star certo che verrà utilizzata per questo progetto.

Ho tante idee, ma ho capito che non posso fare tutto da solo. Ti anticipo già che il primo obiettivo a cui sto lavorando è quello di eliminare la pubblicità per rimuovere, con essa, la profilazione, ma un po' di supporto è indispensabile. Sul sito pensieriincodice.it trovi tutti i link utili per: donazioni, affiliazioni, gruppo e canale telegram, ecc.

A proposto di Telegram, l'ingresso nel gruppo è impostato su autorizzazione perché purtroppo c'è un serio problema di bot. Ti consiglio quindi di scrivermi per velocizzare le procedure di verifica: mi trovi facilmente cercando @valeriogalano direttamente nella casella di ricerca di Telegram.

Infine, non dimenticare di condividere l'episodio con amici, parenti e gruppi. Come al solito, far crescere gli ascoltatori è l'obiettivo primario e a te non costa nulla!

Grazie dunque per aver ascoltato fin qui. Ad un prossimo episodio e non dimenticare mai che *un informatico risolve problemi, a volte anche usando il computer*.
"