{"text": " Sono passati ormai quasi sei mesi da quando si \u00e8 scatenato l'enorme interesse di massa per ChatGPT e le sue innumerevoli applicazioni e qui su Pensieri in Codice la vita \u00e8 trascorsa serena e tranquilla nonostante tutto il tumulto e l'entusiasmo che imperversava all'esterno. Ora per\u00f2 che il clamore iniziale \u00e8 un po' scemato, che il fumo del sensazionalismo ha iniziato un po' a diradarsi direi che \u00e8 arrivato anche per noi il momento di unirci alla festa ovviamente nel nostro stile usando la testa e con elegante ritardo. Benvenuti su Pensieri in Codice il podcast dove si ragiona da informatici con Valerio Galano. Nel caso tu abbia vissuto su un eremo o nel mezzo dell'oceano pacifico negli ultimi sei mesi devi sapere che ChatGPT \u00e8 un tipo particolare di chatbot basato su quella che ad oggi in tanti ancora si ostinano a chiamare intelligenza artificiale. Gli utenti di questo software infatti possono scrivere frasi o domande di ogni genere ed il bot risponde un po' come ci si aspetterebbe da un'entit\u00e0 intelligente ma in realt\u00e0 ChatGPT \u00e8 di fatto un'interfaccia realizzata per chattare con un tipo particolare di applicazione di machine learning che prende il nome di Large Language Model. Questo specifico LLM, quello che fa funzionare ChatGPT intendo, \u00e8 stato battezzato dai suoi creatori GPT e non \u00e8 certo il primo del suo genere ad essere stato realizzato fino ad ora. Come vedremo a breve infatti la tecnologia di cui stiamo parlando non \u00e8 particolarmente moderna e nemmeno esclusiva di questo bot. Ne esistono molti e tanto per fare un nome illustre Google ha sviluppato la sua versione che ha chiamato BARD ma la novit\u00e0 \u00e8 che fino ad ora un lavoro di questo tipo non era mai stato applicato su cos\u00ec larga scala e poi messo a disposizione degli utenti in modo cos\u00ec semplice e gratuito. ChatGPT quindi non \u00e8 tanto il primo esempio della sua categoria quanto piuttosto il primo ad aver raggiunto e colpito fortemente cos\u00ec tante persone anche al di fuori della ristretta cerchia degli addetti ai lavori facendo parlare di s\u00e9 cos\u00ec in lungo e in largo. Realizzato dall'americana OpenAI il servizio \u00e8 stato mostrato al grande pubblico a fine novembre 2022 con una versione beta per poi essere dichiarato stabile verso la fine di marzo di quest'anno e l'entusiasmo globale \u00e8 stato enorme in cinque giorni ha raggiunto un milione di utenti registrati e tanto per intenderci Instagram ci ha messo cinque mesi a conseguire lo stesso obiettivo. Un LLM come GPT che di fatto \u00e8 il perno centrale di ChatGPT \u00e8 dunque un sistema in grado di accettare gli input pi\u00f9 disparati e sulla base di questi rispondere a tono in linguaggio umano pertanto la possibilit\u00e0 di interagire con esso attraverso un semplice meccanismo di chat ha giustamente scatenato un entusiasmo notevole. Inoltre GPT \u00e8 stato reso disponibile anche tramite API cio\u00e8 quei meccanismi dedicati agli sviluppatori e utilizzabili in modo programmatico e ci\u00f2 ha permesso a tanti di integrarlo all'interno di altri servizi o software. Quindi fermiamoci un secondo e facciamo un attimo ordine nei termini che in questo episodio ci serviranno. Dunque GPT \u00e8 il motore, ChatGPT \u00e8 l'interfaccia che permette di chattare con il motore e ancora le API sono altre interfacce che permettono di utilizzare il motore attraverso altri software. Ok? Come accennavamo poco fa quindi fin da subito ChatGPT ha stupito il mondo con le sue capacit\u00e0 dialettiche, devo dire onestamente superiori anche a quelle di una certa fetta di umani, ma ad ogni modo ci\u00f2 ha fatto s\u00ec che le persone iniziassero ad utilizzarlo per gli scopi pi\u00f9 disparati dal semplice svago allo studio del sistema stesso fino ad applicazioni professionali e di supporto nel proprio lavoro. Data la disponibilit\u00e0 delle API poi la corsa ad inventarsi un modo per sfruttare le sue grandi capacit\u00e0 \u00e8 stata ed \u00e8 tuttora a dir poco roccambolesca, \u00e8 stato integrato nei pi\u00f9 disparati software e servizi e come spesso accade in questi casi qualcuno ha quasi subito individuato un utilizzo sensato per lo strumento dando vita a sinergie proficue o a una serie di esperimenti interessanti mentre al contrario molti altri hanno frainteso in parte o in toto la possibilit\u00e0 di questo motore e hanno prodotto storture e abberrazioni senza senso. Gli esempi in entrambe le direzioni sono moltissimi e sono certo che di giorno in giorno ne vedremo sempre di nuovi. Tanti hanno semplicemente deciso di giocare con chat gpt di provare i pi\u00f9 disparati esperimenti cercando di sondarne i limiti e le possibilit\u00e0 cercando di forzarlo a funzionare in modi diversi da quelli per i quali \u00e8 stato programmato potremmo dire hanno cercato di hackerarlo. Si tratta di comportamenti mossi da una sana curiosit\u00e0 e sono perfettamente comprensibili. Molti altri poi hanno capito immediatamente il fatto che se correttamente indirizzato e supervisionato questo pu\u00f2 essere di ampio supporto in varie attivit\u00e0 in particolare quelle creative di ricerca e catalogazione delle informazioni. Tra i soli esempi di cui mi \u00e8 capitato di leggere ho visto utenti fargli scrivere testi base per descrizioni, storie, copioni, articoli, algoritmi, itinerari di viaggio senza contare chi utilizzandolo in connubio con altri strumenti simili in grado di generare ad esempio immagini, musiche o altro, ha dato vita a tanti prodotti interessanti app, siti web, la redazione di guerre di rete ad esempio ha progettato un intero gioco da tavolo in un pomeriggio. Certo intendiamoci tutti i risultati da rifinire a volte da correggere in minore o maggior parte ma in effetti quasi sempre un buon punto da cui partire per produrre un qualcosa. Tuttavia purtroppo c'\u00e8 stato anche chi ha pensato di usare questo strumento in modi che definire discutibili \u00e8 poco. L'evidente potenza del sistema ha suscitato in alcuni la spinta a cercare impieghi che generino un tornaconto personale a scapito di fattori come l'etica tanto per dirne una. Anche questo \u00e8 nella natura umana lo capisco ma per fortuna non di tutti gli umani. Ma anche di questi casi si sono visti esempi di ogni tipo, progettazione di campagne di phishing, scrittura di fake news, produzione di algoritmi con i pi\u00f9 disparati bias o pregiudizi, redazione di strategie di attacco per la diffusione di malware, tutte cose simpatiche insomma. Ma in tutto questo marasma a mio parere le storture peggiori sono quelle che si sono verificate e se ne verificheranno sicuramente altre in futuro quando gli utilizzi aberranti sono derivati non dall'intenzione di creare qualcosa di orribile quanto piuttosto dalla scarsa conoscenza e consapevolezza di come funzioni effettivamente lo strumento, di cosa possa e non possa fare o di quanto sia attendibile nel fare quello che gli si chiede di fare. Quello che sto cercando di dire \u00e8 che \u00e8 fisiologico ci sar\u00e0 sempre qualcuno che utilizza uno strumento perfini magari poco etici o addirittura poco legali ma con piena intenzione e cognizione di causa. Questo fatto lo dobbiamo accettare e di conseguenza gestire come societ\u00e0 ma i comportamenti forse pi\u00f9 pericolosi sono quelli non previsti, quelli derivati da aspetti non considerati. E cos\u00ec ad esempio una societ\u00e0 che gestisce un servizio di supporto psicologico online ha ben pensato di provare su un gruppo di utenti cavie a rispondere al primo livello di richieste utilizzando un bot basato su gpt senza nel fare ci\u00f2 chiedersi quanto potrebbe essere dannosa una risposta potenzialmente fuori luogo data ad utenti che per la natura del servizio probabilmente sono gi\u00e0 fragili in partenza. Oppure altro esempio molti che utilizzano chat gpt come motore di ricerca o compagno di discussione per risolvere i pi\u00f9 disparati problemi hanno sistematicamente condiviso informazioni sensibili personali o professionali o della propria azienda senza dal canto loro chiedersi dove queste vengano archiviate chi possa avervi accesso. Ora anche gli esempi in tal senso sarebbero tantissimi ma sinceramente non mi interessa in questo momento fare un elenco di storture a una sorta di bestiario delle aberrazioni nate da gpt quello che piuttosto vorrei fare \u00e8 provare a evidenziare quali sono secondo me le cause di fondo di questo genere di comportamenti e dare il mio piccolo contributo per contrastarle perch\u00e9 ritengo che sia questo il modo migliore per ridurre i comportamenti pi\u00f9 pericolosi in assoluto cio\u00e8 quelli involontari. Nel suo celebre testo le leggi fondamentali della stupidit\u00e0 umana il professor Cipolla come corollario alla quinta legge afferma che lo stupido \u00e8 pi\u00f9 pericoloso del bandito riassumendo proprio il senso di quanto ho cercato di spiegare fino ad ora lo stupido \u00e8 colui che agisce male ma senza rendersene conto mentre il bandito \u00e8 colui le cui azioni seppur malvagie sono ben controllate indirizzate. Ad una prima superficiale occhiata questo corollario potrebbe sembrare gi\u00e0 riassumere interamente il nocciolo del problema d'altronde noi informatici siamo abituati a questo genere di reazione a volte a torto a volte a ragione l'utonto \u00e8 proprio questo no? Quell'utente che non \u00e8 in grado di utilizzare uno strumento tecnologico non perch\u00e9 esso sia troppo complicato bens\u00ec perch\u00e9 \u00e8 lui ad essere troppo stupido per capirlo sarebbe facile considerare uno stupido colui che ha pensato di integrare gpt nel proprio business che magari richiede competenze di tutt'altro genere o di farsi difendere in tribunale da chat gpt o di chiedergli consigli di trading o altro ma quando la manifestazione di stupidit\u00e0 \u00e8 cos\u00ec su larga scala come \u00e8 accaduto e sta accadendo giorno dopo giorno con chat gpt e i suoi derivati forse \u00e8 il caso di chiedersi se si parla ancora di utonti se effettivamente \u00e8 solo di stupidit\u00e0 si tratti pu\u00f2 essere davvero la causa di tante storture ricondotta solo ed unicamente alla stupidit\u00e0 dei vari utilizzatori anche se parliamo di persone molto abili nei rispettivi campi inclini a sperimentare le novit\u00e0 e abituati ad utilizzare la tecnologia non \u00e8 che magari il problema sotto sotto risiede altrove probabilmente avrai gi\u00e0 sentito nominare la terza legge di clark che recita qualunque tecnologia sufficientemente avanzata \u00e8 indistinguibile dalla magia e se ci pensi \u00e8 vero si tratta di un concetto molto attuale che una volta chiarito addovere il significato del termine magia si adatta particolarmente a tantissime situazioni del nostro tempo tuttavia io sono anche convinto che guardare il mondo con il solo ausilio di una tale concezione della tecnologia porti a vedere il tutto attraverso un potente filtro una sorta di limite che spinge a sottovalutare altri aspetti secondo me molto importanti della questione molti fanno risalire la nascita del concetto di computer alla prima met\u00e0 del 1800 ad opera del matematico inglese charles babbage che realizz\u00f2 per primo il progetto di un calcolatore programmabile quella che lui stesso chiam\u00f2 la macchina analitica il suo progetto mai realizzato nella realt\u00e0 se non come tributo al genio molti anni dopo derivava da un altro strumento meno evoluto sempre ideato dallo stesso scienziato ma di cui egli era stato in grado di realizzare almeno un prototipo i costi per la produzione delle migliaia di ingranaggi necessari per le sue macchine e poi per il loro successivo assemblaggio era proibitivo e babbage organizzava incontri periodici nella sua residenza londinese per mostrare a nobili ed intellettuali di tutta l'inghilterra il suo prototipo al fine di cercare di creare interesse e raccogliere fondi a questi incontri nonostante vi partecipassero le persone pi\u00f9 istruite di tutto il regno e parliamo di un'epoca nella quale solo un bambino su 11 riceveva un'istruzione formale capitava spesso che qualcuno vedendo in funzione la macchina differenziale intenta ad eseguire i propri conti la definisse macchina intelligente o addirittura facesse domande del tipo ma se io inserisco i numeri errati il risultato sar\u00e0 comunque corretto ecco esistono tantissime testimonianze del fatto che ogni volta babbage ben lungi dal considerarli stupidi si affrettava a ridimensionare le impressioni e le aspettative di questi entusiasti intellettuali spiegando loro che la macchina non era n\u00e9 intelligente n\u00e9 in grado di pensare ma solo di fare determinati calcoli che venivano per essa programmati anche per via di questa sua onest\u00e0 intellettuale babbage non riusc\u00ec mai a realizzare i suoi progetti dato che non riusc\u00ec mai ad ottenere sufficienti sovvenzioni pubbliche o private che fossero oggi invece mi sembra proprio che l'atteggiamento la retorica e il marketing che girano intorno a questi strumenti di machine learning siano orientati esattamente nel verso opposto che ci vogliono far credere in qualche modo che essi siano in grado di pensare e risolvere problemi in autonomia lo stesso chat gpt se lo hai provato l'avrai notato \u00e8 implementato per dare l'impressione all'utente di stare dialogando con una sorta di intelligenza di qualche tipo usa perfino tecniche visive tipiche dei film o dei videogiochi normalmente infatti la risposta ad un prompt data da un software \u00e8 solitamente immediata viene elaborato il risultato e poi mostrato nel modo pi\u00f9 rapido possibile in chat gpt invece le parole compaiono una per volta come a dare l'impressione di stare comunicando con un'intelligenza aliena da film di fantascienza come a farci credere che stia pensando o formulando le frasi secondo me \u00e8 proprio questo atteggiamento a generare confusione nel grande pubblico soprattutto nelle persone meno tecnicamente preparate sull'argomento sono questi ed altri trucchi della stessa risma come ad esempio continuare a martellare sul termine intelligenza artificiale che fanno apparire questa tecnologia pi\u00f9 come una magia o nel caso specifico come una intelligenza invece di diffondere la conoscenza si diffonde il mito ma per come la vedo io basta scalfire la superficie del problema dissipare l'aura di trascendenza per dare a chiunque gli strumenti per capire una tecnologia non serve diventarne degli esperti ma basta capirne almeno i concetti di base e quindi oggi voglio provare a fare proprio questo voglio provare a sfatare un pochino del mito e ad intaccarne le fige partiamo subito con il dire che io non sono n\u00e9 un esperto di machine learning n\u00e9 ho avuto mai accesso a chiss\u00e0 quali informazioni riservate su chat gpt lo spunto per questo episodio mi \u00e8 stato dato da un articolo del new yorker che ti lascio in descrizione insieme con tutte le altre fonti che ho utilizzato secondo l'autore dell'articolo e anche secondo me il modo migliore per capire i concetti di base di una tecnologia \u00e8 provare ad affrontare superare almeno dal punto di vista teorico i vari ostacoli che essa pone ai suoi progettisti ovviamente noi non saremo in grado di implementare il nostro bot nella mezz'ora che durer\u00e0 questo episodio di pensieri in codice ma individuare e risolvere teoricamente i problemi ci permetter\u00e0 da una parte di contestualizzare le caratteristiche del prodotto e dall'altra di comprendere le scelte fatte da coloro che quei problemi li hanno realmente affrontati dunque come punto di partenza torniamo a ribadire che un bot come chat gpt si basa essenzialmente sull'utilizzo di un tipo di machine learning chiamato large language model che in pratica \u00e8 una rete neurale ad apprendimento automatico allenata su una quantit\u00e0 enorme di dati di fatto il bot funge da interfaccia per la rete neurale e permette di ricevere gli input dagli utenti e di restituire agli stessi output per i nostri scopi di oggi ti anticipo gi\u00e0 che non sar\u00e0 necessario capire in dettaglio come funziona una rete neurale o un' interfaccia tutto quello che faremo sar\u00e0 descrivere i vari passaggi necessari al bot per produrre una risposta a partire da una domanda e sempre per semplicit\u00e0 ci limiteremo a considerare solo le funzioni inerenti il testo ignorando tutto ci\u00f2 che riguarda le modalit\u00e0 di funzionamento di algoritmi per gestire musica immagini eccetera quindi il concetto di base \u00e8 un testo in input produce un testo in output coerente con l'input ricevuto come possiamo fare a realizzare una cosa del genere beh come prima cosa abbiamo detto di avere a disposizione una grande quantit\u00e0 di dati no proviamo innanzitutto a capire come sfruttare quelli per farlo e tanto per ribadire che questa tecnologia \u00e8 tutt'altro che nuova partiamo da un grande classico dell'informatica il testo intitolato \u00e8 mathematical theory of communication scritto da Claude Shannon che \u00e8 il matematico che per primo ha descritto la teoria della gestione dell'informazione praticamente la base dell'informatica moderna in questo paper oltre a tantissima matematica ovviamente si pu\u00f2 trovare anche la descrizione di un interessante esperimento di generazione del testo Shannon scrive nel 1948 e all'epoca non immagina le dimensioni alle quali sarebbe potuta arrivare una banca dati nel 2023 o cosa sar\u00e0 internet o ancora di quanta potenza di calcolo avremmo potuto disporre noi al giorno d'oggi quindi formula tutto il suo ragionamento considerando come base di informazioni disponibili la sua libreria personale tutto il discorso \u00e8 ovviamente in scala rispetto a quelli che sono i numeri di un moderno large language model ma nonostante ci\u00f2 tutto funziona perfettamente e come bonus lo si pu\u00f2 mettere in pratica anche senza l'ausilio di un computer basta semplicemente avere qualche libro in casa come prima cosa Shannon sceglie una parola da cui iniziare la generazione del testo e la scrive su un foglio per semplicit\u00e0 sceglie una delle parole pi\u00f9 comuni della sua lingua l'articolo a questo punto sceglie un libro a caso dalla libreria e lo apre ad una pagina sempre a caso legge il testo finch\u00e9 non arriva alla parola e a quel punto scrive sul suo foglio la prima parola che viene subito dopo che nel suo esempio \u00e8 head testa il testo sul foglio diventa quindi the head e lui ripete il processo partendo per\u00f2 questa volta dalla parola head la cerca in una pagina a caso di un libro a caso e quando la trova ricopia sul suo foglio la parola che appare subito dopo la terza parola e quindi hand e congiunzione il matematico continua cos\u00ec per un po e alla fine arriva a formulare la frase the head and in frontal attack on an english writer that the character of this point is therefore another method e ok la frase in s\u00e9 non ha tantissimo senso sono d'accordo ma l'algoritmo messo a punto \u00e8 un'ottima base da cui possiamo partire noi per realizzare il nostro semplice llm casalingo per migliorare la ricerca del testo generato possiamo usare un semplice trucco che pur rendendo un po pi\u00f9 complicata la ricerca ha per\u00f2 il vantaggio di aumentare le probabilit\u00e0 di prelevare parole maggiormente senzate possiamo invece di ricercare una singola parola ad ogni iterazione cercarne gruppi di due tre o anche pi\u00f9 quindi se il testo che vogliamo generare deve parlare ad esempio della razza di cane pastore tedesco potremmo scrivere sul nostro foglietto le parole di partenza il pastore tedesco \u00e8 e poi scorrere le pagine del libro finch\u00e9 non troviamo esattamente le tre parole pastore tedesco \u00e8 per poi come prima prelevare la successiva e aggiungere al nostro testo proviamo dunque ad applicare il nuovo algoritmo e a scopo esemplificativo facciamo finta che la parola trovata sia una l'articolo indeterminativo femminile la frase diventerebbe il pastore tedesco \u00e8 una mentre la prossima chiave di ricerca diventerebbe tedesco \u00e8 una perch\u00e9 stiamo cercando sempre tre parole per volta procediamo cos\u00ec prendendo libri e pagine a caso per 3 4 5 10 100 volte dipende da quanto vogliamo che il nostro testo sia lungo con quest'altra modifica applicata all'algoritmo l'attenenza delle parole fra loro \u00e8 dunque aumentata ma scommetto gi\u00e0 che starai iniziando ad intuire che per ottenere dei risultati decenti serve una quantit\u00e0 di libri quindi una base dati molto grande se avessimo infatti pochi libri considerando la complessit\u00e0 delle nuove chiavi di ricerca finiremmo per capitare sempre sulle stesse pagine e quindi automaticamente ci troveremmo a ricopiare pi\u00f9 o meno pedissequamente il testo di un certo libro oppure nella peggiore delle ipotesi potremmo non trovare nessun gruppo di parole che soddisfi la ricerca e in tal caso dovremmo semplicemente rinunciare ma anche cos\u00ec con molti libri a disposizione resta comunque un problema di fondo certi gruppi di parole possono portare a ricercare nell'intero database senza dare risultati quindi per produrre noi un algoritmo robusto ci serve di inventarci una strategia che ci eviti di andare a comporre delle chiavi di ricerca troppo insolite o impossibili da trovare per ampliare il ventaglio di possibili risultati allora cambiamo leggermente il nostro approccio innanzitutto passiamo dal cercare esattamente un gruppo di parole al cercare quelle stesse parole in ordine sparso all'interno di gruppetti poco grandi in pratica in questo modo riusciamo ad individuare anche le chiavi di ricerca che somigliano alla nostra non per forza solo quelle identiche inoltre invece di accodare immediatamente la parola al nostro testo appena incontriamo un risultato della nostra ricerca annotiamola da qualche parte poi continuiamo a cercare la stessa chiave in altri libri o pagine e ogni volta che incontriamo una parola candidata ad entrare a far parte del nostro testo annotiamola insieme alle altre alla fine ovviamente otterremo non pi\u00f9 una sola parola ma una lista di candidate e per scegliere fra queste quale sia la pi\u00f9 adatta possiamo allora predisporre un sistema di classifica basato su dei voti che daremo ad ogni parola banalmente quella con il voto pi\u00f9 alto verr\u00e0 selezionata per entrare a far parte del testo che stiamo generando il voto pu\u00f2 essere calcolato in base ai fattori che pi\u00f9 riteniamo appropriati come ad esempio il numero di volte in cui la parola appare nella lista o la quantit\u00e0 di parole che la precedono o la seguono fino al punto il numero di pagina in cui \u00e8 stata trovata il numero di recensioni positive che il libro ha su amazon qualsiasi criterio o insieme di criteri che vogliamo insomma una volta trasformata la ricerca diretta in un sistema di votazione otteniamo ben due vantaggi rispetto all'algoritmo precedente il primo consiste nell'eliminare le ricerche che non diano risultati che \u00e8 appunto il problema da cui siamo partiti il bacino di scelta infatti riduce la componente di casualit\u00e0 permettendo di evitare di selezionare parole poco adatte utilizzate in modi inconsueti o poco comuni in pi\u00f9 per\u00f2 otteniamo anche un secondo vantaggio che ci apre un nuovo orizzonte di possibilit\u00e0 le regole di votazione che abbiamo aggiunto infatti ci permettono di applicare le pi\u00f9 disparate regolazioni al nostro motore di ricerca cambiare le regole ci permetter\u00e0 di cambiare il risultato di poco o di tanto a seconda delle necessit\u00e0 se ad esempio prediligeremo regole che si basano su un criterio di autorevolezza dei testi in cui cerchiamo il risultato sar\u00e0 di maggiore attendibilit\u00e0 mentre se prediligeremo testi pi\u00f9 antichi il linguaggio sar\u00e0 pi\u00f9 arcaico e cos\u00ec via siamo dunque giunti a saper generare dei testi in linguaggio naturale partendo da un gruppo di parole e attenendoci ad una serie di indicazioni o regole ma quello che vogliamo fare in realt\u00e0 non \u00e8 solo creare un software in grado di ciarlare all'infinito il nostro scopo \u00e8 programmare un bot che dialoghi con il proprio utente seguendo il classico approccio botta e risposta quindi dobbiamo fare in modo che il software sia in grado di capire ci\u00f2 che gli viene detto anche se qui capire \u00e8 fra due virgolette belle grandi nel nostro caso infatti capire vuol dire in realt\u00e0 selezionare semplicemente le parole pi\u00f9 importanti della richiesta ed utilizzarle come gruppo di partenza per indirizzare la ricerca cos\u00ec come l'abbiamo descritta fino ad ora valutare l'input in questo modo non solo ci permetter\u00e0 di creare testi che suonino naturali ma che siano anche sensati rispetto a quanto richiesto dall'utente per effettuare questa scrematura esistono vari metodi e tanto per capire il concetto te ne descrivo uno dei pi\u00f9 semplici che ho visto anche applicare durante un workshop qualche mese fa anche se nella realt\u00e0 quello di chat gpt \u00e8 pi\u00f9 complesso di cos\u00ec il processo consiste in pratica nell'utilizzare un dizionario che cataloga le parole di una lingua in base all'utilit\u00e0 le parole meno utili come ad esempio gli articoli vengono scartate una dopo l'altra fino a raggiungere una frase spesso sgrammaticata ma questo non importa che soddisfi per\u00f2 un certo livello di importanza una volta effettuata questa operazione possiamo considerare il risultato come input di partenza per la nostra generazione del testo \u00e8 controintuitivo ma funziona il nostro bot sembrerebbe a questo punto completo almeno da un punto di vista teorico ma se hai provato ad utilizzare chat gpt o hai letto un po di esperimenti fatti da altri saprai certamente che esso \u00e8 in grado di fare molto di pi\u00f9 che rispondere con un testo sensato ad una domanda \u00e8 in grado di eseguire compiti come scrivere poesie rispondere in altre lingue formulare una lista di istruzioni enunciandole come farebbe dante nella divina commedia e tante altre cose simili sono questi forse gli aspetti che pi\u00f9 di tutti hanno tratto in inganno tante persone dando l'impressione che per svolgere compiti del genere sia necessaria una sorta di intelligenza simile a quella umana ma in verit\u00e0 per raggiungere un tale livello di complessit\u00e0 al nostro bot non serve pensare non gli serve ragionare n\u00e9 inventare alcunch\u00e9 basta solo che noi aumentiamo il numero di testi a cui attingere da una parte e il numero di regole del sistema di voting dall'altra per il numero di testi beh openai sfruttando un super elaboratore realizzato appositamente da microsoft ha potuto dare in passo a chat gpt una quantit\u00e0 enorme di dati non che pare tutto il web disponibile fino a qualche mese fa mentre noi dal canto nostro per il nostro esperimento mentale dobbiamo semplicemente immaginare di avere a disposizione una biblioteca che comprenda gran parte dello scibile umano cartaceo o digitale che sia per il numero di regole invece il discorso \u00e8 un po pi\u00f9 complesso sarebbe umanamente impossibile progettare tutte quelle necessarie a coprire ogni possibile combinazione di richieste potrebbe sempre arrivare qualcuno a chiedere di progettare un codice di leggi per una societ\u00e0 in cui le giraffe sono la specie pi\u00f9 evoluta e dominante ad esempio quindi appare subito chiaro che stilare a mano un catalogo completo di regole \u00e8 praticamente irrealizzabile considerando che la loro quantit\u00e0 sarebbe enorme e la complessit\u00e0 di una singola regola potrebbe anche essere notevole ma la soluzione \u00e8 in realt\u00e0 molto pi\u00f9 semplice di quanto possa sembrare serve infatti un bel po di potenza di calcolo ma si pu\u00f2 fare in modo che il bot generi da solo tutte le regole di cui ha bisogno il concetto \u00e8 noto come auto apprendimento non \u00e8 nulla di nuovo nel campo dei large language model e supergio funziona in questo modo si mette a lavorare un sistema su un gruppo di regole presso che casuali e utilizzando una selezione di testi dalla base dati si fa in modo che il sistema corregga poco a poco le regole so che sembra impossibile ma facciamo un semplice esempio prendiamo la prima frase della divina commedia che tutti conosciamo che nel mezzo del cammin di nostra vita mi ritrovai per una selva oscura che la dritta via era smarrita l'idea \u00e8 quella di provare a cercare le parole della frase ad esempio cercando nel cammin di nostra ci aspetteremo di individuare la parola vita ma con le regole casuali impostate inizialmente immaginiamo che il nostro llm tiri fuori per qualche motivo la parola nonna chiss\u00e0 da quale testo a questo punto essendo in fase di auto apprendimento l'algoritmo confronter\u00e0 automaticamente la risposta nonna con la parola vita che sa essere quella giusta si accorger\u00e0 che le due non coincidono e che quindi la ricerca ha prodotto un risultato sbagliato e come conseguenza cambier\u00e0 leggermente alcune regole e riprover\u00e0 andr\u00e0 avanti cos\u00ec a provare e riprovare per centinaia di volte finch\u00e9 la parola che viene fuori dalla ricerca non sar\u00e0 effettivamente vita ripetendo questa operazione per un numero sufficiente di volte su un numero sufficiente di esempi dove sufficiente vuol dire milioni o addirittura miliardi il catalogo delle regole diverr\u00e0 sempre pi\u00f9 grande e accurato e nel momento in cui noi chiederemo al nostro bot di scrivere la ricetta della carbonara in terzine dantesche lui sar\u00e0 in grado di selezionare una serie di parole che si adattino a rispondere alla nostra domanda. Infine giuro \u00e8 l'ultimo passaggio abbiamo finito dobbiamo mettere ora tutto insieme e ricapitolare il processo. Il nostro bot riceve un testo in input e lo prepara facendolo passare attraverso una rete neurale che come una versione potentissima dei dizionari menzionati prima seleziona le parole pi\u00f9 importanti assegnando a ciascuna un valore di importanza appunto un peso una volta ottenuto questo elenco di parole pesate esso viene utilizzato per avviare una ricerca nel large language model che grazie ai pesi riesce anche a selezionare quali regole far prevalere durante l'esecuzione. Al termine di tutto questo processo la ricerca produce una parola questa parola viene aggiunta al testo in input e tutto il giro ricomincia da capo considerando l'elenco aggiornato ad ogni iterazione il testo diventa pi\u00f9 lungo di una parola finch\u00e9 non viene generato un testo di risposta con le caratteristiche richieste. Chiaramente ho dovuto sorvolare su tanti aspetti e semplificarne altri ma tutto sommato a questo punto se mi sono spiegato a dovere dovrebbe essere chiaro un fatto abbastanza importante e cio\u00e8 che un bot come chat gpt o in generale un llm come gpt o bardo quello che sia non crea proprio nulla semplicemente imita \u00e8 di fatto un selezionatore di parole su base statistica molto grande molto potente ma niente pi\u00f9 di questo copia manipola e unisce testi che gi\u00e0 esistono non \u00e8 minimamente in grado di pensare o di formulare idee ma nemmeno di capire il senso dei testi che riceve in input o di quelli che genera in output ed \u00e8 questo forse il punto cruciale di tutto l'episodio per come \u00e8 stato ampiamente descritto per come \u00e8 stato posto in termini grafici e per come \u00e8 stato pubblicizzato e diffuso chat gpt trasmette un'enorme sicurezza la sicurezza che trasmette una persona molto intelligente ed esperta dell'argomento di cui sta parlando ma la verit\u00e0 \u00e8 che si tratta solamente di una facciata una bugia sorretta unicamente dal fatto che statisticamente molto spesso una parola ne segue un'altra rosso di sera ecco se hai pensato bel tempo si spera hai applicato lo stesso principio ho voluto fare tutto questo discorso e provare a descrivere come funziona il sistema gpt perch\u00e9 ritengo importante che chi ci ha e ci avr\u00e0 a che fare in qualche modo tenga sempre bene a mente i suoi limiti viviamo in un periodo storico molto importante stiamo attraversando un momento fantastico per ci\u00f2 che riguarda il progresso tecnologico anche e soprattutto nel campo del machine learning fino a pochi anni fa mancavano gli strumenti hardware ma ora ci sono le risorse in termini di ricerca quantit\u00e0 di dati addestramento e potenza di calcolo non oso neanche immaginare cosa accadr\u00e0 tra dieci anni ma \u00e8 proprio per questo motivo che dobbiamo essere consapevoli questi llm stanno venendo integrati in moltissimi strumenti che utilizziamo anche noi ogni giorno e che utilizzano le persone che prendono le decisioni pertanto dobbiamo abituarci tutti ad usarli correttamente il prima possibile \u00e8 questo il momento di porci le domande giuste come utenti di iniziare a sviluppare i giusti anticorpi altrimenti ci troveremo catapultati in un mondo che non capiremo come funziona e di cui non sappiamo utilizzare correttamente gli oggetti le applicazioni reali gi\u00e0 si vedono microsoft sta correndo ad integrare gpt nel suo motore di ricerca bing in office 365 google fa lo stesso con bard in gmail nella sua suite da ufficio e in realt\u00e0 pare anche che i risultati siano molto incoraggianti perch\u00e9 no? noi per\u00f2 dobbiamo evitare di abbandonarci alla pigrizia ed accontentarci immediatamente di delegare le nostre decisioni a questi sistemi dobbiamo capire e ricordare che chiss\u00e0 quello che sta facendo siamo sempre noi bard o gpt per quanto possano diventare sofisticati almeno per ora non hanno idea di quello che fanno e per i fini per i quali sono stati pensati in effetti nemmeno \u00e8 importante che lo capiscano per tutti questi motivi usarli come base di partenza per qualcosa pu\u00f2 rivelarsi veramente utile in termini di produttivit\u00e0 di comodit\u00e0 eccetera ma prendere per buone le loro creazioni senza valutarle prima attentamente beh questo potrebbe rivelarsi una follia bene anche oggi l'episodio \u00e8 giunto al termine io non ho pi\u00f9 voce ma spero di averti portato come al solito un contenuto interessante e spero anche di averlo spiegato in maniera sufficientemente chiara perch\u00e9 l'argomento \u00e8 bel lungi dall'essere semplice prima di chiudere come ormai di consuetudine ringrazio edoardo e carlo per la loro donazione mensile e se anche tu apprezzi quello che faccio ti invito a fare come loro e dimostrarlo concretamente ricorda nessuna cifra \u00e8 troppo bassa e puoi star certo che verr\u00e0 utilizzata per migliorare questo progetto la verit\u00e0 \u00e8 che io ho tante idee ma ho anche capito che non posso fare tutto da solo ti anticipo gi\u00e0 che il primo obiettivo a cui sto lavorando \u00e8 quello di eliminare la pubblicit\u00e0 per rimuovere il tracciamento la profilazione ma un po di supporto \u00e8 indispensabile sul sito pensieriincodice.it trovi tutti i link utili per donazioni affiliazioni gruppo e canale telegram eccetera a proposito di telegram l'ingresso nel gruppo \u00e8 impostato su autorizzazione perch\u00e9 purtroppo su telegram c'\u00e8 un serio problema di bot ti consiglio quindi di scrivermi se vuoi entrare per velocizzare le procedure di verifica mi trovi facilmente cercando chiocciola valerio galano direttamente nella casella di ricerca telegram infine non dimenticare di condividere l'episodio con amici parenti gruppi eccetera come al solito far crescere gli ascoltatori \u00e8 sempre l'obiettivo primario e a te non costa nulla grazie dunque per aver ascoltato fin qui grazie alla mia voce per aver retto fino alla fine ci sentiamo ad un prossimo episodio e non dimenticare mai che un informatico risolve problemi a volte anche usando il computer", "segments": [{"id": 1, "seek": 2476, "start": 0.0, "end": 5.64, "text": " Sono passati ormai quasi sei mesi da quando si \u00e8 scatenato l'enorme interesse di massa", "tokens": [50364, 48344, 1320, 6908, 420, 76, 1301, 20954, 10842, 3813, 72, 1120, 7770, 1511, 4873, 795, 7186, 2513, 287, 6, 268, 687, 68, 728, 7357, 1026, 26689, 50646], "temperature": 0.0, "avg_logprob": -0.17250503839985018, "compression_ratio": 1.5294117647058822, "no_speech_prob": 0.00243377685546875, "words": null}, {"id": 2, "seek": 2476, "start": 5.64, "end": 12.24, "text": " per ChatGPT e le sue innumerevoli applicazioni e qui su Pensieri in Codice la vita \u00e8 trascorsa", "tokens": [50646, 680, 27503, 38, 47, 51, 308, 476, 20416, 7714, 449, 323, 85, 9384, 2580, 27569, 308, 1956, 459, 45035, 45980, 294, 383, 378, 573, 635, 32712, 4873, 504, 4806, 38822, 50976], "temperature": 0.0, "avg_logprob": -0.17250503839985018, "compression_ratio": 1.5294117647058822, "no_speech_prob": 0.00243377685546875, "words": null}, {"id": 3, "seek": 2476, "start": 12.24, "end": 18.12, "text": " serena e tranquilla nonostante tutto il tumulto e l'entusiasmo che imperversava all'esterno.", "tokens": [50976, 816, 4118, 308, 17640, 5291, 2107, 555, 2879, 23048, 1930, 13102, 723, 78, 308, 287, 6, 317, 301, 4609, 3280, 947, 10100, 840, 4061, 439, 6, 377, 1248, 78, 13, 51270], "temperature": 0.0, "avg_logprob": -0.17250503839985018, "compression_ratio": 1.5294117647058822, "no_speech_prob": 0.00243377685546875, "words": null}, {"id": 4, "seek": 2476, "start": 18.12, "end": 24.76, "text": " Ora per\u00f2 che il clamore iniziale \u00e8 un po' scemato, che il fumo del sensazionalismo ha", "tokens": [51270, 43672, 12673, 947, 1930, 34112, 418, 294, 590, 25051, 4873, 517, 714, 6, 262, 384, 76, 2513, 11, 947, 1930, 283, 40904, 1103, 2923, 921, 1966, 6882, 324, 51602], "temperature": 0.0, "avg_logprob": -0.17250503839985018, "compression_ratio": 1.5294117647058822, "no_speech_prob": 0.00243377685546875, "words": null}, {"id": 5, "seek": 5316, "start": 24.76, "end": 31.44, "text": " iniziato un po' a diradarsi direi che \u00e8 arrivato anche per noi il momento di unirci alla festa", "tokens": [50364, 294, 24300, 2513, 517, 714, 6, 257, 4746, 345, 32742, 1264, 72, 947, 4873, 30697, 2513, 11585, 680, 22447, 1930, 9333, 1026, 517, 347, 537, 11591, 48080, 50698], "temperature": 0.0, "avg_logprob": -0.20593398206689384, "compression_ratio": 1.4666666666666666, "no_speech_prob": 0.1728515625, "words": null}, {"id": 6, "seek": 5316, "start": 31.44, "end": 41.68000000000001, "text": " ovviamente nel nostro stile usando la testa e con elegante ritardo. Benvenuti su Pensieri", "tokens": [50698, 14187, 23347, 15373, 35779, 342, 794, 29798, 635, 1500, 64, 308, 416, 14459, 2879, 11289, 12850, 13, 3964, 553, 29161, 459, 45035, 45980, 51210], "temperature": 0.0, "avg_logprob": -0.20593398206689384, "compression_ratio": 1.4666666666666666, "no_speech_prob": 0.1728515625, "words": null}, {"id": 7, "seek": 5316, "start": 41.68000000000001, "end": 53.160000000000004, "text": " in Codice il podcast dove si ragiona da informatici con Valerio Galano. Nel caso tu abbia vissuto su", "tokens": [51210, 294, 383, 378, 573, 1930, 7367, 23287, 1511, 17539, 21758, 1120, 1356, 2399, 72, 416, 7188, 260, 1004, 7336, 3730, 13, 426, 338, 9666, 2604, 16903, 654, 371, 891, 8262, 459, 51784], "temperature": 0.0, "avg_logprob": -0.20593398206689384, "compression_ratio": 1.4666666666666666, "no_speech_prob": 0.1728515625, "words": null}, {"id": 8, "seek": 7928, "start": 53.160000000000004, "end": 59.84, "text": " un eremo o nel mezzo dell'oceano pacifico negli ultimi sei mesi devi sapere che ChatGPT \u00e8 un", "tokens": [50364, 517, 25022, 3280, 277, 15373, 385, 35130, 19781, 6, 78, 384, 3730, 15165, 1089, 78, 2485, 2081, 3725, 10121, 10842, 3813, 72, 31219, 18985, 323, 947, 27503, 38, 47, 51, 4873, 517, 50698], "temperature": 0.0, "avg_logprob": -0.20815678572250626, "compression_ratio": 1.5737704918032787, "no_speech_prob": 0.0021152496337890625, "words": null}, {"id": 9, "seek": 7928, "start": 59.84, "end": 65.88000000000001, "text": " tipo particolare di chatbot basato su quella che ad oggi in tanti ancora si ostinano a chiamare", "tokens": [50698, 9746, 1276, 43141, 1026, 5081, 18870, 987, 2513, 459, 32234, 947, 614, 34768, 294, 256, 11520, 30656, 1511, 32946, 259, 3730, 257, 417, 2918, 543, 51000], "temperature": 0.0, "avg_logprob": -0.20815678572250626, "compression_ratio": 1.5737704918032787, "no_speech_prob": 0.0021152496337890625, "words": null}, {"id": 10, "seek": 7928, "start": 65.88000000000001, "end": 72.12, "text": " intelligenza artificiale. Gli utenti di questo software infatti possono scrivere frasi o domande", "tokens": [51000, 4359, 3213, 2394, 11677, 68, 13, 460, 2081, 2839, 23012, 1026, 10263, 4722, 1536, 21515, 43857, 5545, 5887, 431, 8483, 277, 3285, 11123, 51312], "temperature": 0.0, "avg_logprob": -0.20815678572250626, "compression_ratio": 1.5737704918032787, "no_speech_prob": 0.0021152496337890625, "words": null}, {"id": 11, "seek": 7928, "start": 72.12, "end": 79.28, "text": " di ogni genere ed il bot risponde un po' come ci si aspetterebbe da un'entit\u00e0 intelligente ma in", "tokens": [51312, 1026, 33189, 41553, 1257, 1930, 10592, 2253, 79, 7259, 517, 714, 6, 808, 6983, 1511, 16817, 3093, 323, 39042, 1120, 517, 6, 317, 12445, 5613, 1576, 463, 294, 51670], "temperature": 0.0, "avg_logprob": -0.20815678572250626, "compression_ratio": 1.5737704918032787, "no_speech_prob": 0.0021152496337890625, "words": null}, {"id": 12, "seek": 10692, "start": 79.36, "end": 86.8, "text": " realt\u00e0 ChatGPT \u00e8 di fatto un'interfaccia realizzata per chattare con un tipo particolare di applicazione", "tokens": [50368, 47512, 27503, 38, 47, 51, 4873, 1026, 23228, 517, 6, 5106, 69, 326, 2755, 957, 8072, 3274, 680, 417, 1591, 543, 416, 517, 9746, 1276, 43141, 1026, 2580, 12928, 50740], "temperature": 0.0, "avg_logprob": -0.22704645806709223, "compression_ratio": 1.5426356589147288, "no_speech_prob": 0.039031982421875, "words": null}, {"id": 13, "seek": 10692, "start": 86.8, "end": 93.56, "text": " di machine learning che prende il nome di Large Language Model. Questo specifico LLM, quello che", "tokens": [50740, 1026, 3479, 2539, 947, 9866, 68, 1930, 19003, 1026, 33092, 24445, 17105, 13, 38167, 2685, 78, 441, 43, 44, 11, 22813, 947, 51078], "temperature": 0.0, "avg_logprob": -0.22704645806709223, "compression_ratio": 1.5426356589147288, "no_speech_prob": 0.039031982421875, "words": null}, {"id": 14, "seek": 10692, "start": 93.56, "end": 101.08, "text": " fa funzionare ChatGPT intendo, \u00e8 stato battezzato dai suoi creatori GPT e non \u00e8 certo il primo del", "tokens": [51078, 2050, 49345, 313, 543, 27503, 38, 47, 51, 560, 3999, 11, 4873, 29657, 7362, 975, 4313, 2513, 38586, 459, 4869, 1428, 7386, 26039, 51, 308, 2107, 4873, 22261, 1930, 38671, 1103, 51454], "temperature": 0.0, "avg_logprob": -0.22704645806709223, "compression_ratio": 1.5426356589147288, "no_speech_prob": 0.039031982421875, "words": null}, {"id": 15, "seek": 10692, "start": 101.08, "end": 106.92, "text": " suo genere ad essere stato realizzato fino ad ora. Come vedremo a breve infatti la tecnologia", "tokens": [51454, 34197, 41553, 614, 19799, 29657, 957, 8072, 2513, 42560, 614, 33714, 13, 2492, 14267, 44172, 257, 48517, 1536, 21515, 635, 44905, 51746], "temperature": 0.0, "avg_logprob": -0.22704645806709223, "compression_ratio": 1.5426356589147288, "no_speech_prob": 0.039031982421875, "words": null}, {"id": 16, "seek": 13372, "start": 106.92, "end": 113.16, "text": " di cui stiamo parlando non \u00e8 particolarmente moderna e nemmeno esclusiva di questo bot. Ne", "tokens": [50364, 1026, 22929, 342, 7415, 971, 16201, 2107, 4873, 1276, 15276, 4082, 10494, 629, 308, 408, 2174, 5808, 4721, 3063, 5931, 1026, 10263, 10592, 13, 1734, 50676], "temperature": 0.0, "avg_logprob": -0.1922433034383825, "compression_ratio": 1.5447154471544715, "no_speech_prob": 0.0814208984375, "words": null}, {"id": 17, "seek": 13372, "start": 113.16, "end": 119.24000000000001, "text": " esistono molti e tanto per fare un nome illustre Google ha sviluppato la sua versione che ha", "tokens": [50676, 785, 468, 8957, 10739, 72, 308, 10331, 680, 11994, 517, 19003, 8490, 265, 3329, 324, 17342, 388, 10504, 2513, 635, 8233, 3037, 68, 947, 324, 50980], "temperature": 0.0, "avg_logprob": -0.1922433034383825, "compression_ratio": 1.5447154471544715, "no_speech_prob": 0.0814208984375, "words": null}, {"id": 18, "seek": 13372, "start": 119.24000000000001, "end": 126.64, "text": " chiamato BARD ma la novit\u00e0 \u00e8 che fino ad ora un lavoro di questo tipo non era mai stato applicato", "tokens": [50980, 417, 2918, 2513, 363, 13259, 463, 635, 572, 10398, 1467, 4873, 947, 42560, 614, 33714, 517, 42060, 1026, 10263, 9746, 2107, 4249, 12698, 29657, 2580, 2513, 51350], "temperature": 0.0, "avg_logprob": -0.1922433034383825, "compression_ratio": 1.5447154471544715, "no_speech_prob": 0.0814208984375, "words": null}, {"id": 19, "seek": 13372, "start": 126.64, "end": 133.72, "text": " su cos\u00ec larga scala e poi messo a disposizione degli utenti in modo cos\u00ec semplice e gratuito.", "tokens": [51350, 459, 23278, 1613, 3680, 795, 5159, 308, 19260, 2082, 78, 257, 15885, 35740, 32079, 2839, 23012, 294, 16664, 23278, 4361, 564, 573, 308, 10158, 22703, 13, 51704], "temperature": 0.0, "avg_logprob": -0.1922433034383825, "compression_ratio": 1.5447154471544715, "no_speech_prob": 0.0814208984375, "words": null}, {"id": 20, "seek": 16048, "start": 134.28, "end": 141.0, "text": " ChatGPT quindi non \u00e8 tanto il primo esempio della sua categoria quanto piuttosto il primo ad aver", "tokens": [50392, 27503, 38, 47, 51, 15727, 2107, 4873, 10331, 1930, 38671, 33627, 11618, 8233, 4847, 8172, 17820, 3895, 13478, 22756, 1930, 38671, 614, 18247, 50728], "temperature": 0.0, "avg_logprob": -0.1961309478396461, "compression_ratio": 1.5, "no_speech_prob": 0.004329681396484375, "words": null}, {"id": 21, "seek": 16048, "start": 141.0, "end": 148.04, "text": " raggiunto e colpito fortemente cos\u00ec tante persone anche al di fuori della ristretta", "tokens": [50728, 17539, 7834, 24052, 308, 1173, 79, 3528, 5009, 16288, 23278, 256, 2879, 29944, 11585, 419, 1026, 8536, 7386, 11618, 367, 468, 1505, 1328, 51080], "temperature": 0.0, "avg_logprob": -0.1961309478396461, "compression_ratio": 1.5, "no_speech_prob": 0.004329681396484375, "words": null}, {"id": 22, "seek": 16048, "start": 148.04, "end": 154.64, "text": " cerchia degli addetti ai lavori facendo parlare di s\u00e9 cos\u00ec in lungo e in largo. Realizzato", "tokens": [51080, 10146, 339, 654, 32079, 909, 12495, 9783, 20923, 7386, 1915, 3999, 13734, 543, 1026, 7910, 23278, 294, 16730, 78, 308, 294, 31245, 13, 8467, 8072, 2513, 51410], "temperature": 0.0, "avg_logprob": -0.1961309478396461, "compression_ratio": 1.5, "no_speech_prob": 0.004329681396484375, "words": null}, {"id": 23, "seek": 16048, "start": 154.64, "end": 160.48, "text": " dall'americana OpenAI il servizio \u00e8 stato mostrato al grande pubblico a fine novembre", "tokens": [51410, 43351, 6, 13530, 44864, 7238, 48698, 1930, 1658, 590, 1004, 4873, 29657, 881, 43037, 419, 8883, 1535, 11489, 78, 257, 2489, 26972, 20014, 51702], "temperature": 0.0, "avg_logprob": -0.1961309478396461, "compression_ratio": 1.5, "no_speech_prob": 0.004329681396484375, "words": null}, {"id": 24, "seek": 18920, "start": 160.6, "end": 167.0, "text": " 2022 con una versione beta per poi essere dichiarato stabile verso la fine di marzo", "tokens": [50370, 20229, 416, 2002, 3037, 68, 9861, 680, 19260, 19799, 10390, 9448, 2513, 16343, 794, 49786, 635, 2489, 1026, 1849, 4765, 50690], "temperature": 0.0, "avg_logprob": -0.20923912991648136, "compression_ratio": 1.5204918032786885, "no_speech_prob": 0.044647216796875, "words": null}, {"id": 25, "seek": 18920, "start": 167.0, "end": 174.12, "text": " di quest'anno e l'entusiasmo globale \u00e8 stato enorme in cinque giorni ha raggiunto un milione", "tokens": [50690, 1026, 866, 6, 13484, 308, 287, 6, 317, 301, 4609, 3280, 16125, 1220, 4873, 29657, 33648, 294, 6539, 1077, 36937, 72, 324, 17539, 7834, 24052, 517, 1962, 5328, 51046], "temperature": 0.0, "avg_logprob": -0.20923912991648136, "compression_ratio": 1.5204918032786885, "no_speech_prob": 0.044647216796875, "words": null}, {"id": 26, "seek": 18920, "start": 174.12, "end": 179.92, "text": " di utenti registrati e tanto per intenderci Instagram ci ha messo cinque mesi a conseguire", "tokens": [51046, 1026, 2839, 23012, 11376, 4481, 72, 308, 10331, 680, 560, 3216, 537, 5281, 6983, 324, 2082, 78, 6539, 1077, 3813, 72, 257, 12706, 621, 51336], "temperature": 0.0, "avg_logprob": -0.20923912991648136, "compression_ratio": 1.5204918032786885, "no_speech_prob": 0.044647216796875, "words": null}, {"id": 27, "seek": 18920, "start": 179.92, "end": 189.2, "text": " lo stesso obiettivo. Un LLM come GPT che di fatto \u00e8 il perno centrale di ChatGPT \u00e8 dunque un sistema", "tokens": [51336, 450, 44413, 1111, 1684, 83, 6340, 13, 1156, 441, 43, 44, 808, 26039, 51, 947, 1026, 23228, 4873, 1930, 680, 1771, 32199, 1220, 1026, 27503, 38, 47, 51, 4873, 10234, 1077, 517, 13245, 51800], "temperature": 0.0, "avg_logprob": -0.20923912991648136, "compression_ratio": 1.5204918032786885, "no_speech_prob": 0.044647216796875, "words": null}, {"id": 28, "seek": 21464, "start": 189.20000000000002, "end": 195.04000000000002, "text": " in grado di accettare gli input pi\u00f9 disparati e sulla base di questi rispondere a tono in", "tokens": [50364, 294, 677, 1573, 1026, 1317, 3093, 543, 17161, 4846, 10589, 14548, 6908, 308, 33625, 3096, 1026, 29729, 2253, 79, 33447, 257, 2952, 78, 294, 50656], "temperature": 0.0, "avg_logprob": -0.1654647374764467, "compression_ratio": 1.526530612244898, "no_speech_prob": 0.0001055598258972168, "words": null}, {"id": 29, "seek": 21464, "start": 195.04000000000002, "end": 201.44000000000003, "text": " linguaggio umano pertanto la possibilit\u00e0 di interagire con esso attraverso un semplice", "tokens": [50656, 21766, 30763, 1105, 3730, 13269, 5857, 635, 24145, 12445, 1026, 728, 559, 621, 416, 2097, 78, 951, 424, 331, 539, 517, 4361, 564, 573, 50976], "temperature": 0.0, "avg_logprob": -0.1654647374764467, "compression_ratio": 1.526530612244898, "no_speech_prob": 0.0001055598258972168, "words": null}, {"id": 30, "seek": 21464, "start": 201.44000000000003, "end": 208.44000000000003, "text": " meccanismo di chat ha giustamente scatenato un entusiasmo notevole. Inoltre GPT \u00e8 stato reso", "tokens": [50976, 385, 1914, 282, 6882, 1026, 5081, 324, 1735, 381, 3439, 795, 7186, 2513, 517, 948, 301, 4609, 3280, 3637, 3080, 306, 13, 682, 401, 3599, 26039, 51, 4873, 29657, 319, 539, 51326], "temperature": 0.0, "avg_logprob": -0.1654647374764467, "compression_ratio": 1.526530612244898, "no_speech_prob": 0.0001055598258972168, "words": null}, {"id": 31, "seek": 21464, "start": 208.44000000000003, "end": 214.64000000000001, "text": " disponibile anche tramite API cio\u00e8 quei meccanismi dedicati agli sviluppatori e utilizzabili in modo", "tokens": [51326, 23311, 30898, 11585, 25749, 642, 9362, 41827, 631, 72, 385, 1914, 282, 1434, 72, 37071, 6908, 623, 2081, 17342, 388, 10504, 39842, 308, 40355, 455, 2312, 294, 16664, 51636], "temperature": 0.0, "avg_logprob": -0.1654647374764467, "compression_ratio": 1.526530612244898, "no_speech_prob": 0.0001055598258972168, "words": null}, {"id": 32, "seek": 24360, "start": 214.64000000000001, "end": 221.8, "text": " programmatico e ci\u00f2 ha permesso a tanti di integrarlo all'interno di altri servizi o software.", "tokens": [50364, 1461, 25915, 78, 308, 6983, 4293, 324, 4784, 5557, 257, 256, 11520, 1026, 3572, 19457, 439, 6, 5106, 1771, 1026, 33707, 1658, 24300, 277, 4722, 13, 50722], "temperature": 0.0, "avg_logprob": -0.17855234533293635, "compression_ratio": 1.63135593220339, "no_speech_prob": 0.08624267578125, "words": null}, {"id": 33, "seek": 24360, "start": 221.8, "end": 228.0, "text": " Quindi fermiamoci un secondo e facciamo un attimo ordine nei termini che in questo episodio ci", "tokens": [50722, 32534, 26558, 7415, 537, 517, 41601, 308, 1915, 42052, 517, 951, 6934, 4792, 533, 34517, 1433, 3812, 947, 294, 10263, 39200, 1004, 6983, 51032], "temperature": 0.0, "avg_logprob": -0.17855234533293635, "compression_ratio": 1.63135593220339, "no_speech_prob": 0.08624267578125, "words": null}, {"id": 34, "seek": 24360, "start": 228.0, "end": 235.68, "text": " serviranno. Dunque GPT \u00e8 il motore, ChatGPT \u00e8 l'interfaccia che permette di chattare con il", "tokens": [51032, 29463, 13484, 13, 11959, 1077, 26039, 51, 4873, 1930, 2184, 418, 11, 27503, 38, 47, 51, 4873, 287, 6, 5106, 69, 326, 2755, 947, 4784, 3007, 1026, 417, 1591, 543, 416, 1930, 51416], "temperature": 0.0, "avg_logprob": -0.17855234533293635, "compression_ratio": 1.63135593220339, "no_speech_prob": 0.08624267578125, "words": null}, {"id": 35, "seek": 24360, "start": 235.68, "end": 243.60000000000002, "text": " motore e ancora le API sono altre interfacce che permettono di utilizzare il motore attraverso altri", "tokens": [51416, 2184, 418, 308, 30656, 476, 9362, 9259, 34983, 14510, 326, 384, 947, 20696, 1756, 78, 1026, 40355, 543, 1930, 2184, 418, 951, 424, 331, 539, 33707, 51812], "temperature": 0.0, "avg_logprob": -0.17855234533293635, "compression_ratio": 1.63135593220339, "no_speech_prob": 0.08624267578125, "words": null}, {"id": 36, "seek": 27144, "start": 243.6, "end": 251.6, "text": " software. Ok? Come accennavamo poco fa quindi fin da subito ChatGPT ha stupito il mondo con le sue", "tokens": [50364, 4722, 13, 3477, 30, 2492, 1317, 268, 629, 85, 10502, 10639, 2050, 15727, 962, 1120, 1422, 3528, 27503, 38, 47, 51, 324, 342, 1010, 3528, 1930, 40499, 416, 476, 20416, 50764], "temperature": 0.0, "avg_logprob": -0.22656249309127982, "compression_ratio": 1.4827586206896552, "no_speech_prob": 0.0087127685546875, "words": null}, {"id": 37, "seek": 27144, "start": 251.6, "end": 258.04, "text": " capacit\u00e0 dialettiche, devo dire onestamente superiori anche a quelle di una certa fetta di", "tokens": [50764, 4637, 12445, 5502, 3093, 9304, 11, 49717, 1264, 322, 377, 3439, 13028, 72, 11585, 257, 29237, 1026, 2002, 44438, 15136, 1328, 1026, 51086], "temperature": 0.0, "avg_logprob": -0.22656249309127982, "compression_ratio": 1.4827586206896552, "no_speech_prob": 0.0087127685546875, "words": null}, {"id": 38, "seek": 27144, "start": 258.04, "end": 264.48, "text": " umani, ma ad ogni modo ci\u00f2 ha fatto s\u00ec che le persone iniziassero ad utilizzarlo per gli scopi", "tokens": [51086, 1105, 3782, 11, 463, 614, 33189, 16664, 6983, 4293, 324, 23228, 49267, 947, 476, 29944, 294, 24300, 640, 2032, 614, 40355, 19457, 680, 17161, 795, 404, 72, 51408], "temperature": 0.0, "avg_logprob": -0.22656249309127982, "compression_ratio": 1.4827586206896552, "no_speech_prob": 0.0087127685546875, "words": null}, {"id": 39, "seek": 27144, "start": 264.48, "end": 271.44, "text": " pi\u00f9 disparati dal semplice svago allo studio del sistema stesso fino ad applicazioni professionali", "tokens": [51408, 10589, 14548, 6908, 11702, 4361, 564, 573, 17342, 6442, 439, 78, 6811, 1103, 13245, 44413, 42560, 614, 2580, 27569, 4843, 72, 51756], "temperature": 0.0, "avg_logprob": -0.22656249309127982, "compression_ratio": 1.4827586206896552, "no_speech_prob": 0.0087127685546875, "words": null}, {"id": 40, "seek": 29780, "start": 272.0, "end": 277.88, "text": " e di supporto nel proprio lavoro. Data la disponibilit\u00e0 delle API poi la corsa ad", "tokens": [50392, 308, 1026, 1406, 78, 15373, 28203, 42060, 13, 11888, 635, 23311, 11607, 12445, 16485, 9362, 19260, 635, 269, 38822, 614, 50686], "temperature": 0.0, "avg_logprob": -0.21139705853134977, "compression_ratio": 1.525, "no_speech_prob": 0.06365966796875, "words": null}, {"id": 41, "seek": 29780, "start": 277.88, "end": 283.32, "text": " inventarsi un modo per sfruttare le sue grandi capacit\u00e0 \u00e8 stata ed \u00e8 tuttora a dir poco", "tokens": [50686, 7962, 32742, 517, 16664, 680, 262, 5779, 13478, 543, 476, 20416, 45155, 4637, 12445, 4873, 49554, 1257, 4873, 3672, 83, 3252, 257, 4746, 10639, 50958], "temperature": 0.0, "avg_logprob": -0.21139705853134977, "compression_ratio": 1.525, "no_speech_prob": 0.06365966796875, "words": null}, {"id": 42, "seek": 29780, "start": 283.32, "end": 291.4, "text": " roccambolesca, \u00e8 stato integrato nei pi\u00f9 disparati software e servizi e come spesso accade in questi", "tokens": [50958, 744, 1914, 2173, 7456, 496, 11, 4873, 29657, 3572, 2513, 34517, 10589, 14548, 6908, 4722, 308, 1658, 24300, 308, 808, 637, 5557, 1317, 762, 294, 29729, 51362], "temperature": 0.0, "avg_logprob": -0.21139705853134977, "compression_ratio": 1.525, "no_speech_prob": 0.06365966796875, "words": null}, {"id": 43, "seek": 29780, "start": 291.4, "end": 297.8, "text": " casi qualcuno ha quasi subito individuato un utilizzo sensato per lo strumento dando vita", "tokens": [51362, 22567, 32101, 12638, 324, 20954, 1422, 3528, 2461, 84, 2513, 517, 19906, 4765, 2923, 2513, 680, 450, 1056, 2206, 78, 29854, 32712, 51682], "temperature": 0.0, "avg_logprob": -0.21139705853134977, "compression_ratio": 1.525, "no_speech_prob": 0.06365966796875, "words": null}, {"id": 44, "seek": 32648, "start": 297.8, "end": 307.44, "text": " a sinergie proficue o a una serie di esperimenti interessanti mentre al contrario molti altri hanno", "tokens": [50364, 257, 3343, 17025, 414, 1740, 299, 622, 277, 257, 2002, 23030, 1026, 10045, 2328, 72, 12478, 11520, 49601, 419, 47642, 10739, 72, 33707, 26595, 50846], "temperature": 0.0, "avg_logprob": -0.20667614218863575, "compression_ratio": 1.6888888888888889, "no_speech_prob": 0.28076171875, "words": null}, {"id": 45, "seek": 32648, "start": 307.44, "end": 313.96000000000004, "text": " frainteso in parte o in toto la possibilit\u00e0 di questo motore e hanno prodotto storture e", "tokens": [50846, 6600, 686, 41189, 294, 6975, 277, 294, 281, 1353, 635, 24145, 12445, 1026, 10263, 2184, 418, 308, 26595, 15792, 18838, 342, 477, 540, 308, 51172], "temperature": 0.0, "avg_logprob": -0.20667614218863575, "compression_ratio": 1.6888888888888889, "no_speech_prob": 0.28076171875, "words": null}, {"id": 46, "seek": 32648, "start": 313.96000000000004, "end": 320.56, "text": " abberrazioni senza senso. Gli esempi in entrambe le direzioni sono moltissimi e sono certo che di", "tokens": [51172, 410, 607, 30695, 15273, 36208, 3151, 539, 13, 460, 2081, 32340, 72, 294, 948, 2356, 650, 476, 1264, 89, 15273, 9259, 10739, 891, 10121, 308, 9259, 22261, 947, 1026, 51502], "temperature": 0.0, "avg_logprob": -0.20667614218863575, "compression_ratio": 1.6888888888888889, "no_speech_prob": 0.28076171875, "words": null}, {"id": 47, "seek": 32648, "start": 320.56, "end": 326.48, "text": " giorno in giorno ne vedremo sempre di nuovi. Tanti hanno semplicemente deciso di giocare con", "tokens": [51502, 42202, 294, 42202, 408, 14267, 44172, 9553, 1026, 37802, 4917, 13, 314, 11520, 26595, 4361, 4770, 16288, 18206, 78, 1026, 48508, 5685, 416, 51798], "temperature": 0.0, "avg_logprob": -0.20667614218863575, "compression_ratio": 1.6888888888888889, "no_speech_prob": 0.28076171875, "words": null}, {"id": 48, "seek": 35332, "start": 326.48, "end": 333.20000000000005, "text": " chat gpt di provare i pi\u00f9 disparati esperimenti cercando di sondarne i limiti e le possibilit\u00e0", "tokens": [50364, 5081, 290, 662, 1026, 1439, 543, 741, 10589, 14548, 6908, 10045, 2328, 72, 36099, 1806, 1026, 262, 684, 289, 716, 741, 4948, 72, 308, 476, 24145, 12445, 50700], "temperature": 0.0, "avg_logprob": -0.19717919721012622, "compression_ratio": 1.648068669527897, "no_speech_prob": 0.00547027587890625, "words": null}, {"id": 49, "seek": 35332, "start": 333.20000000000005, "end": 339.92, "text": " cercando di forzarlo a funzionare in modi diversi da quelli per i quali \u00e8 stato programmato potremmo", "tokens": [50700, 36099, 1806, 1026, 337, 89, 19457, 257, 49345, 313, 543, 294, 1072, 72, 6111, 72, 1120, 631, 16320, 680, 741, 4101, 72, 4873, 29657, 37648, 2513, 1847, 265, 2174, 78, 51036], "temperature": 0.0, "avg_logprob": -0.19717919721012622, "compression_ratio": 1.648068669527897, "no_speech_prob": 0.00547027587890625, "words": null}, {"id": 50, "seek": 35332, "start": 339.92, "end": 347.24, "text": " dire hanno cercato di hackerarlo. Si tratta di comportamenti mossi da una sana curiosit\u00e0 e sono", "tokens": [51036, 1264, 26595, 36099, 2513, 1026, 38155, 19457, 13, 4909, 504, 18405, 1026, 25883, 2466, 72, 36193, 72, 1120, 2002, 15490, 13625, 12445, 308, 9259, 51402], "temperature": 0.0, "avg_logprob": -0.19717919721012622, "compression_ratio": 1.648068669527897, "no_speech_prob": 0.00547027587890625, "words": null}, {"id": 51, "seek": 35332, "start": 347.24, "end": 353.32, "text": " perfettamente comprensibili. Molti altri poi hanno capito immediatamente il fatto che se", "tokens": [51402, 13826, 3093, 3439, 715, 1095, 82, 897, 2312, 13, 39254, 72, 33707, 19260, 26595, 1410, 3528, 3640, 25354, 1930, 23228, 947, 369, 51706], "temperature": 0.0, "avg_logprob": -0.19717919721012622, "compression_ratio": 1.648068669527897, "no_speech_prob": 0.00547027587890625, "words": null}, {"id": 52, "seek": 38016, "start": 353.32, "end": 359.84, "text": " correttamente indirizzato e supervisionato questo pu\u00f2 essere di ampio supporto in varie attivit\u00e0 in", "tokens": [50364, 1181, 14313, 3439, 1016, 347, 8072, 2513, 308, 32675, 2513, 10263, 26526, 19799, 1026, 18648, 1004, 1406, 78, 294, 1374, 414, 951, 592, 12445, 294, 50690], "temperature": 0.0, "avg_logprob": -0.19031531101948507, "compression_ratio": 1.6147540983606556, "no_speech_prob": 0.062744140625, "words": null}, {"id": 53, "seek": 38016, "start": 359.84, "end": 366.28, "text": " particolare quelle creative di ricerca e catalogazione delle informazioni. Tra i soli esempi di cui mi \u00e8", "tokens": [50690, 1276, 43141, 29237, 5880, 1026, 21040, 36127, 308, 19746, 12928, 16485, 1356, 27569, 13, 5403, 741, 1404, 72, 32340, 72, 1026, 22929, 2752, 4873, 51012], "temperature": 0.0, "avg_logprob": -0.19031531101948507, "compression_ratio": 1.6147540983606556, "no_speech_prob": 0.062744140625, "words": null}, {"id": 54, "seek": 38016, "start": 366.28, "end": 372.32, "text": " capitato di leggere ho visto utenti fargli scrivere testi base per descrizioni, storie,", "tokens": [51012, 33807, 2513, 1026, 30991, 323, 1106, 17558, 2839, 23012, 1400, 41443, 5545, 5887, 1500, 72, 3096, 680, 2189, 89, 15273, 11, 5967, 414, 11, 51314], "temperature": 0.0, "avg_logprob": -0.19031531101948507, "compression_ratio": 1.6147540983606556, "no_speech_prob": 0.062744140625, "words": null}, {"id": 55, "seek": 38016, "start": 372.32, "end": 380.15999999999997, "text": " copioni, articoli, algoritmi, itinerari di viaggio senza contare chi utilizzandolo in connubio con", "tokens": [51314, 2971, 15273, 11, 15228, 9384, 11, 3501, 50017, 3057, 11, 309, 4564, 3504, 1026, 1932, 30763, 36208, 660, 543, 13228, 40355, 474, 7902, 294, 46264, 836, 1004, 416, 51706], "temperature": 0.0, "avg_logprob": -0.19031531101948507, "compression_ratio": 1.6147540983606556, "no_speech_prob": 0.062744140625, "words": null}, {"id": 56, "seek": 40768, "start": 380.20000000000005, "end": 386.44, "text": " altri strumenti simili in grado di generare ad esempio immagini, musiche o altro, ha dato vita a", "tokens": [50366, 33707, 1056, 2206, 72, 1034, 2312, 294, 677, 1573, 1026, 1337, 543, 614, 33627, 3397, 559, 3812, 11, 1038, 9304, 277, 40924, 11, 324, 46971, 32712, 257, 50678], "temperature": 0.0, "avg_logprob": -0.20390625447034835, "compression_ratio": 1.6824034334763949, "no_speech_prob": 0.129150390625, "words": null}, {"id": 57, "seek": 40768, "start": 386.44, "end": 393.20000000000005, "text": " tanti prodotti interessanti app, siti web, la redazione di guerre di rete ad esempio ha progettato", "tokens": [50678, 256, 11520, 15792, 37514, 12478, 11520, 724, 11, 1394, 72, 3670, 11, 635, 2182, 12928, 1026, 31400, 1026, 319, 975, 614, 33627, 324, 447, 847, 83, 2513, 51016], "temperature": 0.0, "avg_logprob": -0.20390625447034835, "compression_ratio": 1.6824034334763949, "no_speech_prob": 0.129150390625, "words": null}, {"id": 58, "seek": 40768, "start": 393.20000000000005, "end": 400.40000000000003, "text": " un intero gioco da tavolo in un pomeriggio. Certo intendiamoci tutti i risultati da rifinire a volte", "tokens": [51016, 517, 728, 78, 1735, 11198, 1120, 23214, 7902, 294, 517, 12991, 260, 6249, 1004, 13, 383, 13098, 19759, 7415, 537, 19822, 741, 2253, 723, 6908, 1120, 13203, 259, 621, 257, 37801, 51376], "temperature": 0.0, "avg_logprob": -0.20390625447034835, "compression_ratio": 1.6824034334763949, "no_speech_prob": 0.129150390625, "words": null}, {"id": 59, "seek": 40768, "start": 400.40000000000003, "end": 407.68, "text": " da correggere in minore o maggior parte ma in effetti quasi sempre un buon punto da cui partire", "tokens": [51376, 1120, 29731, 1615, 323, 294, 923, 418, 277, 44639, 1973, 6975, 463, 294, 1244, 12495, 20954, 9553, 517, 758, 266, 14326, 1120, 22929, 644, 621, 51740], "temperature": 0.0, "avg_logprob": -0.20390625447034835, "compression_ratio": 1.6824034334763949, "no_speech_prob": 0.129150390625, "words": null}, {"id": 60, "seek": 43616, "start": 407.68, "end": 414.08, "text": " per produrre un qualcosa. Tuttavia purtroppo c'\u00e8 stato anche chi ha pensato di usare questo", "tokens": [50364, 680, 15792, 374, 265, 517, 42400, 13, 314, 13478, 23015, 1864, 38604, 27000, 269, 6, 1462, 29657, 11585, 13228, 324, 6099, 2513, 1026, 505, 543, 10263, 50684], "temperature": 0.0, "avg_logprob": -0.18504648661810505, "compression_ratio": 1.579591836734694, "no_speech_prob": 0.07916259765625, "words": null}, {"id": 61, "seek": 43616, "start": 414.08, "end": 421.32, "text": " strumento in modi che definire discutibili \u00e8 poco. L'evidente potenza del sistema ha suscitato in", "tokens": [50684, 1056, 2206, 78, 294, 1072, 72, 947, 1561, 621, 42085, 897, 2312, 4873, 10639, 13, 441, 6, 13379, 40114, 1847, 23691, 1103, 13245, 324, 3291, 45135, 2513, 294, 51046], "temperature": 0.0, "avg_logprob": -0.18504648661810505, "compression_ratio": 1.579591836734694, "no_speech_prob": 0.07916259765625, "words": null}, {"id": 62, "seek": 43616, "start": 421.32, "end": 428.48, "text": " alcuni la spinta a cercare impieghi che generino un tornaconto personale a scapito di fattori come", "tokens": [51046, 20005, 24307, 635, 637, 16071, 257, 10146, 5685, 704, 20408, 4954, 947, 1337, 2982, 517, 10885, 326, 7556, 954, 1220, 257, 4216, 79, 3528, 1026, 283, 1591, 7386, 808, 51404], "temperature": 0.0, "avg_logprob": -0.18504648661810505, "compression_ratio": 1.579591836734694, "no_speech_prob": 0.07916259765625, "words": null}, {"id": 63, "seek": 43616, "start": 428.48, "end": 436.16, "text": " l'etica tanto per dirne una. Anche questo \u00e8 nella natura umana lo capisco ma per fortuna non di", "tokens": [51404, 287, 6, 302, 2262, 10331, 680, 4746, 716, 2002, 13, 1107, 1876, 10263, 4873, 23878, 2249, 2991, 1105, 2095, 450, 1410, 8610, 463, 680, 5009, 5051, 2107, 1026, 51788], "temperature": 0.0, "avg_logprob": -0.18504648661810505, "compression_ratio": 1.579591836734694, "no_speech_prob": 0.07916259765625, "words": null}, {"id": 64, "seek": 45988, "start": 436.16, "end": 444.24, "text": " tutti gli umani. Ma anche di questi casi si sono visti esempi di ogni tipo, progettazione di campagne", "tokens": [50364, 19822, 17161, 1105, 3782, 13, 4042, 11585, 1026, 29729, 22567, 1511, 9259, 40247, 72, 32340, 72, 1026, 33189, 9746, 11, 447, 847, 83, 12928, 1026, 2255, 13887, 50768], "temperature": 0.0, "avg_logprob": -0.2184027772810724, "compression_ratio": 1.5618556701030928, "no_speech_prob": 0.00679779052734375, "words": null}, {"id": 65, "seek": 45988, "start": 444.24, "end": 452.08000000000004, "text": " di phishing, scrittura di fake news, produzione di algoritmi con i pi\u00f9 disparati bias o pregiudizi,", "tokens": [50768, 1026, 903, 3807, 11, 5918, 593, 2991, 1026, 7592, 2583, 11, 1082, 19706, 1026, 3501, 50017, 3057, 416, 741, 10589, 14548, 6908, 12577, 277, 659, 7834, 532, 24300, 11, 51160], "temperature": 0.0, "avg_logprob": -0.2184027772810724, "compression_ratio": 1.5618556701030928, "no_speech_prob": 0.00679779052734375, "words": null}, {"id": 66, "seek": 45988, "start": 452.08000000000004, "end": 459.88, "text": " redazione di strategie di attacco per la diffusione di malware, tutte cose simpatiche insomma. Ma in", "tokens": [51160, 2182, 12928, 1026, 5464, 414, 1026, 951, 18662, 680, 635, 7593, 301, 5328, 1026, 40747, 11, 38632, 30261, 1034, 11584, 9304, 1028, 30243, 13, 4042, 294, 51550], "temperature": 0.0, "avg_logprob": -0.2184027772810724, "compression_ratio": 1.5618556701030928, "no_speech_prob": 0.00679779052734375, "words": null}, {"id": 67, "seek": 48752, "start": 460.0, "end": 466.56, "text": " tutto questo marasma a mio parere le storture peggiori sono quelle che si sono verificate e se", "tokens": [50370, 23048, 10263, 1849, 17494, 257, 29908, 971, 323, 476, 342, 477, 540, 520, 1615, 1973, 72, 9259, 29237, 947, 1511, 9259, 1306, 1089, 473, 308, 369, 50698], "temperature": 0.0, "avg_logprob": -0.2161458348510442, "compression_ratio": 1.7123287671232876, "no_speech_prob": 0.300048828125, "words": null}, {"id": 68, "seek": 48752, "start": 466.56, "end": 473.36, "text": " ne verificheranno sicuramente altre in futuro quando gli utilizzi aberranti sono derivati non", "tokens": [50698, 408, 1306, 351, 14934, 13484, 33579, 374, 3439, 34983, 294, 23953, 7770, 17161, 19906, 3992, 4340, 7541, 72, 9259, 10151, 6908, 2107, 51038], "temperature": 0.0, "avg_logprob": -0.2161458348510442, "compression_ratio": 1.7123287671232876, "no_speech_prob": 0.300048828125, "words": null}, {"id": 69, "seek": 48752, "start": 473.36, "end": 479.84, "text": " dall'intenzione di creare qualcosa di orribile quanto piuttosto dalla scarsa conoscenza e", "tokens": [51038, 43351, 6, 686, 11368, 5328, 1026, 1197, 543, 42400, 1026, 420, 2024, 794, 17820, 3895, 13478, 22756, 35566, 795, 29720, 416, 10466, 23691, 308, 51362], "temperature": 0.0, "avg_logprob": -0.2161458348510442, "compression_ratio": 1.7123287671232876, "no_speech_prob": 0.300048828125, "words": null}, {"id": 70, "seek": 48752, "start": 479.84, "end": 487.52, "text": " consapevolezza di come funzioni effettivamente lo strumento, di cosa possa e non possa fare o di", "tokens": [51362, 1014, 41153, 3080, 20336, 2394, 1026, 808, 49345, 15273, 1244, 3093, 23957, 450, 1056, 2206, 78, 11, 1026, 10163, 41564, 308, 2107, 41564, 11994, 277, 1026, 51746], "temperature": 0.0, "avg_logprob": -0.2161458348510442, "compression_ratio": 1.7123287671232876, "no_speech_prob": 0.300048828125, "words": null}, {"id": 71, "seek": 51744, "start": 487.52, "end": 494.68, "text": " quanto sia attendibile nel fare quello che gli si chiede di fare. Quello che sto cercando di dire", "tokens": [50364, 17820, 25176, 6888, 30898, 15373, 11994, 22813, 947, 17161, 1511, 417, 1091, 68, 1026, 11994, 13, 4493, 1913, 947, 22784, 36099, 1806, 1026, 1264, 50722], "temperature": 0.0, "avg_logprob": -0.2066441390428457, "compression_ratio": 1.625, "no_speech_prob": 0.0247955322265625, "words": null}, {"id": 72, "seek": 51744, "start": 494.68, "end": 501.4, "text": " \u00e8 che \u00e8 fisiologico ci sar\u00e0 sempre qualcuno che utilizza uno strumento perfini magari poco etici", "tokens": [50722, 4873, 947, 4873, 283, 8021, 1132, 2789, 6983, 41338, 9553, 32101, 12638, 947, 4976, 7176, 8526, 1056, 2206, 78, 13826, 3812, 49932, 10639, 1030, 8787, 51058], "temperature": 0.0, "avg_logprob": -0.2066441390428457, "compression_ratio": 1.625, "no_speech_prob": 0.0247955322265625, "words": null}, {"id": 73, "seek": 51744, "start": 501.4, "end": 510.03999999999996, "text": " o addirittura poco legali ma con piena intenzione e cognizione di causa. Questo fatto lo dobbiamo", "tokens": [51058, 277, 909, 347, 593, 2991, 10639, 5089, 72, 463, 416, 26274, 64, 560, 11368, 5328, 308, 11786, 35740, 1026, 23667, 13, 38167, 23228, 450, 360, 6692, 7415, 51490], "temperature": 0.0, "avg_logprob": -0.2066441390428457, "compression_ratio": 1.625, "no_speech_prob": 0.0247955322265625, "words": null}, {"id": 74, "seek": 51744, "start": 510.03999999999996, "end": 517.4399999999999, "text": " accettare e di conseguenza gestire come societ\u00e0 ma i comportamenti forse pi\u00f9 pericolosi sono", "tokens": [51490, 1317, 3093, 543, 308, 1026, 12706, 23691, 7219, 621, 808, 14051, 1467, 463, 741, 25883, 2466, 72, 337, 405, 10589, 680, 299, 401, 21521, 9259, 51860], "temperature": 0.0, "avg_logprob": -0.2066441390428457, "compression_ratio": 1.625, "no_speech_prob": 0.0247955322265625, "words": null}, {"id": 75, "seek": 54620, "start": 517.44, "end": 525.32, "text": " quelli non previsti, quelli derivati da aspetti non considerati. E cos\u00ec ad esempio una societ\u00e0", "tokens": [50364, 631, 16320, 2107, 12642, 45308, 11, 631, 16320, 10151, 6908, 1120, 16817, 12495, 2107, 1949, 6908, 13, 462, 23278, 614, 33627, 2002, 14051, 1467, 50758], "temperature": 0.0, "avg_logprob": -0.19419643096625805, "compression_ratio": 1.5673469387755101, "no_speech_prob": 0.0006666183471679688, "words": null}, {"id": 76, "seek": 54620, "start": 525.32, "end": 531.5600000000001, "text": " che gestisce un servizio di supporto psicologico online ha ben pensato di provare su un gruppo di", "tokens": [50758, 947, 7219, 49596, 517, 1658, 590, 1004, 1026, 1406, 78, 38609, 1132, 2789, 2950, 324, 3271, 6099, 2513, 1026, 1439, 543, 459, 517, 47477, 78, 1026, 51070], "temperature": 0.0, "avg_logprob": -0.19419643096625805, "compression_ratio": 1.5673469387755101, "no_speech_prob": 0.0006666183471679688, "words": null}, {"id": 77, "seek": 54620, "start": 531.5600000000001, "end": 539.08, "text": " utenti cavie a rispondere al primo livello di richieste utilizzando un bot basato su gpt senza", "tokens": [51070, 2839, 23012, 13971, 414, 257, 2253, 79, 33447, 419, 38671, 1621, 1913, 1026, 4593, 6495, 68, 40355, 1806, 517, 10592, 987, 2513, 459, 290, 662, 36208, 51446], "temperature": 0.0, "avg_logprob": -0.19419643096625805, "compression_ratio": 1.5673469387755101, "no_speech_prob": 0.0006666183471679688, "words": null}, {"id": 78, "seek": 54620, "start": 539.08, "end": 546.2, "text": " nel fare ci\u00f2 chiedersi quanto potrebbe essere dannosa una risposta potenzialmente fuori luogo", "tokens": [51446, 15373, 11994, 6983, 4293, 417, 1091, 433, 72, 17820, 1847, 39487, 19799, 3594, 6447, 2002, 2253, 79, 8638, 1847, 11368, 831, 4082, 8536, 7386, 10438, 23515, 51802], "temperature": 0.0, "avg_logprob": -0.19419643096625805, "compression_ratio": 1.5673469387755101, "no_speech_prob": 0.0006666183471679688, "words": null}, {"id": 79, "seek": 57368, "start": 546.2, "end": 552.9200000000001, "text": " data ad utenti che per la natura del servizio probabilmente sono gi\u00e0 fragili in partenza. Oppure", "tokens": [50364, 1412, 614, 2839, 23012, 947, 680, 635, 2249, 2991, 1103, 1658, 590, 1004, 31959, 4082, 9259, 30469, 9241, 2312, 294, 644, 23691, 13, 15666, 540, 50700], "temperature": 0.0, "avg_logprob": -0.2103365337332854, "compression_ratio": 1.5925925925925926, "no_speech_prob": 0.0279998779296875, "words": null}, {"id": 80, "seek": 57368, "start": 552.9200000000001, "end": 561.36, "text": " altro esempio molti che utilizzano chat gpt come motore di ricerca o compagno di discussione per", "tokens": [50700, 40924, 33627, 10739, 72, 947, 40355, 3730, 5081, 290, 662, 808, 2184, 418, 1026, 21040, 36127, 277, 715, 559, 1771, 1026, 5017, 68, 680, 51122], "temperature": 0.0, "avg_logprob": -0.2103365337332854, "compression_ratio": 1.5925925925925926, "no_speech_prob": 0.0279998779296875, "words": null}, {"id": 81, "seek": 57368, "start": 561.36, "end": 567.1600000000001, "text": " risolvere i pi\u00f9 disparati problemi hanno sistematicamente condiviso informazioni sensibili", "tokens": [51122, 2253, 401, 5887, 741, 10589, 14548, 6908, 1154, 72, 26595, 10555, 14911, 3439, 2224, 592, 19227, 1356, 27569, 2923, 897, 2312, 51412], "temperature": 0.0, "avg_logprob": -0.2103365337332854, "compression_ratio": 1.5925925925925926, "no_speech_prob": 0.0279998779296875, "words": null}, {"id": 82, "seek": 57368, "start": 567.1600000000001, "end": 573.6800000000001, "text": " personali o professionali o della propria azienda senza dal canto loro chiedersi dove queste vengano", "tokens": [51412, 2973, 72, 277, 4843, 72, 277, 11618, 2365, 4668, 7883, 30498, 36208, 11702, 393, 1353, 28810, 417, 1091, 433, 72, 23287, 35455, 6138, 35255, 51738], "temperature": 0.0, "avg_logprob": -0.2103365337332854, "compression_ratio": 1.5925925925925926, "no_speech_prob": 0.0279998779296875, "words": null}, {"id": 83, "seek": 60076, "start": 573.7600000000001, "end": 581.24, "text": " archiviate chi possa avervi accesso. Ora anche gli esempi in tal senso sarebbero tantissimi ma", "tokens": [50368, 3912, 592, 13024, 13228, 41564, 18247, 4917, 2105, 78, 13, 43672, 11585, 17161, 32340, 72, 294, 4023, 3151, 539, 38706, 65, 46659, 12095, 891, 10121, 463, 50742], "temperature": 0.0, "avg_logprob": -0.21377841247753662, "compression_ratio": 1.6375, "no_speech_prob": 0.1036376953125, "words": null}, {"id": 84, "seek": 60076, "start": 581.24, "end": 586.9200000000001, "text": " sinceramente non mi interessa in questo momento fare un elenco di storture a una sorta di bestiario", "tokens": [50742, 30220, 3439, 2107, 2752, 728, 8391, 294, 10263, 9333, 11994, 517, 806, 268, 1291, 1026, 342, 477, 540, 257, 2002, 33425, 1026, 1151, 72, 4912, 51026], "temperature": 0.0, "avg_logprob": -0.21377841247753662, "compression_ratio": 1.6375, "no_speech_prob": 0.1036376953125, "words": null}, {"id": 85, "seek": 60076, "start": 586.9200000000001, "end": 594.1600000000001, "text": " delle aberrazioni nate da gpt quello che piuttosto vorrei fare \u00e8 provare a evidenziare quali sono", "tokens": [51026, 16485, 4340, 30695, 15273, 297, 473, 1120, 290, 662, 22813, 947, 3895, 13478, 22756, 4245, 10271, 11994, 4873, 1439, 543, 257, 43699, 3992, 543, 4101, 72, 9259, 51388], "temperature": 0.0, "avg_logprob": -0.21377841247753662, "compression_ratio": 1.6375, "no_speech_prob": 0.1036376953125, "words": null}, {"id": 86, "seek": 60076, "start": 594.1600000000001, "end": 600.7600000000001, "text": " secondo me le cause di fondo di questo genere di comportamenti e dare il mio piccolo contributo per", "tokens": [51388, 41601, 385, 476, 3082, 1026, 38101, 1026, 10263, 41553, 1026, 25883, 2466, 72, 308, 8955, 1930, 29908, 13363, 46086, 4226, 8262, 680, 51718], "temperature": 0.0, "avg_logprob": -0.21377841247753662, "compression_ratio": 1.6375, "no_speech_prob": 0.1036376953125, "words": null}, {"id": 87, "seek": 62660, "start": 600.76, "end": 607.28, "text": " contrastarle perch\u00e9 ritengo che sia questo il modo migliore per ridurre i comportamenti pi\u00f9", "tokens": [50364, 8712, 36153, 14303, 11289, 30362, 947, 25176, 10263, 1930, 16664, 6186, 2081, 418, 680, 3973, 374, 265, 741, 25883, 2466, 72, 10589, 50690], "temperature": 0.0, "avg_logprob": -0.17731585513268197, "compression_ratio": 1.623931623931624, "no_speech_prob": 0.06951904296875, "words": null}, {"id": 88, "seek": 62660, "start": 607.28, "end": 613.68, "text": " pericolosi in assoluto cio\u00e8 quelli involontari. Nel suo celebre testo le leggi fondamentali della", "tokens": [50690, 680, 299, 401, 21521, 294, 1256, 2308, 78, 41827, 631, 16320, 2499, 896, 3504, 13, 426, 338, 34197, 43165, 2672, 1500, 78, 476, 476, 22771, 9557, 2466, 5103, 11618, 51010], "temperature": 0.0, "avg_logprob": -0.17731585513268197, "compression_ratio": 1.623931623931624, "no_speech_prob": 0.06951904296875, "words": null}, {"id": 89, "seek": 62660, "start": 613.68, "end": 620.12, "text": " stupidit\u00e0 umana il professor Cipolla come corollario alla quinta legge afferma che lo", "tokens": [51010, 6631, 12445, 1105, 2095, 1930, 8304, 383, 647, 27160, 808, 1181, 1833, 4912, 11591, 421, 16071, 1676, 432, 2096, 39994, 947, 450, 51332], "temperature": 0.0, "avg_logprob": -0.17731585513268197, "compression_ratio": 1.623931623931624, "no_speech_prob": 0.06951904296875, "words": null}, {"id": 90, "seek": 62660, "start": 620.12, "end": 626.6, "text": " stupido \u00e8 pi\u00f9 pericoloso del bandito riassumendo proprio il senso di quanto ho cercato di spiegare", "tokens": [51332, 342, 1010, 2925, 4873, 10589, 680, 299, 401, 9869, 1103, 4116, 3528, 19739, 640, 449, 3999, 28203, 1930, 3151, 539, 1026, 17820, 1106, 36099, 2513, 1026, 637, 20408, 543, 51656], "temperature": 0.0, "avg_logprob": -0.17731585513268197, "compression_ratio": 1.623931623931624, "no_speech_prob": 0.06951904296875, "words": null}, {"id": 91, "seek": 65492, "start": 626.6, "end": 634.44, "text": " fino ad ora lo stupido \u00e8 colui che agisce male ma senza rendersene conto mentre il bandito \u00e8 colui", "tokens": [50364, 42560, 614, 33714, 450, 342, 1010, 2925, 4873, 1173, 3077, 947, 623, 49596, 7133, 463, 36208, 6125, 433, 1450, 660, 78, 49601, 1930, 4116, 3528, 4873, 1173, 3077, 50756], "temperature": 0.0, "avg_logprob": -0.1948369518570278, "compression_ratio": 1.6198347107438016, "no_speech_prob": 0.06005859375, "words": null}, {"id": 92, "seek": 65492, "start": 634.44, "end": 642.08, "text": " le cui azioni seppur malvagie sono ben controllate indirizzate. Ad una prima superficiale occhiata", "tokens": [50756, 476, 22929, 7883, 15273, 369, 427, 374, 2806, 42586, 414, 9259, 3271, 45159, 473, 1016, 347, 8072, 473, 13, 1999, 2002, 19507, 23881, 25051, 10409, 8036, 3274, 51138], "temperature": 0.0, "avg_logprob": -0.1948369518570278, "compression_ratio": 1.6198347107438016, "no_speech_prob": 0.06005859375, "words": null}, {"id": 93, "seek": 65492, "start": 642.08, "end": 649.4, "text": " questo corollario potrebbe sembrare gi\u00e0 riassumere interamente il nocciolo del problema d'altronde noi", "tokens": [51138, 10263, 1181, 1833, 4912, 1847, 39487, 20775, 35559, 30469, 19739, 640, 449, 323, 728, 3439, 1930, 572, 66, 537, 7902, 1103, 12395, 274, 6, 3198, 81, 7259, 22447, 51504], "temperature": 0.0, "avg_logprob": -0.1948369518570278, "compression_ratio": 1.6198347107438016, "no_speech_prob": 0.06005859375, "words": null}, {"id": 94, "seek": 65492, "start": 649.4, "end": 654.9200000000001, "text": " informatici siamo abituati a questo genere di reazione a volte a torto a volte a ragione", "tokens": [51504, 1356, 2399, 72, 33459, 410, 6380, 6908, 257, 10263, 41553, 1026, 319, 12928, 257, 37801, 257, 50159, 257, 37801, 257, 17539, 5328, 51780], "temperature": 0.0, "avg_logprob": -0.1948369518570278, "compression_ratio": 1.6198347107438016, "no_speech_prob": 0.06005859375, "words": null}, {"id": 95, "seek": 68080, "start": 655.3199999999999, "end": 661.1999999999999, "text": " l'utonto \u00e8 proprio questo no? Quell'utente che non \u00e8 in grado di utilizzare uno strumento", "tokens": [50384, 287, 6, 325, 7556, 4873, 28203, 10263, 572, 30, 4493, 285, 6, 325, 1576, 947, 2107, 4873, 294, 677, 1573, 1026, 40355, 543, 8526, 1056, 2206, 78, 50678], "temperature": 0.0, "avg_logprob": -0.1927083341388015, "compression_ratio": 1.6233766233766234, "no_speech_prob": 0.0004172325134277344, "words": null}, {"id": 96, "seek": 68080, "start": 661.1999999999999, "end": 668.4799999999999, "text": " tecnologico non perch\u00e9 esso sia troppo complicato bens\u00ec perch\u00e9 \u00e8 lui ad essere troppo stupido per", "tokens": [50678, 20105, 1132, 2789, 2107, 14303, 2097, 78, 25176, 4495, 27000, 16060, 2513, 272, 694, 4749, 14303, 4873, 8783, 614, 19799, 4495, 27000, 342, 1010, 2925, 680, 51042], "temperature": 0.0, "avg_logprob": -0.1927083341388015, "compression_ratio": 1.6233766233766234, "no_speech_prob": 0.0004172325134277344, "words": null}, {"id": 97, "seek": 68080, "start": 668.4799999999999, "end": 674.9599999999999, "text": " capirlo sarebbe facile considerare uno stupido colui che ha pensato di integrare gpt nel proprio", "tokens": [51042, 1410, 347, 752, 38706, 39042, 23670, 1949, 543, 8526, 342, 1010, 2925, 1173, 3077, 947, 324, 6099, 2513, 1026, 16200, 35559, 290, 662, 15373, 28203, 51366], "temperature": 0.0, "avg_logprob": -0.1927083341388015, "compression_ratio": 1.6233766233766234, "no_speech_prob": 0.0004172325134277344, "words": null}, {"id": 98, "seek": 68080, "start": 674.9599999999999, "end": 680.8, "text": " business che magari richiede competenze di tutt'altro genere o di farsi difendere in", "tokens": [51366, 1606, 947, 49932, 4593, 1091, 68, 2850, 268, 1381, 1026, 3672, 83, 6, 47484, 41553, 277, 1026, 283, 32742, 679, 521, 323, 294, 51658], "temperature": 0.0, "avg_logprob": -0.1927083341388015, "compression_ratio": 1.6233766233766234, "no_speech_prob": 0.0004172325134277344, "words": null}, {"id": 99, "seek": 70452, "start": 680.8000000000001, "end": 689.2, "text": " tribunale da chat gpt o di chiedergli consigli di trading o altro ma quando la manifestazione di", "tokens": [50364, 15039, 409, 1220, 1120, 5081, 290, 662, 277, 1026, 417, 5653, 41443, 40233, 2081, 1026, 9529, 277, 40924, 463, 7770, 635, 10067, 12928, 1026, 50784], "temperature": 0.0, "avg_logprob": -0.1761762627055136, "compression_ratio": 1.625, "no_speech_prob": 0.306396484375, "words": null}, {"id": 100, "seek": 70452, "start": 689.2, "end": 696.08, "text": " stupidit\u00e0 \u00e8 cos\u00ec su larga scala come \u00e8 accaduto e sta accadendo giorno dopo giorno con chat gpt", "tokens": [50784, 6631, 12445, 4873, 23278, 459, 1613, 3680, 795, 5159, 808, 4873, 1317, 345, 8262, 308, 11135, 1317, 345, 3999, 42202, 35196, 42202, 416, 5081, 290, 662, 51128], "temperature": 0.0, "avg_logprob": -0.1761762627055136, "compression_ratio": 1.625, "no_speech_prob": 0.306396484375, "words": null}, {"id": 101, "seek": 70452, "start": 696.08, "end": 704.5200000000001, "text": " e i suoi derivati forse \u00e8 il caso di chiedersi se si parla ancora di utonti se effettivamente \u00e8 solo", "tokens": [51128, 308, 741, 459, 4869, 10151, 6908, 337, 405, 4873, 1930, 9666, 1026, 417, 1091, 433, 72, 369, 1511, 971, 875, 30656, 1026, 2839, 896, 72, 369, 1244, 3093, 23957, 4873, 6944, 51550], "temperature": 0.0, "avg_logprob": -0.1761762627055136, "compression_ratio": 1.625, "no_speech_prob": 0.306396484375, "words": null}, {"id": 102, "seek": 72304, "start": 704.52, "end": 711.16, "text": " di stupidit\u00e0 si tratti pu\u00f2 essere davvero la causa di tante storture ricondotta solo ed", "tokens": [50364, 1026, 6631, 12445, 1511, 504, 21515, 26526, 19799, 11753, 39332, 635, 23667, 1026, 256, 2879, 342, 477, 540, 21040, 684, 22967, 6944, 1257, 50696], "temperature": 0.0, "avg_logprob": -0.20668513035472436, "compression_ratio": 1.569060773480663, "no_speech_prob": 0.262451171875, "words": null}, {"id": 103, "seek": 72304, "start": 711.16, "end": 717.24, "text": " unicamente alla stupidit\u00e0 dei vari utilizzatori anche se parliamo di persone molto abili nei", "tokens": [50696, 517, 23653, 11591, 6631, 12445, 13874, 3034, 40355, 39842, 11585, 369, 971, 49926, 1026, 29944, 16394, 410, 2312, 34517, 51000], "temperature": 0.0, "avg_logprob": -0.20668513035472436, "compression_ratio": 1.569060773480663, "no_speech_prob": 0.262451171875, "words": null}, {"id": 104, "seek": 72304, "start": 717.24, "end": 723.04, "text": " rispettivi campi inclini a sperimentare le novit\u00e0 e abituati ad utilizzare la tecnologia non \u00e8 che", "tokens": [51000, 2253, 79, 3093, 33448, 2255, 72, 834, 5045, 72, 257, 24152, 2328, 543, 476, 572, 10398, 1467, 308, 410, 6380, 6908, 614, 40355, 543, 635, 44905, 2107, 4873, 947, 51290], "temperature": 0.0, "avg_logprob": -0.20668513035472436, "compression_ratio": 1.569060773480663, "no_speech_prob": 0.262451171875, "words": null}, {"id": 105, "seek": 74924, "start": 723.04, "end": 736.5999999999999, "text": " magari il problema sotto sotto risiede altrove probabilmente avrai gi\u00e0 sentito nominare la terza", "tokens": [50364, 49932, 1930, 12395, 43754, 43754, 2253, 1091, 68, 4955, 32467, 31959, 4082, 1305, 34554, 30469, 2279, 3528, 5369, 259, 543, 635, 1796, 2394, 51042], "temperature": 0.0, "avg_logprob": -0.17800633137739158, "compression_ratio": 1.5405405405405406, "no_speech_prob": 0.2197265625, "words": null}, {"id": 106, "seek": 74924, "start": 736.5999999999999, "end": 742.48, "text": " legge di clark che recita qualunque tecnologia sufficientemente avanzata \u00e8 indistinguibile", "tokens": [51042, 1676, 432, 1026, 596, 809, 947, 850, 2786, 4101, 409, 1077, 44905, 11563, 16288, 42444, 3274, 4873, 1016, 468, 7050, 30898, 51336], "temperature": 0.0, "avg_logprob": -0.17800633137739158, "compression_ratio": 1.5405405405405406, "no_speech_prob": 0.2197265625, "words": null}, {"id": 107, "seek": 74924, "start": 742.48, "end": 749.24, "text": " dalla magia e se ci pensi \u00e8 vero si tratta di un concetto molto attuale che una volta chiarito", "tokens": [51336, 35566, 2258, 654, 308, 369, 6983, 6099, 72, 4873, 1306, 78, 1511, 504, 18405, 1026, 517, 1588, 23778, 16394, 951, 901, 68, 947, 2002, 18765, 47454, 3528, 51674], "temperature": 0.0, "avg_logprob": -0.17800633137739158, "compression_ratio": 1.5405405405405406, "no_speech_prob": 0.2197265625, "words": null}, {"id": 108, "seek": 77548, "start": 749.24, "end": 755.44, "text": " addovere il significato del termine magia si adatta particolarmente a tantissime situazioni", "tokens": [50364, 909, 5179, 323, 1930, 3350, 2513, 1103, 1433, 533, 2258, 654, 1511, 614, 18405, 1276, 15276, 4082, 257, 12095, 891, 1312, 2054, 27569, 50674], "temperature": 0.0, "avg_logprob": -0.19658800625071235, "compression_ratio": 1.7289719626168225, "no_speech_prob": 0.1383056640625, "words": null}, {"id": 109, "seek": 77548, "start": 755.44, "end": 761.48, "text": " del nostro tempo tuttavia io sono anche convinto che guardare il mondo con il solo ausilio di una", "tokens": [50674, 1103, 35779, 8972, 3672, 83, 23015, 19785, 9259, 11585, 3754, 17246, 947, 6290, 543, 1930, 40499, 416, 1930, 6944, 3437, 388, 1004, 1026, 2002, 50976], "temperature": 0.0, "avg_logprob": -0.19658800625071235, "compression_ratio": 1.7289719626168225, "no_speech_prob": 0.1383056640625, "words": null}, {"id": 110, "seek": 77548, "start": 761.48, "end": 769.52, "text": " tale concezione della tecnologia porti a vedere il tutto attraverso un potente filtro una sorta", "tokens": [50976, 17172, 10413, 19706, 11618, 44905, 2436, 72, 257, 35373, 1930, 23048, 951, 424, 331, 539, 517, 1847, 1576, 29148, 340, 2002, 33425, 51378], "temperature": 0.0, "avg_logprob": -0.19658800625071235, "compression_ratio": 1.7289719626168225, "no_speech_prob": 0.1383056640625, "words": null}, {"id": 111, "seek": 77548, "start": 769.52, "end": 775.48, "text": " di limite che spinge a sottovalutare altri aspetti secondo me molto importanti della", "tokens": [51378, 1026, 39946, 947, 637, 8735, 257, 43754, 3337, 325, 543, 33707, 16817, 12495, 41601, 385, 16394, 1021, 72, 11618, 51676], "temperature": 0.0, "avg_logprob": -0.19658800625071235, "compression_ratio": 1.7289719626168225, "no_speech_prob": 0.1383056640625, "words": null}, {"id": 112, "seek": 80428, "start": 775.48, "end": 783.24, "text": " questione molti fanno risalire la nascita del concetto di computer alla prima met\u00e0 del 1800", "tokens": [50364, 1168, 68, 10739, 72, 283, 13484, 2253, 304, 621, 635, 297, 4806, 2786, 1103, 1588, 23778, 1026, 3820, 11591, 19507, 1131, 1467, 1103, 24327, 50752], "temperature": 0.0, "avg_logprob": -0.20016891999287648, "compression_ratio": 1.628691983122363, "no_speech_prob": 0.11114501953125, "words": null}, {"id": 113, "seek": 80428, "start": 783.24, "end": 790.32, "text": " ad opera del matematico inglese charles babbage che realizz\u00f2 per primo il progetto di un calcolatore", "tokens": [50752, 614, 22202, 1103, 3803, 14911, 78, 3957, 904, 68, 1290, 904, 7564, 9742, 947, 957, 8072, 4293, 680, 38671, 1930, 447, 847, 1353, 1026, 517, 2104, 8768, 43148, 51106], "temperature": 0.0, "avg_logprob": -0.20016891999287648, "compression_ratio": 1.628691983122363, "no_speech_prob": 0.11114501953125, "words": null}, {"id": 114, "seek": 80428, "start": 790.32, "end": 797.4, "text": " programmabile quella che lui stesso chiam\u00f2 la macchina analitica il suo progetto mai realizzato", "tokens": [51106, 37648, 33288, 32234, 947, 8783, 44413, 417, 2918, 4293, 635, 7912, 339, 1426, 2624, 270, 2262, 1930, 34197, 447, 847, 1353, 12698, 957, 8072, 2513, 51460], "temperature": 0.0, "avg_logprob": -0.20016891999287648, "compression_ratio": 1.628691983122363, "no_speech_prob": 0.11114501953125, "words": null}, {"id": 115, "seek": 80428, "start": 797.4, "end": 804.28, "text": " nella realt\u00e0 se non come tributo al genio molti anni dopo derivava da un altro strumento meno", "tokens": [51460, 23878, 47512, 369, 2107, 808, 1376, 5955, 78, 419, 1049, 1004, 10739, 72, 31164, 35196, 10151, 4061, 1120, 517, 40924, 1056, 2206, 78, 40236, 51804], "temperature": 0.0, "avg_logprob": -0.20016891999287648, "compression_ratio": 1.628691983122363, "no_speech_prob": 0.11114501953125, "words": null}, {"id": 116, "seek": 82984, "start": 804.28, "end": 810.72, "text": " evoluto sempre ideato dallo stesso scienziato ma di cui egli era stato in grado di realizzare almeno", "tokens": [50364, 1073, 2308, 78, 9553, 1153, 2513, 274, 37104, 44413, 2180, 268, 3992, 2513, 463, 1026, 22929, 24263, 2081, 4249, 29657, 294, 677, 1573, 1026, 957, 8072, 543, 419, 43232, 50686], "temperature": 0.0, "avg_logprob": -0.15557064958240674, "compression_ratio": 1.7077625570776256, "no_speech_prob": 0.01168060302734375, "words": null}, {"id": 117, "seek": 82984, "start": 810.72, "end": 816.8399999999999, "text": " un prototipo i costi per la produzione delle migliaia di ingranaggi necessari per le sue", "tokens": [50686, 517, 1742, 310, 647, 78, 741, 2063, 72, 680, 635, 1082, 19706, 16485, 6186, 14218, 654, 1026, 3957, 4257, 46893, 2688, 3504, 680, 476, 20416, 50992], "temperature": 0.0, "avg_logprob": -0.15557064958240674, "compression_ratio": 1.7077625570776256, "no_speech_prob": 0.01168060302734375, "words": null}, {"id": 118, "seek": 82984, "start": 816.8399999999999, "end": 824.56, "text": " macchine e poi per il loro successivo assemblaggio era proibitivo e babbage organizzava incontri", "tokens": [50992, 7912, 36675, 308, 19260, 680, 1930, 28810, 2245, 6340, 8438, 27298, 17862, 4249, 447, 897, 270, 6340, 308, 7564, 9742, 4645, 89, 4061, 834, 896, 470, 51378], "temperature": 0.0, "avg_logprob": -0.15557064958240674, "compression_ratio": 1.7077625570776256, "no_speech_prob": 0.01168060302734375, "words": null}, {"id": 119, "seek": 82984, "start": 824.56, "end": 829.8399999999999, "text": " periodici nella sua residenza londinese per mostrare a nobili ed intellettuali di tutta", "tokens": [51378, 2896, 8787, 23878, 8233, 725, 4380, 2394, 287, 684, 48629, 680, 881, 35559, 257, 572, 65, 2312, 1257, 4359, 3093, 901, 72, 1026, 3672, 1328, 51642], "temperature": 0.0, "avg_logprob": -0.15557064958240674, "compression_ratio": 1.7077625570776256, "no_speech_prob": 0.01168060302734375, "words": null}, {"id": 120, "seek": 85712, "start": 829.88, "end": 838.36, "text": " l'inghilterra il suo prototipo al fine di cercare di creare interesse e raccogliere fondi a questi", "tokens": [50366, 287, 6, 278, 42829, 391, 424, 1930, 34197, 1742, 310, 647, 78, 419, 2489, 1026, 10146, 5685, 1026, 1197, 543, 728, 7357, 308, 4129, 66, 664, 2081, 323, 9557, 72, 257, 29729, 50790], "temperature": 0.0, "avg_logprob": -0.16872374074799673, "compression_ratio": 1.6130434782608696, "no_speech_prob": 0.286865234375, "words": null}, {"id": 121, "seek": 85712, "start": 838.36, "end": 844.88, "text": " incontri nonostante vi partecipassero le persone pi\u00f9 istruite di tutto il regno e parliamo di", "tokens": [50790, 834, 896, 470, 2107, 555, 2879, 1932, 6975, 11371, 640, 2032, 476, 29944, 10589, 1418, 894, 642, 1026, 23048, 1930, 1121, 1771, 308, 971, 49926, 1026, 51116], "temperature": 0.0, "avg_logprob": -0.16872374074799673, "compression_ratio": 1.6130434782608696, "no_speech_prob": 0.286865234375, "words": null}, {"id": 122, "seek": 85712, "start": 844.88, "end": 851.44, "text": " un'epoca nella quale solo un bambino su 11 riceveva un'istruzione formale capitava spesso", "tokens": [51116, 517, 6, 595, 24035, 23878, 421, 1220, 6944, 517, 272, 2173, 2982, 459, 2975, 5090, 303, 2757, 517, 6, 468, 894, 19706, 1254, 1220, 33807, 4061, 637, 5557, 51444], "temperature": 0.0, "avg_logprob": -0.16872374074799673, "compression_ratio": 1.6130434782608696, "no_speech_prob": 0.286865234375, "words": null}, {"id": 123, "seek": 85712, "start": 851.44, "end": 857.12, "text": " che qualcuno vedendo in funzione la macchina differenziale intenta ad eseguire i propri", "tokens": [51444, 947, 32101, 12638, 14267, 3999, 294, 1019, 19706, 635, 7912, 339, 1426, 743, 11368, 25051, 560, 8938, 614, 785, 1146, 43612, 741, 40465, 51728], "temperature": 0.0, "avg_logprob": -0.16872374074799673, "compression_ratio": 1.6130434782608696, "no_speech_prob": 0.286865234375, "words": null}, {"id": 124, "seek": 88452, "start": 857.12, "end": 864.12, "text": " conti la definisse macchina intelligente o addirittura facesse domande del tipo ma se io", "tokens": [50364, 660, 72, 635, 1561, 7746, 7912, 339, 1426, 5613, 1576, 277, 909, 347, 593, 2991, 1915, 7357, 3285, 11123, 1103, 9746, 463, 369, 19785, 50714], "temperature": 0.0, "avg_logprob": -0.15739679391231012, "compression_ratio": 1.6271929824561404, "no_speech_prob": 0.25341796875, "words": null}, {"id": 125, "seek": 88452, "start": 864.12, "end": 870.68, "text": " inserisco i numeri errati il risultato sar\u00e0 comunque corretto ecco esistono tantissime", "tokens": [50714, 1028, 260, 8610, 741, 7866, 72, 1189, 4481, 72, 1930, 2253, 723, 2513, 41338, 45736, 1181, 1505, 1353, 11437, 1291, 785, 468, 8957, 12095, 891, 1312, 51042], "temperature": 0.0, "avg_logprob": -0.15739679391231012, "compression_ratio": 1.6271929824561404, "no_speech_prob": 0.25341796875, "words": null}, {"id": 126, "seek": 88452, "start": 870.68, "end": 878.08, "text": " testimonianze del fatto che ogni volta babbage ben lungi dal considerarli stupidi si affrettava a", "tokens": [51042, 30963, 952, 1381, 1103, 23228, 947, 33189, 18765, 7564, 9742, 3271, 16730, 72, 11702, 1949, 289, 2081, 6631, 72, 1511, 2096, 14313, 4061, 257, 51412], "temperature": 0.0, "avg_logprob": -0.15739679391231012, "compression_ratio": 1.6271929824561404, "no_speech_prob": 0.25341796875, "words": null}, {"id": 127, "seek": 88452, "start": 878.08, "end": 884.52, "text": " ridimensionare le impressioni e le aspettative di questi entusiasti intellettuali spiegando loro", "tokens": [51412, 3973, 332, 3378, 543, 476, 9995, 72, 308, 476, 16817, 3093, 1166, 1026, 29729, 948, 33016, 24080, 4359, 3093, 901, 72, 637, 20408, 1806, 28810, 51734], "temperature": 0.0, "avg_logprob": -0.15739679391231012, "compression_ratio": 1.6271929824561404, "no_speech_prob": 0.25341796875, "words": null}, {"id": 128, "seek": 91068, "start": 884.52, "end": 890.24, "text": " che la macchina non era n\u00e9 intelligente n\u00e9 in grado di pensare ma solo di fare determinati", "tokens": [50364, 947, 635, 7912, 339, 1426, 2107, 4249, 7024, 5613, 1576, 7024, 294, 677, 1573, 1026, 6099, 543, 463, 6944, 1026, 11994, 15957, 6908, 50650], "temperature": 0.0, "avg_logprob": -0.16834238430728082, "compression_ratio": 1.6652173913043478, "no_speech_prob": 0.1868896484375, "words": null}, {"id": 129, "seek": 91068, "start": 890.24, "end": 898.6, "text": " calcoli che venivano per essa programmati anche per via di questa sua onest\u00e0 intellettuale babbage", "tokens": [50650, 2104, 8768, 72, 947, 6138, 592, 3730, 680, 7208, 37648, 6908, 11585, 680, 5766, 1026, 16540, 8233, 322, 377, 1467, 4359, 3093, 901, 68, 7564, 9742, 51068], "temperature": 0.0, "avg_logprob": -0.16834238430728082, "compression_ratio": 1.6652173913043478, "no_speech_prob": 0.1868896484375, "words": null}, {"id": 130, "seek": 91068, "start": 898.6, "end": 904.24, "text": " non riusc\u00ec mai a realizzare i suoi progetti dato che non riusc\u00ec mai ad ottenere sufficienti", "tokens": [51068, 2107, 367, 4872, 66, 4749, 12698, 257, 957, 8072, 543, 741, 459, 4869, 447, 847, 7317, 46971, 947, 2107, 367, 4872, 66, 4749, 12698, 614, 4337, 1147, 323, 11563, 72, 51350], "temperature": 0.0, "avg_logprob": -0.16834238430728082, "compression_ratio": 1.6652173913043478, "no_speech_prob": 0.1868896484375, "words": null}, {"id": 131, "seek": 91068, "start": 904.24, "end": 910.68, "text": " sovvenzioni pubbliche o private che fossero oggi invece mi sembra proprio che l'atteggiamento la", "tokens": [51350, 370, 85, 553, 89, 15273, 1535, 65, 10185, 277, 4551, 947, 14090, 2032, 34768, 36344, 2752, 20775, 424, 28203, 947, 287, 6, 30466, 22771, 8824, 635, 51672], "temperature": 0.0, "avg_logprob": -0.16834238430728082, "compression_ratio": 1.6652173913043478, "no_speech_prob": 0.1868896484375, "words": null}, {"id": 132, "seek": 93780, "start": 910.6800000000001, "end": 916.2, "text": " retorica e il marketing che girano intorno a questi strumenti di machine learning siano", "tokens": [50364, 1533, 284, 2262, 308, 1930, 6370, 947, 14703, 3730, 560, 21998, 257, 29729, 1056, 2206, 72, 1026, 3479, 2539, 262, 6254, 50640], "temperature": 0.0, "avg_logprob": -0.17578124296334055, "compression_ratio": 1.6844444444444444, "no_speech_prob": 0.27734375, "words": null}, {"id": 133, "seek": 93780, "start": 916.2, "end": 923.1200000000001, "text": " orientati esattamente nel verso opposto che ci vogliono far credere in qualche modo che essi", "tokens": [50640, 8579, 6908, 785, 1591, 3439, 15373, 49786, 1458, 22756, 947, 6983, 31273, 75, 49020, 1400, 3864, 323, 294, 38737, 16664, 947, 2097, 72, 50986], "temperature": 0.0, "avg_logprob": -0.17578124296334055, "compression_ratio": 1.6844444444444444, "no_speech_prob": 0.27734375, "words": null}, {"id": 134, "seek": 93780, "start": 923.1200000000001, "end": 930.36, "text": " siano in grado di pensare e risolvere problemi in autonomia lo stesso chat gpt se lo hai provato", "tokens": [50986, 262, 6254, 294, 677, 1573, 1026, 6099, 543, 308, 2253, 401, 5887, 1154, 72, 294, 18203, 654, 450, 44413, 5081, 290, 662, 369, 450, 21822, 1439, 2513, 51348], "temperature": 0.0, "avg_logprob": -0.17578124296334055, "compression_ratio": 1.6844444444444444, "no_speech_prob": 0.27734375, "words": null}, {"id": 135, "seek": 93780, "start": 930.36, "end": 937.8000000000001, "text": " l'avrai notato \u00e8 implementato per dare l'impressione all'utente di stare dialogando con una sorta di", "tokens": [51348, 287, 6, 706, 34554, 406, 2513, 4873, 4445, 2513, 680, 8955, 287, 6, 36107, 68, 439, 6, 325, 1576, 1026, 22432, 19308, 1806, 416, 2002, 33425, 1026, 51720], "temperature": 0.0, "avg_logprob": -0.17578124296334055, "compression_ratio": 1.6844444444444444, "no_speech_prob": 0.27734375, "words": null}, {"id": 136, "seek": 96760, "start": 937.8000000000001, "end": 946.2400000000001, "text": " intelligenza di qualche tipo usa perfino tecniche visive tipiche dei film o dei videogiochi normalmente", "tokens": [50364, 4359, 3213, 2394, 1026, 38737, 9746, 29909, 13826, 2982, 20105, 9304, 1452, 488, 4125, 9304, 13874, 2007, 277, 13874, 46801, 1004, 8036, 38217, 50786], "temperature": 0.0, "avg_logprob": -0.18370752485053052, "compression_ratio": 1.649789029535865, "no_speech_prob": 0.117431640625, "words": null}, {"id": 137, "seek": 96760, "start": 946.2400000000001, "end": 953.5600000000001, "text": " infatti la risposta ad un prompt data da un software \u00e8 solitamente immediata viene elaborato il", "tokens": [50786, 1536, 21515, 635, 2253, 79, 8638, 614, 517, 12391, 1412, 1120, 517, 4722, 4873, 1404, 270, 3439, 3640, 3274, 19561, 16298, 2513, 1930, 51152], "temperature": 0.0, "avg_logprob": -0.18370752485053052, "compression_ratio": 1.649789029535865, "no_speech_prob": 0.117431640625, "words": null}, {"id": 138, "seek": 96760, "start": 953.5600000000001, "end": 960.6400000000001, "text": " risultato e poi mostrato nel modo pi\u00f9 rapido possibile in chat gpt invece le parole compaiono", "tokens": [51152, 2253, 723, 2513, 308, 19260, 881, 43037, 15373, 16664, 10589, 5099, 2925, 50184, 294, 5081, 290, 662, 36344, 476, 26783, 715, 64, 49020, 51506], "temperature": 0.0, "avg_logprob": -0.18370752485053052, "compression_ratio": 1.649789029535865, "no_speech_prob": 0.117431640625, "words": null}, {"id": 139, "seek": 96760, "start": 960.6400000000001, "end": 967.6, "text": " una per volta come a dare l'impressione di stare comunicando con un'intelligenza aliena da film", "tokens": [51506, 2002, 680, 18765, 808, 257, 8955, 287, 6, 36107, 68, 1026, 22432, 31710, 1806, 416, 517, 6, 20761, 3213, 2394, 12319, 64, 1120, 2007, 51854], "temperature": 0.0, "avg_logprob": -0.18370752485053052, "compression_ratio": 1.649789029535865, "no_speech_prob": 0.117431640625, "words": null}, {"id": 140, "seek": 99376, "start": 967.6, "end": 974.28, "text": " di fantascienza come a farci credere che stia pensando o formulando le frasi secondo me \u00e8", "tokens": [50364, 1026, 31255, 537, 23691, 808, 257, 1400, 537, 3864, 323, 947, 342, 654, 34525, 277, 49990, 1806, 476, 431, 8483, 41601, 385, 4873, 50698], "temperature": 0.0, "avg_logprob": -0.2060643517144836, "compression_ratio": 1.6752136752136753, "no_speech_prob": 0.0041351318359375, "words": null}, {"id": 141, "seek": 99376, "start": 974.28, "end": 980.44, "text": " proprio questo atteggiamento a generare confusione nel grande pubblico soprattutto nelle persone meno", "tokens": [50698, 28203, 10263, 951, 1146, 7834, 8824, 257, 1337, 543, 1497, 301, 5328, 15373, 8883, 1535, 11489, 78, 50002, 46350, 29944, 40236, 51006], "temperature": 0.0, "avg_logprob": -0.2060643517144836, "compression_ratio": 1.6752136752136753, "no_speech_prob": 0.0041351318359375, "words": null}, {"id": 142, "seek": 99376, "start": 980.44, "end": 987.28, "text": " tecnicamente preparate sull'argomento sono questi ed altri trucchi della stessa risma come ad esempio", "tokens": [51006, 535, 66, 7692, 3439, 8231, 473, 459, 285, 6, 289, 30851, 15467, 9259, 29729, 1257, 33707, 14805, 8036, 11618, 342, 8391, 367, 14795, 808, 614, 33627, 51348], "temperature": 0.0, "avg_logprob": -0.2060643517144836, "compression_ratio": 1.6752136752136753, "no_speech_prob": 0.0041351318359375, "words": null}, {"id": 143, "seek": 99376, "start": 987.28, "end": 993.76, "text": " continuare a martellare sul termine intelligenza artificiale che fanno apparire questa tecnologia", "tokens": [51348, 2993, 543, 257, 12396, 898, 543, 17603, 1433, 533, 4359, 3213, 2394, 11677, 68, 947, 283, 13484, 45914, 621, 16540, 44905, 51672], "temperature": 0.0, "avg_logprob": -0.2060643517144836, "compression_ratio": 1.6752136752136753, "no_speech_prob": 0.0041351318359375, "words": null}, {"id": 144, "seek": 102288, "start": 993.76, "end": 1001.56, "text": " pi\u00f9 come una magia o nel caso specifico come una intelligenza invece di diffondere la conoscenza", "tokens": [50364, 10589, 808, 2002, 2258, 654, 277, 15373, 9666, 2685, 78, 808, 2002, 4359, 3213, 2394, 36344, 1026, 7593, 33447, 635, 416, 10466, 23691, 50754], "temperature": 0.0, "avg_logprob": -0.18127893587505375, "compression_ratio": 1.7130044843049328, "no_speech_prob": 0.1363525390625, "words": null}, {"id": 145, "seek": 102288, "start": 1001.56, "end": 1009.56, "text": " si diffonde il mito ma per come la vedo io basta scalfire la superficie del problema dissipare", "tokens": [50754, 1511, 7593, 7259, 1930, 2194, 78, 463, 680, 808, 635, 14267, 78, 19785, 45282, 795, 1678, 621, 635, 23881, 414, 1103, 12395, 29544, 543, 51154], "temperature": 0.0, "avg_logprob": -0.18127893587505375, "compression_ratio": 1.7130044843049328, "no_speech_prob": 0.1363525390625, "words": null}, {"id": 146, "seek": 102288, "start": 1009.56, "end": 1015.4399999999999, "text": " l'aura di trascendenza per dare a chiunque gli strumenti per capire una tecnologia non serve", "tokens": [51154, 287, 6, 64, 2991, 1026, 504, 4806, 8896, 2394, 680, 8955, 257, 13228, 409, 1077, 17161, 1056, 2206, 72, 680, 1410, 621, 2002, 44905, 2107, 4596, 51448], "temperature": 0.0, "avg_logprob": -0.18127893587505375, "compression_ratio": 1.7130044843049328, "no_speech_prob": 0.1363525390625, "words": null}, {"id": 147, "seek": 102288, "start": 1015.4399999999999, "end": 1022.88, "text": " diventarne degli esperti ma basta capirne almeno i concetti di base e quindi oggi voglio provare", "tokens": [51448, 3414, 32067, 716, 32079, 10045, 7317, 463, 45282, 1410, 347, 716, 419, 43232, 741, 1588, 12495, 1026, 3096, 308, 15727, 34768, 31273, 19987, 1439, 543, 51820], "temperature": 0.0, "avg_logprob": -0.18127893587505375, "compression_ratio": 1.7130044843049328, "no_speech_prob": 0.1363525390625, "words": null}, {"id": 148, "seek": 104912, "start": 1022.88, "end": 1030.24, "text": " a fare proprio questo voglio provare a sfatare un pochino del mito e ad intaccarne le fige", "tokens": [50364, 257, 11994, 28203, 10263, 31273, 19987, 1439, 543, 257, 262, 35293, 543, 517, 714, 339, 2982, 1103, 2194, 78, 308, 614, 560, 326, 6166, 716, 476, 2147, 68, 50732], "temperature": 0.0, "avg_logprob": -0.22619912270889725, "compression_ratio": 1.5265957446808511, "no_speech_prob": 0.00701141357421875, "words": null}, {"id": 149, "seek": 104912, "start": 1030.24, "end": 1042.64, "text": " partiamo subito con il dire che io non sono n\u00e9 un esperto di machine learning n\u00e9 ho avuto mai", "tokens": [50732, 644, 7415, 1422, 3528, 416, 1930, 1264, 947, 19785, 2107, 9259, 7024, 517, 10045, 1353, 1026, 3479, 2539, 7024, 1106, 1305, 8262, 12698, 51352], "temperature": 0.0, "avg_logprob": -0.22619912270889725, "compression_ratio": 1.5265957446808511, "no_speech_prob": 0.00701141357421875, "words": null}, {"id": 150, "seek": 104912, "start": 1042.64, "end": 1049.12, "text": " accesso a chiss\u00e0 quali informazioni riservate su chat gpt lo spunto per questo episodio mi \u00e8 stato", "tokens": [51352, 2105, 78, 257, 417, 891, 1467, 4101, 72, 1356, 27569, 2253, 1978, 473, 459, 5081, 290, 662, 450, 637, 24052, 680, 10263, 39200, 1004, 2752, 4873, 29657, 51676], "temperature": 0.0, "avg_logprob": -0.22619912270889725, "compression_ratio": 1.5265957446808511, "no_speech_prob": 0.00701141357421875, "words": null}, {"id": 151, "seek": 107320, "start": 1049.1200000000001, "end": 1055.3600000000001, "text": " dato da un articolo del new yorker che ti lascio in descrizione insieme con tutte le altre fonti che", "tokens": [50364, 46971, 1120, 517, 15228, 7902, 1103, 777, 288, 1284, 260, 947, 8757, 2439, 8529, 294, 2189, 19706, 1028, 44940, 416, 38632, 476, 34983, 10703, 72, 947, 50676], "temperature": 0.0, "avg_logprob": -0.19214527161271722, "compression_ratio": 1.6754385964912282, "no_speech_prob": 0.1292724609375, "words": null}, {"id": 152, "seek": 107320, "start": 1055.3600000000001, "end": 1061.4, "text": " ho utilizzato secondo l'autore dell'articolo e anche secondo me il modo migliore per capire i", "tokens": [50676, 1106, 40355, 2513, 41601, 287, 6, 1375, 418, 19781, 6, 446, 299, 7902, 308, 11585, 41601, 385, 1930, 16664, 6186, 2081, 418, 680, 1410, 621, 741, 50978], "temperature": 0.0, "avg_logprob": -0.19214527161271722, "compression_ratio": 1.6754385964912282, "no_speech_prob": 0.1292724609375, "words": null}, {"id": 153, "seek": 107320, "start": 1061.4, "end": 1066.3600000000001, "text": " concetti di base di una tecnologia \u00e8 provare ad affrontare superare almeno dal punto di vista", "tokens": [50978, 1588, 12495, 1026, 3096, 1026, 2002, 44905, 4873, 1439, 543, 614, 2096, 10001, 543, 1687, 543, 419, 43232, 11702, 14326, 1026, 22553, 51226], "temperature": 0.0, "avg_logprob": -0.19214527161271722, "compression_ratio": 1.6754385964912282, "no_speech_prob": 0.1292724609375, "words": null}, {"id": 154, "seek": 107320, "start": 1066.3600000000001, "end": 1073.2, "text": " teorico i vari ostacoli che essa pone ai suoi progettisti ovviamente noi non saremo in grado", "tokens": [51226, 40238, 2789, 741, 3034, 32946, 326, 9384, 947, 7208, 9224, 68, 9783, 459, 4869, 447, 847, 83, 45308, 14187, 23347, 22447, 2107, 38706, 3280, 294, 677, 1573, 51568], "temperature": 0.0, "avg_logprob": -0.19214527161271722, "compression_ratio": 1.6754385964912282, "no_speech_prob": 0.1292724609375, "words": null}, {"id": 155, "seek": 109960, "start": 1073.4, "end": 1079.64, "text": " di implementare il nostro bot nella mezz'ora che durer\u00e0 questo episodio di pensieri in codice ma", "tokens": [50374, 1026, 4445, 543, 1930, 35779, 10592, 23878, 385, 4313, 6, 3252, 947, 4861, 260, 1467, 10263, 39200, 1004, 1026, 6099, 45980, 294, 17656, 573, 463, 50686], "temperature": 0.0, "avg_logprob": -0.18936353320375496, "compression_ratio": 1.6637554585152838, "no_speech_prob": 0.274658203125, "words": null}, {"id": 156, "seek": 109960, "start": 1079.64, "end": 1087.0800000000002, "text": " individuare e risolvere teoricamente i problemi ci permetter\u00e0 da una parte di contestualizzare le", "tokens": [50686, 2461, 84, 543, 308, 2253, 401, 5887, 535, 16345, 3439, 741, 1154, 72, 6983, 20696, 391, 1467, 1120, 2002, 6975, 1026, 10287, 901, 8072, 543, 476, 51058], "temperature": 0.0, "avg_logprob": -0.18936353320375496, "compression_ratio": 1.6637554585152838, "no_speech_prob": 0.274658203125, "words": null}, {"id": 157, "seek": 109960, "start": 1087.0800000000002, "end": 1093.28, "text": " caratteristiche del prodotto e dall'altra di comprendere le scelte fatte da coloro che quei", "tokens": [51058, 1032, 1161, 468, 9304, 1103, 15792, 18838, 308, 43351, 6, 38865, 1026, 30765, 323, 476, 795, 338, 975, 4046, 975, 1120, 2017, 78, 947, 631, 72, 51368], "temperature": 0.0, "avg_logprob": -0.18936353320375496, "compression_ratio": 1.6637554585152838, "no_speech_prob": 0.274658203125, "words": null}, {"id": 158, "seek": 109960, "start": 1093.28, "end": 1099.6000000000001, "text": " problemi li hanno realmente affrontati dunque come punto di partenza torniamo a ribadire che", "tokens": [51368, 1154, 72, 375, 26595, 14446, 2096, 10001, 6908, 10234, 1077, 808, 14326, 1026, 644, 23691, 10885, 7415, 257, 9162, 345, 621, 947, 51684], "temperature": 0.0, "avg_logprob": -0.18936353320375496, "compression_ratio": 1.6637554585152838, "no_speech_prob": 0.274658203125, "words": null}, {"id": 159, "seek": 112772, "start": 1099.6000000000001, "end": 1105.64, "text": " un bot come chat gpt si basa essenzialmente sull'utilizzo di un tipo di machine learning", "tokens": [50364, 517, 10592, 808, 5081, 290, 662, 1511, 987, 64, 2097, 11368, 831, 4082, 459, 285, 6, 20835, 590, 4765, 1026, 517, 9746, 1026, 3479, 2539, 50666], "temperature": 0.0, "avg_logprob": -0.20299030724784423, "compression_ratio": 1.6595744680851063, "no_speech_prob": 0.203857421875, "words": null}, {"id": 160, "seek": 112772, "start": 1105.64, "end": 1112.3600000000001, "text": " chiamato large language model che in pratica \u00e8 una rete neurale ad apprendimento automatico allenata", "tokens": [50666, 417, 2918, 2513, 2416, 2856, 2316, 947, 294, 28844, 2262, 4873, 2002, 319, 975, 12087, 1220, 614, 724, 4542, 10030, 12509, 78, 18440, 3274, 51002], "temperature": 0.0, "avg_logprob": -0.20299030724784423, "compression_ratio": 1.6595744680851063, "no_speech_prob": 0.203857421875, "words": null}, {"id": 161, "seek": 112772, "start": 1112.3600000000001, "end": 1120.2, "text": " su una quantit\u00e0 enorme di dati di fatto il bot funge da interfaccia per la rete neurale e permette", "tokens": [51002, 459, 2002, 4426, 12445, 33648, 1026, 1137, 72, 1026, 23228, 1930, 10592, 1019, 432, 1120, 14510, 326, 2755, 680, 635, 319, 975, 12087, 1220, 308, 4784, 3007, 51394], "temperature": 0.0, "avg_logprob": -0.20299030724784423, "compression_ratio": 1.6595744680851063, "no_speech_prob": 0.203857421875, "words": null}, {"id": 162, "seek": 112772, "start": 1120.2, "end": 1127.72, "text": " di ricevere gli input dagli utenti e di restituire agli stessi output per i nostri scopi di oggi ti", "tokens": [51394, 1026, 5090, 5887, 17161, 4846, 15460, 2081, 2839, 23012, 308, 1026, 1472, 6380, 621, 623, 2081, 342, 442, 72, 5598, 680, 741, 10397, 470, 795, 404, 72, 1026, 34768, 8757, 51770], "temperature": 0.0, "avg_logprob": -0.20299030724784423, "compression_ratio": 1.6595744680851063, "no_speech_prob": 0.203857421875, "words": null}, {"id": 163, "seek": 115256, "start": 1127.72, "end": 1132.84, "text": " anticipo gi\u00e0 che non sar\u00e0 necessario capire in dettaglio come funziona una rete neurale o un'", "tokens": [50364, 10416, 78, 30469, 947, 2107, 41338, 2688, 4912, 1410, 621, 294, 1141, 25030, 19987, 808, 49345, 21758, 2002, 319, 975, 12087, 1220, 277, 517, 6, 50620], "temperature": 0.0, "avg_logprob": -0.16571101190846996, "compression_ratio": 1.682608695652174, "no_speech_prob": 0.0216064453125, "words": null}, {"id": 164, "seek": 115256, "start": 1132.84, "end": 1139.6000000000001, "text": " interfaccia tutto quello che faremo sar\u00e0 descrivere i vari passaggi necessari al bot per produrre una", "tokens": [50620, 14510, 326, 2755, 23048, 22813, 947, 11994, 3280, 41338, 2189, 5887, 741, 3034, 1320, 46893, 2688, 3504, 419, 10592, 680, 15792, 374, 265, 2002, 50958], "temperature": 0.0, "avg_logprob": -0.16571101190846996, "compression_ratio": 1.682608695652174, "no_speech_prob": 0.0216064453125, "words": null}, {"id": 165, "seek": 115256, "start": 1139.6000000000001, "end": 1146.48, "text": " risposta a partire da una domanda e sempre per semplicit\u00e0 ci limiteremo a considerare solo le", "tokens": [50958, 2253, 79, 8638, 257, 644, 621, 1120, 2002, 3285, 5575, 308, 9553, 680, 4361, 4770, 12445, 6983, 4948, 323, 3280, 257, 1949, 543, 6944, 476, 51302], "temperature": 0.0, "avg_logprob": -0.16571101190846996, "compression_ratio": 1.682608695652174, "no_speech_prob": 0.0216064453125, "words": null}, {"id": 166, "seek": 115256, "start": 1146.48, "end": 1152.56, "text": " funzioni inerenti il testo ignorando tutto ci\u00f2 che riguarda le modalit\u00e0 di funzionamento di", "tokens": [51302, 49345, 15273, 294, 260, 23012, 1930, 1500, 78, 14698, 1806, 23048, 6983, 4293, 947, 8329, 16981, 64, 476, 39745, 12445, 1026, 49345, 313, 8824, 1026, 51606], "temperature": 0.0, "avg_logprob": -0.16571101190846996, "compression_ratio": 1.682608695652174, "no_speech_prob": 0.0216064453125, "words": null}, {"id": 167, "seek": 117868, "start": 1152.56, "end": 1160.3999999999999, "text": " algoritmi per gestire musica immagini eccetera quindi il concetto di base \u00e8 un testo in input", "tokens": [50364, 3501, 50017, 3057, 680, 7219, 621, 1318, 64, 3397, 559, 3812, 29613, 20269, 15727, 1930, 1588, 23778, 1026, 3096, 4873, 517, 1500, 78, 294, 4846, 50756], "temperature": 0.0, "avg_logprob": -0.18487150061910398, "compression_ratio": 1.6755555555555555, "no_speech_prob": 0.09661865234375, "words": null}, {"id": 168, "seek": 117868, "start": 1160.3999999999999, "end": 1166.52, "text": " produce un testo in output coerente con l'input ricevuto come possiamo fare a realizzare una cosa", "tokens": [50756, 5258, 517, 1500, 78, 294, 5598, 598, 260, 1576, 416, 287, 6, 259, 2582, 5090, 85, 8262, 808, 44758, 11994, 257, 957, 8072, 543, 2002, 10163, 51062], "temperature": 0.0, "avg_logprob": -0.18487150061910398, "compression_ratio": 1.6755555555555555, "no_speech_prob": 0.09661865234375, "words": null}, {"id": 169, "seek": 117868, "start": 1166.52, "end": 1172.24, "text": " del genere beh come prima cosa abbiamo detto di avere a disposizione una grande quantit\u00e0 di", "tokens": [51062, 1103, 41553, 1540, 808, 19507, 10163, 22815, 41031, 1026, 37914, 257, 15885, 35740, 2002, 8883, 4426, 12445, 1026, 51348], "temperature": 0.0, "avg_logprob": -0.18487150061910398, "compression_ratio": 1.6755555555555555, "no_speech_prob": 0.09661865234375, "words": null}, {"id": 170, "seek": 117868, "start": 1172.24, "end": 1178.6799999999998, "text": " dati no proviamo innanzitutto a capire come sfruttare quelli per farlo e tanto per ribadire", "tokens": [51348, 1137, 72, 572, 1439, 7415, 7714, 3910, 270, 28698, 257, 1410, 621, 808, 262, 5779, 13478, 543, 631, 16320, 680, 1400, 752, 308, 10331, 680, 9162, 345, 621, 51670], "temperature": 0.0, "avg_logprob": -0.18487150061910398, "compression_ratio": 1.6755555555555555, "no_speech_prob": 0.09661865234375, "words": null}, {"id": 171, "seek": 120544, "start": 1178.68, "end": 1185.04, "text": " che questa tecnologia \u00e8 tutt'altro che nuova partiamo da un grande classico dell'informatica", "tokens": [50364, 947, 16540, 44905, 4873, 3672, 83, 6, 47484, 947, 3822, 27924, 644, 7415, 1120, 517, 8883, 1508, 2789, 19781, 6, 37811, 267, 2262, 50682], "temperature": 0.0, "avg_logprob": -0.18515625044703485, "compression_ratio": 1.6858407079646018, "no_speech_prob": 0.1845703125, "words": null}, {"id": 172, "seek": 120544, "start": 1185.04, "end": 1191.72, "text": " il testo intitolato \u00e8 mathematical theory of communication scritto da Claude Shannon che \u00e8", "tokens": [50682, 1930, 1500, 78, 560, 21086, 2513, 4873, 18894, 5261, 295, 6101, 5918, 34924, 1120, 12947, 2303, 28974, 947, 4873, 51016], "temperature": 0.0, "avg_logprob": -0.18515625044703485, "compression_ratio": 1.6858407079646018, "no_speech_prob": 0.1845703125, "words": null}, {"id": 173, "seek": 120544, "start": 1191.72, "end": 1198.4, "text": " il matematico che per primo ha descritto la teoria della gestione dell'informazione praticamente la", "tokens": [51016, 1930, 3803, 14911, 78, 947, 680, 38671, 324, 7471, 18579, 78, 635, 535, 8172, 11618, 7219, 5328, 19781, 6, 37811, 12928, 45734, 635, 51350], "temperature": 0.0, "avg_logprob": -0.18515625044703485, "compression_ratio": 1.6858407079646018, "no_speech_prob": 0.1845703125, "words": null}, {"id": 174, "seek": 120544, "start": 1198.4, "end": 1205.44, "text": " base dell'informatica moderna in questo paper oltre a tantissima matematica ovviamente si pu\u00f2", "tokens": [51350, 3096, 19781, 6, 37811, 267, 2262, 10494, 629, 294, 10263, 3035, 277, 2282, 265, 257, 12095, 891, 4775, 3803, 8615, 2262, 14187, 23347, 1511, 26526, 51702], "temperature": 0.0, "avg_logprob": -0.18515625044703485, "compression_ratio": 1.6858407079646018, "no_speech_prob": 0.1845703125, "words": null}, {"id": 175, "seek": 123460, "start": 1205.44, "end": 1212.6000000000001, "text": " trovare anche la descrizione di un interessante esperimento di generazione del testo Shannon", "tokens": [50364, 35449, 543, 11585, 635, 2189, 19706, 1026, 517, 24372, 10045, 10030, 1026, 1337, 12928, 1103, 1500, 78, 28974, 50722], "temperature": 0.0, "avg_logprob": -0.17677695421027204, "compression_ratio": 1.5889830508474576, "no_speech_prob": 0.012054443359375, "words": null}, {"id": 176, "seek": 123460, "start": 1212.6000000000001, "end": 1220.24, "text": " scrive nel 1948 e all'epoca non immagina le dimensioni alle quali sarebbe potuta arrivare", "tokens": [50722, 5545, 303, 15373, 38833, 308, 439, 6, 595, 24035, 2107, 3397, 559, 1426, 476, 10139, 72, 5430, 4101, 72, 38706, 39042, 1847, 12093, 30697, 543, 51104], "temperature": 0.0, "avg_logprob": -0.17677695421027204, "compression_ratio": 1.5889830508474576, "no_speech_prob": 0.012054443359375, "words": null}, {"id": 177, "seek": 123460, "start": 1220.24, "end": 1227.8, "text": " una banca dati nel 2023 o cosa sar\u00e0 internet o ancora di quanta potenza di calcolo avremmo", "tokens": [51104, 2002, 5643, 496, 1137, 72, 15373, 44377, 277, 10163, 41338, 4705, 277, 30656, 1026, 4426, 64, 1847, 23691, 1026, 2104, 46086, 1305, 265, 2174, 78, 51482], "temperature": 0.0, "avg_logprob": -0.17677695421027204, "compression_ratio": 1.5889830508474576, "no_speech_prob": 0.012054443359375, "words": null}, {"id": 178, "seek": 123460, "start": 1227.8, "end": 1234.6000000000001, "text": " potuto disporre noi al giorno d'oggi quindi formula tutto il suo ragionamento considerando come base", "tokens": [51482, 1847, 8262, 717, 2816, 265, 22447, 419, 42202, 274, 6, 664, 7834, 15727, 8513, 23048, 1930, 34197, 17539, 313, 8824, 1949, 1806, 808, 3096, 51822], "temperature": 0.0, "avg_logprob": -0.17677695421027204, "compression_ratio": 1.5889830508474576, "no_speech_prob": 0.012054443359375, "words": null}, {"id": 179, "seek": 126016, "start": 1234.6000000000001, "end": 1240.2, "text": " di informazioni disponibili la sua libreria personale tutto il discorso \u00e8 ovviamente in", "tokens": [50364, 1026, 1356, 27569, 23311, 897, 2312, 635, 8233, 4939, 41568, 954, 1220, 23048, 1930, 2983, 284, 539, 4873, 14187, 23347, 294, 50644], "temperature": 0.0, "avg_logprob": -0.18640624433755876, "compression_ratio": 1.6217391304347826, "no_speech_prob": 0.011505126953125, "words": null}, {"id": 180, "seek": 126016, "start": 1240.2, "end": 1247.0800000000002, "text": " scala rispetto a quelli che sono i numeri di un moderno large language model ma nonostante ci\u00f2", "tokens": [50644, 795, 5159, 2253, 42801, 257, 631, 16320, 947, 9259, 741, 7866, 72, 1026, 517, 4363, 78, 2416, 2856, 2316, 463, 2107, 555, 2879, 6983, 4293, 50988], "temperature": 0.0, "avg_logprob": -0.18640624433755876, "compression_ratio": 1.6217391304347826, "no_speech_prob": 0.011505126953125, "words": null}, {"id": 181, "seek": 126016, "start": 1247.0800000000002, "end": 1254.2, "text": " tutto funziona perfettamente e come bonus lo si pu\u00f2 mettere in pratica anche senza l'ausilio di", "tokens": [50988, 23048, 49345, 21758, 13826, 3093, 3439, 308, 808, 10882, 450, 1511, 26526, 27812, 323, 294, 28844, 2262, 11585, 36208, 287, 6, 8463, 388, 1004, 1026, 51344], "temperature": 0.0, "avg_logprob": -0.18640624433755876, "compression_ratio": 1.6217391304347826, "no_speech_prob": 0.011505126953125, "words": null}, {"id": 182, "seek": 126016, "start": 1254.2, "end": 1260.16, "text": " un computer basta semplicemente avere qualche libro in casa come prima cosa Shannon sceglie", "tokens": [51344, 517, 3820, 45282, 4361, 4770, 16288, 37914, 38737, 29354, 294, 9022, 808, 19507, 10163, 28974, 262, 384, 70, 6302, 51642], "temperature": 0.0, "avg_logprob": -0.18640624433755876, "compression_ratio": 1.6217391304347826, "no_speech_prob": 0.011505126953125, "words": null}, {"id": 183, "seek": 128548, "start": 1260.16, "end": 1266.64, "text": " una parola da cui iniziare la generazione del testo e la scrive su un foglio per semplicit\u00e0", "tokens": [50364, 2002, 971, 4711, 1120, 22929, 294, 24300, 543, 635, 1337, 12928, 1103, 1500, 78, 308, 635, 5545, 303, 459, 517, 13648, 19987, 680, 4361, 4770, 12445, 50688], "temperature": 0.0, "avg_logprob": -0.177768634207416, "compression_ratio": 1.75, "no_speech_prob": 0.2142333984375, "words": null}, {"id": 184, "seek": 128548, "start": 1266.64, "end": 1272.72, "text": " sceglie una delle parole pi\u00f9 comuni della sua lingua l'articolo a questo punto sceglie un", "tokens": [50688, 262, 384, 70, 6302, 2002, 16485, 26783, 10589, 11040, 72, 11618, 8233, 22949, 4398, 287, 6, 446, 299, 7902, 257, 10263, 14326, 262, 384, 70, 6302, 517, 50992], "temperature": 0.0, "avg_logprob": -0.177768634207416, "compression_ratio": 1.75, "no_speech_prob": 0.2142333984375, "words": null}, {"id": 185, "seek": 128548, "start": 1272.72, "end": 1278.8000000000002, "text": " libro a caso dalla libreria e lo apre ad una pagina sempre a caso legge il testo finch\u00e9 non arriva", "tokens": [50992, 29354, 257, 9666, 35566, 4939, 41568, 308, 450, 1882, 265, 614, 2002, 11812, 1426, 9553, 257, 9666, 1676, 432, 1930, 1500, 78, 962, 11131, 2107, 3399, 2757, 51296], "temperature": 0.0, "avg_logprob": -0.177768634207416, "compression_ratio": 1.75, "no_speech_prob": 0.2142333984375, "words": null}, {"id": 186, "seek": 128548, "start": 1278.8000000000002, "end": 1285.48, "text": " alla parola e a quel punto scrive sul suo foglio la prima parola che viene subito dopo che nel", "tokens": [51296, 11591, 971, 4711, 308, 257, 7178, 14326, 5545, 303, 17603, 34197, 13648, 19987, 635, 19507, 971, 4711, 947, 19561, 1422, 3528, 35196, 947, 15373, 51630], "temperature": 0.0, "avg_logprob": -0.177768634207416, "compression_ratio": 1.75, "no_speech_prob": 0.2142333984375, "words": null}, {"id": 187, "seek": 131480, "start": 1285.48, "end": 1293.4, "text": " suo esempio \u00e8 head testa il testo sul foglio diventa quindi the head e lui ripete il processo", "tokens": [50364, 34197, 33627, 4873, 1378, 1500, 64, 1930, 1500, 78, 17603, 13648, 19987, 3414, 8938, 15727, 264, 1378, 308, 8783, 12782, 3498, 1930, 27939, 50760], "temperature": 0.0, "avg_logprob": -0.2124707879864167, "compression_ratio": 1.7432432432432432, "no_speech_prob": 0.07257080078125, "words": null}, {"id": 188, "seek": 131480, "start": 1293.4, "end": 1301.48, "text": " partendo per\u00f2 questa volta dalla parola head la cerca in una pagina a caso di un libro a caso e", "tokens": [50760, 644, 3999, 12673, 16540, 18765, 35566, 971, 4711, 1378, 635, 26770, 294, 2002, 11812, 1426, 257, 9666, 1026, 517, 29354, 257, 9666, 308, 51164], "temperature": 0.0, "avg_logprob": -0.2124707879864167, "compression_ratio": 1.7432432432432432, "no_speech_prob": 0.07257080078125, "words": null}, {"id": 189, "seek": 131480, "start": 1301.48, "end": 1307.84, "text": " quando la trova ricopia sul suo foglio la parola che appare subito dopo la terza parola e quindi", "tokens": [51164, 7770, 635, 4495, 2757, 21040, 22376, 17603, 34197, 13648, 19987, 635, 971, 4711, 947, 724, 543, 1422, 3528, 35196, 635, 1796, 2394, 971, 4711, 308, 15727, 51482], "temperature": 0.0, "avg_logprob": -0.2124707879864167, "compression_ratio": 1.7432432432432432, "no_speech_prob": 0.07257080078125, "words": null}, {"id": 190, "seek": 131480, "start": 1307.84, "end": 1314.8, "text": " hand e congiunzione il matematico continua cos\u00ec per un po e alla fine arriva a formulare la frase", "tokens": [51482, 1011, 308, 416, 7834, 409, 19706, 1930, 3803, 14911, 78, 40861, 23278, 680, 517, 714, 308, 11591, 2489, 3399, 2757, 257, 49990, 543, 635, 38406, 51830], "temperature": 0.0, "avg_logprob": -0.2124707879864167, "compression_ratio": 1.7432432432432432, "no_speech_prob": 0.07257080078125, "words": null}, {"id": 191, "seek": 133660, "start": 1314.8, "end": 1322.6399999999999, "text": " the head and in frontal attack on an english writer that the character of this point is", "tokens": [50364, 264, 1378, 293, 294, 34647, 2690, 322, 364, 32169, 9936, 300, 264, 2517, 295, 341, 935, 307, 50756], "temperature": 0.0, "avg_logprob": -0.2660361951903293, "compression_ratio": 1.518918918918919, "no_speech_prob": 0.00490570068359375, "words": null}, {"id": 192, "seek": 133660, "start": 1322.6399999999999, "end": 1329.68, "text": " therefore another method e ok la frase in s\u00e9 non ha tantissimo senso sono d'accordo ma l'algoritmo", "tokens": [50756, 4412, 1071, 3170, 308, 3133, 635, 38406, 294, 7910, 2107, 324, 12095, 34966, 3151, 539, 9259, 274, 6, 19947, 78, 463, 287, 6, 20422, 50017, 3280, 51108], "temperature": 0.0, "avg_logprob": -0.2660361951903293, "compression_ratio": 1.518918918918919, "no_speech_prob": 0.00490570068359375, "words": null}, {"id": 193, "seek": 133660, "start": 1329.68, "end": 1336.6, "text": " messo a punto \u00e8 un'ottima base da cui possiamo partire noi per realizzare il nostro semplice", "tokens": [51108, 2082, 78, 257, 14326, 4873, 517, 6, 1521, 4775, 3096, 1120, 22929, 44758, 644, 621, 22447, 680, 957, 8072, 543, 1930, 35779, 4361, 564, 573, 51454], "temperature": 0.0, "avg_logprob": -0.2660361951903293, "compression_ratio": 1.518918918918919, "no_speech_prob": 0.00490570068359375, "words": null}, {"id": 194, "seek": 136188, "start": 1336.64, "end": 1348.8000000000002, "text": " llm casalingo per migliorare la ricerca del testo generato possiamo usare un semplice trucco che", "tokens": [50366, 287, 75, 76, 3058, 4270, 78, 680, 6186, 75, 1973, 543, 635, 21040, 36127, 1103, 1500, 78, 1337, 2513, 44758, 505, 543, 517, 4361, 564, 573, 14805, 1291, 947, 50974], "temperature": 0.0, "avg_logprob": -0.21056548168971426, "compression_ratio": 1.5934065934065933, "no_speech_prob": 0.17529296875, "words": null}, {"id": 195, "seek": 136188, "start": 1348.8000000000002, "end": 1355.4, "text": " pur rendendo un po pi\u00f9 complicata la ricerca ha per\u00f2 il vantaggio di aumentare le probabilit\u00e0", "tokens": [50974, 1864, 6125, 3999, 517, 714, 10589, 16060, 3274, 635, 21040, 36127, 324, 12673, 1930, 371, 394, 30763, 1026, 17128, 543, 476, 31959, 12445, 51304], "temperature": 0.0, "avg_logprob": -0.21056548168971426, "compression_ratio": 1.5934065934065933, "no_speech_prob": 0.17529296875, "words": null}, {"id": 196, "seek": 136188, "start": 1355.4, "end": 1361.88, "text": " di prelevare parole maggiormente senzate possiamo invece di ricercare una singola parola ad ogni", "tokens": [51304, 1026, 659, 28316, 543, 26783, 44639, 1973, 4082, 3151, 89, 473, 44758, 36344, 1026, 21040, 260, 5685, 2002, 1522, 4711, 971, 4711, 614, 33189, 51628], "temperature": 0.0, "avg_logprob": -0.21056548168971426, "compression_ratio": 1.5934065934065933, "no_speech_prob": 0.17529296875, "words": null}, {"id": 197, "seek": 138788, "start": 1361.88, "end": 1368.0600000000002, "text": " iterazione cercarne gruppi di due tre o anche pi\u00f9 quindi se il testo che vogliamo generare deve", "tokens": [50364, 17138, 12928, 10146, 6166, 716, 47477, 72, 1026, 3462, 2192, 277, 11585, 10589, 15727, 369, 1930, 1500, 78, 947, 31273, 49926, 1337, 543, 17761, 50673], "temperature": 0.0, "avg_logprob": -0.2162610640568016, "compression_ratio": 1.7149122807017543, "no_speech_prob": 0.306884765625, "words": null}, {"id": 198, "seek": 138788, "start": 1368.0600000000002, "end": 1373.0400000000002, "text": " parlare ad esempio della razza di cane pastore tedesco potremmo scrivere sul nostro foglietto", "tokens": [50673, 13734, 543, 614, 33627, 11618, 9639, 2394, 1026, 27518, 1791, 418, 22337, 279, 1291, 1847, 265, 2174, 78, 5545, 5887, 17603, 35779, 13648, 75, 1684, 1353, 50922], "temperature": 0.0, "avg_logprob": -0.2162610640568016, "compression_ratio": 1.7149122807017543, "no_speech_prob": 0.306884765625, "words": null}, {"id": 199, "seek": 138788, "start": 1373.0400000000002, "end": 1380.24, "text": " le parole di partenza il pastore tedesco \u00e8 e poi scorrere le pagine del libro finch\u00e9 non troviamo", "tokens": [50922, 476, 26783, 1026, 644, 23691, 1930, 1791, 418, 22337, 279, 1291, 4873, 308, 19260, 795, 24362, 323, 476, 280, 10260, 1103, 29354, 962, 11131, 2107, 35449, 7415, 51282], "temperature": 0.0, "avg_logprob": -0.2162610640568016, "compression_ratio": 1.7149122807017543, "no_speech_prob": 0.306884765625, "words": null}, {"id": 200, "seek": 138788, "start": 1380.24, "end": 1387.88, "text": " esattamente le tre parole pastore tedesco \u00e8 per poi come prima prelevare la successiva e aggiungere", "tokens": [51282, 785, 1591, 3439, 476, 2192, 26783, 1791, 418, 22337, 279, 1291, 4873, 680, 19260, 808, 19507, 659, 28316, 543, 635, 2245, 5931, 308, 42254, 1063, 323, 51664], "temperature": 0.0, "avg_logprob": -0.2162610640568016, "compression_ratio": 1.7149122807017543, "no_speech_prob": 0.306884765625, "words": null}, {"id": 201, "seek": 141468, "start": 1387.88, "end": 1392.96, "text": " al nostro testo proviamo dunque ad applicare il nuovo algoritmo e a scopo esemplificativo", "tokens": [50364, 419, 35779, 1500, 78, 1439, 7415, 10234, 1077, 614, 2580, 543, 1930, 49348, 3501, 50017, 3280, 308, 257, 795, 404, 78, 785, 5895, 1089, 18586, 50618], "temperature": 0.0, "avg_logprob": -0.1667144484476212, "compression_ratio": 1.7255813953488373, "no_speech_prob": 0.09527587890625, "words": null}, {"id": 202, "seek": 141468, "start": 1392.96, "end": 1399.0400000000002, "text": " facciamo finta che la parola trovata sia una l'articolo indeterminativo femminile la frase", "tokens": [50618, 1915, 42052, 283, 16071, 947, 635, 971, 4711, 35449, 3274, 25176, 2002, 287, 6, 446, 299, 7902, 1016, 35344, 259, 18586, 4010, 2367, 794, 635, 38406, 50922], "temperature": 0.0, "avg_logprob": -0.1667144484476212, "compression_ratio": 1.7255813953488373, "no_speech_prob": 0.09527587890625, "words": null}, {"id": 203, "seek": 141468, "start": 1399.0400000000002, "end": 1407.3200000000002, "text": " diventerebbe il pastore tedesco \u00e8 una mentre la prossima chiave di ricerca diventerebbe tedesco", "tokens": [50922, 3414, 317, 323, 39042, 1930, 1791, 418, 22337, 279, 1291, 4873, 2002, 49601, 635, 48794, 4775, 45793, 303, 1026, 21040, 36127, 3414, 317, 323, 39042, 22337, 279, 1291, 51336], "temperature": 0.0, "avg_logprob": -0.1667144484476212, "compression_ratio": 1.7255813953488373, "no_speech_prob": 0.09527587890625, "words": null}, {"id": 204, "seek": 141468, "start": 1407.3200000000002, "end": 1414.68, "text": " \u00e8 una perch\u00e9 stiamo cercando sempre tre parole per volta procediamo cos\u00ec prendendo libri e", "tokens": [51336, 4873, 2002, 14303, 342, 7415, 36099, 1806, 9553, 2192, 26783, 680, 18765, 6682, 7415, 23278, 9866, 3999, 22854, 470, 308, 51704], "temperature": 0.0, "avg_logprob": -0.1667144484476212, "compression_ratio": 1.7255813953488373, "no_speech_prob": 0.09527587890625, "words": null}, {"id": 205, "seek": 144004, "start": 1414.68, "end": 1422.16, "text": " pagine a caso per 3 4 5 10 100 volte dipende da quanto vogliamo che il nostro testo sia lungo", "tokens": [50364, 280, 10260, 257, 9666, 680, 805, 1017, 1025, 1266, 2319, 37801, 10460, 5445, 1120, 17820, 31273, 49926, 947, 1930, 35779, 1500, 78, 25176, 16730, 78, 50738], "temperature": 0.0, "avg_logprob": -0.20126487598532722, "compression_ratio": 1.4921465968586387, "no_speech_prob": 0.0247955322265625, "words": null}, {"id": 206, "seek": 144004, "start": 1422.16, "end": 1433.3600000000001, "text": " con quest'altra modifica applicata all'algoritmo l'attenenza delle parole fra loro \u00e8 dunque", "tokens": [50738, 416, 866, 6, 38865, 1072, 43377, 2580, 3274, 439, 6, 20422, 50017, 3280, 287, 6, 32733, 23691, 16485, 26783, 6600, 28810, 4873, 10234, 1077, 51298], "temperature": 0.0, "avg_logprob": -0.20126487598532722, "compression_ratio": 1.4921465968586387, "no_speech_prob": 0.0247955322265625, "words": null}, {"id": 207, "seek": 144004, "start": 1433.3600000000001, "end": 1440.04, "text": " aumentata ma scommetto gi\u00e0 che starai iniziando ad intuire che per ottenere dei risultati decenti", "tokens": [51298, 17128, 3274, 463, 795, 1204, 23778, 30469, 947, 3543, 1301, 294, 24300, 1806, 614, 560, 43612, 947, 680, 4337, 1147, 323, 13874, 2253, 723, 6908, 8681, 72, 51632], "temperature": 0.0, "avg_logprob": -0.20126487598532722, "compression_ratio": 1.4921465968586387, "no_speech_prob": 0.0247955322265625, "words": null}, {"id": 208, "seek": 146620, "start": 1440.04, "end": 1447.2, "text": " serve una quantit\u00e0 di libri quindi una base dati molto grande se avessimo infatti pochi libri", "tokens": [50364, 4596, 2002, 4426, 12445, 1026, 22854, 470, 15727, 2002, 3096, 1137, 72, 16394, 8883, 369, 1305, 442, 6934, 1536, 21515, 714, 8036, 22854, 470, 50722], "temperature": 0.0, "avg_logprob": -0.1891891859673165, "compression_ratio": 1.7117117117117118, "no_speech_prob": 0.16650390625, "words": null}, {"id": 209, "seek": 146620, "start": 1447.2, "end": 1452.8, "text": " considerando la complessit\u00e0 delle nuove chiavi di ricerca finiremmo per capitare sempre sulle", "tokens": [50722, 1949, 1806, 635, 1209, 442, 12445, 16485, 3822, 1682, 45793, 4917, 1026, 21040, 36127, 962, 621, 2174, 78, 680, 33807, 543, 9553, 459, 2447, 51002], "temperature": 0.0, "avg_logprob": -0.1891891859673165, "compression_ratio": 1.7117117117117118, "no_speech_prob": 0.16650390625, "words": null}, {"id": 210, "seek": 146620, "start": 1452.8, "end": 1459.44, "text": " stesse pagine e quindi automaticamente ci troveremmo a ricopiare pi\u00f9 o meno pedissequamente", "tokens": [51002, 342, 7357, 280, 10260, 308, 15727, 12509, 3439, 6983, 4495, 5887, 2174, 78, 257, 21040, 404, 72, 543, 10589, 277, 40236, 5670, 7746, 358, 3439, 51334], "temperature": 0.0, "avg_logprob": -0.1891891859673165, "compression_ratio": 1.7117117117117118, "no_speech_prob": 0.16650390625, "words": null}, {"id": 211, "seek": 146620, "start": 1459.44, "end": 1466.2, "text": " il testo di un certo libro oppure nella peggiore delle ipotesi potremmo non trovare nessun gruppo", "tokens": [51334, 1930, 1500, 78, 1026, 517, 22261, 29354, 1458, 540, 23878, 520, 22771, 418, 16485, 28501, 17251, 72, 1847, 265, 2174, 78, 2107, 35449, 543, 39787, 409, 47477, 78, 51672], "temperature": 0.0, "avg_logprob": -0.1891891859673165, "compression_ratio": 1.7117117117117118, "no_speech_prob": 0.16650390625, "words": null}, {"id": 212, "seek": 149252, "start": 1466.2, "end": 1472.1200000000001, "text": " di parole che soddisfi la ricerca e in tal caso dovremmo semplicemente rinunciare ma anche cos\u00ec", "tokens": [50364, 1026, 26783, 947, 15047, 67, 4937, 72, 635, 21040, 36127, 308, 294, 4023, 9666, 30870, 265, 2174, 78, 4361, 4770, 16288, 367, 259, 11228, 543, 463, 11585, 23278, 50660], "temperature": 0.0, "avg_logprob": -0.1858108108108108, "compression_ratio": 1.6440677966101696, "no_speech_prob": 0.07257080078125, "words": null}, {"id": 213, "seek": 149252, "start": 1472.1200000000001, "end": 1479.64, "text": " con molti libri a disposizione resta comunque un problema di fondo certi gruppi di parole possono", "tokens": [50660, 416, 10739, 72, 22854, 470, 257, 15885, 35740, 1472, 64, 45736, 517, 12395, 1026, 38101, 5351, 72, 47477, 72, 1026, 26783, 43857, 51036], "temperature": 0.0, "avg_logprob": -0.1858108108108108, "compression_ratio": 1.6440677966101696, "no_speech_prob": 0.07257080078125, "words": null}, {"id": 214, "seek": 149252, "start": 1479.64, "end": 1486.0800000000002, "text": " portare a ricercare nell'intero database senza dare risultati quindi per produrre noi un algoritmo", "tokens": [51036, 2436, 543, 257, 21040, 260, 5685, 44666, 6, 5106, 78, 8149, 36208, 8955, 2253, 723, 6908, 15727, 680, 15792, 374, 265, 22447, 517, 3501, 50017, 3280, 51358], "temperature": 0.0, "avg_logprob": -0.1858108108108108, "compression_ratio": 1.6440677966101696, "no_speech_prob": 0.07257080078125, "words": null}, {"id": 215, "seek": 149252, "start": 1486.0800000000002, "end": 1492.52, "text": " robusto ci serve di inventarci una strategia che ci eviti di andare a comporre delle chiavi di", "tokens": [51358, 13956, 78, 6983, 4596, 1026, 7962, 289, 537, 2002, 5464, 654, 947, 6983, 1073, 8707, 1026, 42742, 257, 715, 284, 265, 16485, 45793, 4917, 1026, 51680], "temperature": 0.0, "avg_logprob": -0.1858108108108108, "compression_ratio": 1.6440677966101696, "no_speech_prob": 0.07257080078125, "words": null}, {"id": 216, "seek": 151716, "start": 1492.52, "end": 1504.4, "text": " ricerca troppo insolite o impossibili da trovare per ampliare il ventaglio di possibili risultati", "tokens": [50364, 21040, 36127, 4495, 27000, 1028, 401, 642, 277, 38802, 897, 2312, 1120, 35449, 543, 680, 9731, 72, 543, 1930, 6931, 559, 19987, 1026, 1402, 897, 2312, 2253, 723, 6908, 50958], "temperature": 0.0, "avg_logprob": -0.18014172048762786, "compression_ratio": 1.686046511627907, "no_speech_prob": 0.02227783203125, "words": null}, {"id": 217, "seek": 151716, "start": 1504.4, "end": 1510.4, "text": " allora cambiamo leggermente il nostro approccio innanzitutto passiamo dal cercare esattamente un", "tokens": [50958, 44141, 18751, 7415, 1676, 1321, 4082, 1930, 35779, 2075, 66, 8529, 7714, 3910, 270, 28698, 1320, 7415, 11702, 10146, 5685, 785, 1591, 3439, 517, 51258], "temperature": 0.0, "avg_logprob": -0.18014172048762786, "compression_ratio": 1.686046511627907, "no_speech_prob": 0.02227783203125, "words": null}, {"id": 218, "seek": 151716, "start": 1510.4, "end": 1517.16, "text": " gruppo di parole al cercare quelle stesse parole in ordine sparso all'interno di gruppetti poco", "tokens": [51258, 47477, 78, 1026, 26783, 419, 10146, 5685, 29237, 342, 7357, 26783, 294, 4792, 533, 637, 685, 78, 439, 6, 5106, 1771, 1026, 47477, 12495, 10639, 51596], "temperature": 0.0, "avg_logprob": -0.18014172048762786, "compression_ratio": 1.686046511627907, "no_speech_prob": 0.02227783203125, "words": null}, {"id": 219, "seek": 154164, "start": 1517.28, "end": 1523.6000000000001, "text": " grandi in pratica in questo modo riusciamo ad individuare anche le chiavi di ricerca che", "tokens": [50370, 45155, 294, 28844, 2262, 294, 10263, 16664, 367, 4872, 42052, 614, 2461, 84, 543, 11585, 476, 45793, 4917, 1026, 21040, 36127, 947, 50686], "temperature": 0.0, "avg_logprob": -0.1918992654791156, "compression_ratio": 1.7417840375586855, "no_speech_prob": 0.18701171875, "words": null}, {"id": 220, "seek": 154164, "start": 1523.6000000000001, "end": 1530.52, "text": " somigliano alla nostra non per forza solo quelle identiche inoltre invece di accodare immediatamente", "tokens": [50686, 3307, 328, 75, 6254, 11591, 34311, 2107, 680, 337, 2394, 6944, 29237, 2473, 9304, 294, 401, 3599, 36344, 1026, 1317, 378, 543, 3640, 25354, 51032], "temperature": 0.0, "avg_logprob": -0.1918992654791156, "compression_ratio": 1.7417840375586855, "no_speech_prob": 0.18701171875, "words": null}, {"id": 221, "seek": 154164, "start": 1530.52, "end": 1535.28, "text": " la parola al nostro testo appena incontriamo un risultato della nostra ricerca annotiamola", "tokens": [51032, 635, 971, 4711, 419, 35779, 1500, 78, 724, 4118, 834, 896, 470, 10502, 517, 2253, 723, 2513, 11618, 34311, 21040, 36127, 25339, 2918, 4711, 51270], "temperature": 0.0, "avg_logprob": -0.1918992654791156, "compression_ratio": 1.7417840375586855, "no_speech_prob": 0.18701171875, "words": null}, {"id": 222, "seek": 154164, "start": 1535.28, "end": 1541.64, "text": " da qualche parte poi continuiamo a cercare la stessa chiave in altri libri o pagine e ogni", "tokens": [51270, 1120, 38737, 6975, 19260, 2993, 7415, 257, 10146, 5685, 635, 342, 8391, 45793, 303, 294, 33707, 22854, 470, 277, 280, 10260, 308, 33189, 51588], "temperature": 0.0, "avg_logprob": -0.1918992654791156, "compression_ratio": 1.7417840375586855, "no_speech_prob": 0.18701171875, "words": null}, {"id": 223, "seek": 156668, "start": 1541.64, "end": 1547.24, "text": " volta che incontriamo una parola candidata ad entrare a far parte del nostro testo annotiamola", "tokens": [50364, 18765, 947, 834, 896, 470, 10502, 2002, 971, 4711, 6268, 3274, 614, 22284, 265, 257, 1400, 6975, 1103, 35779, 1500, 78, 25339, 2918, 4711, 50644], "temperature": 0.0, "avg_logprob": -0.18855168799368235, "compression_ratio": 1.7431192660550459, "no_speech_prob": 0.0887451171875, "words": null}, {"id": 224, "seek": 156668, "start": 1547.24, "end": 1554.72, "text": " insieme alle altre alla fine ovviamente otterremo non pi\u00f9 una sola parola ma una lista di candidate", "tokens": [50644, 1028, 44940, 5430, 34983, 11591, 2489, 14187, 23347, 4337, 391, 44172, 2107, 10589, 2002, 34162, 971, 4711, 463, 2002, 27764, 1026, 11532, 51018], "temperature": 0.0, "avg_logprob": -0.18855168799368235, "compression_ratio": 1.7431192660550459, "no_speech_prob": 0.0887451171875, "words": null}, {"id": 225, "seek": 156668, "start": 1554.72, "end": 1560.44, "text": " e per scegliere fra queste quale sia la pi\u00f9 adatta possiamo allora predisporre un sistema", "tokens": [51018, 308, 680, 262, 384, 41443, 323, 6600, 35455, 421, 1220, 25176, 635, 10589, 614, 18405, 44758, 44141, 3852, 271, 2816, 265, 517, 13245, 51304], "temperature": 0.0, "avg_logprob": -0.18855168799368235, "compression_ratio": 1.7431192660550459, "no_speech_prob": 0.0887451171875, "words": null}, {"id": 226, "seek": 156668, "start": 1560.44, "end": 1566.68, "text": " di classifica basato su dei voti che daremo ad ogni parola banalmente quella con il voto pi\u00f9", "tokens": [51304, 1026, 1508, 43377, 987, 2513, 459, 13874, 3478, 72, 947, 8955, 3280, 614, 33189, 971, 4711, 5643, 304, 4082, 32234, 416, 1930, 3478, 78, 10589, 51616], "temperature": 0.0, "avg_logprob": -0.18855168799368235, "compression_ratio": 1.7431192660550459, "no_speech_prob": 0.0887451171875, "words": null}, {"id": 227, "seek": 159060, "start": 1566.68, "end": 1572.3600000000001, "text": " alto verr\u00e0 selezionata per entrare a far parte del testo che stiamo generando il voto pu\u00f2 essere", "tokens": [50364, 21275, 1306, 39212, 369, 20336, 313, 3274, 680, 22284, 265, 257, 1400, 6975, 1103, 1500, 78, 947, 342, 7415, 1337, 1806, 1930, 3478, 78, 26526, 19799, 50648], "temperature": 0.0, "avg_logprob": -0.1847254611621393, "compression_ratio": 1.6926406926406927, "no_speech_prob": 0.2039794921875, "words": null}, {"id": 228, "seek": 159060, "start": 1572.3600000000001, "end": 1578.16, "text": " calcolato in base ai fattori che pi\u00f9 riteniamo appropriati come ad esempio il numero di volte", "tokens": [50648, 2104, 8768, 2513, 294, 3096, 9783, 283, 1591, 7386, 947, 10589, 367, 6009, 7415, 5745, 6908, 808, 614, 33627, 1930, 46839, 1026, 37801, 50938], "temperature": 0.0, "avg_logprob": -0.1847254611621393, "compression_ratio": 1.6926406926406927, "no_speech_prob": 0.2039794921875, "words": null}, {"id": 229, "seek": 159060, "start": 1578.16, "end": 1584.4, "text": " in cui la parola appare nella lista o la quantit\u00e0 di parole che la precedono o la seguono fino al", "tokens": [50938, 294, 22929, 635, 971, 4711, 724, 543, 23878, 27764, 277, 635, 4426, 12445, 1026, 26783, 947, 635, 16969, 8957, 277, 635, 8878, 8957, 42560, 419, 51250], "temperature": 0.0, "avg_logprob": -0.1847254611621393, "compression_ratio": 1.6926406926406927, "no_speech_prob": 0.2039794921875, "words": null}, {"id": 230, "seek": 159060, "start": 1584.4, "end": 1590.6000000000001, "text": " punto il numero di pagina in cui \u00e8 stata trovata il numero di recensioni positive che il libro ha", "tokens": [51250, 14326, 1930, 46839, 1026, 11812, 1426, 294, 22929, 4873, 49554, 35449, 3274, 1930, 46839, 1026, 850, 3378, 72, 3353, 947, 1930, 29354, 324, 51560], "temperature": 0.0, "avg_logprob": -0.1847254611621393, "compression_ratio": 1.6926406926406927, "no_speech_prob": 0.2039794921875, "words": null}, {"id": 231, "seek": 161960, "start": 1590.6000000000001, "end": 1601.5200000000002, "text": " su amazon qualsiasi criterio o insieme di criteri che vogliamo insomma una volta trasformata la", "tokens": [50364, 459, 47010, 421, 1124, 4609, 72, 9912, 1004, 277, 1028, 44940, 1026, 9912, 72, 947, 31273, 49926, 1028, 30243, 2002, 18765, 22507, 837, 3274, 635, 50910], "temperature": 0.0, "avg_logprob": -0.18104931520759512, "compression_ratio": 1.6336206896551724, "no_speech_prob": 0.109619140625, "words": null}, {"id": 232, "seek": 161960, "start": 1601.5200000000002, "end": 1607.3200000000002, "text": " ricerca diretta in un sistema di votazione otteniamo ben due vantaggi rispetto all'algoritmo", "tokens": [50910, 21040, 36127, 48196, 1328, 294, 517, 13245, 1026, 3478, 12928, 4337, 1147, 7415, 3271, 3462, 371, 394, 46893, 2253, 42801, 439, 6, 20422, 50017, 3280, 51200], "temperature": 0.0, "avg_logprob": -0.18104931520759512, "compression_ratio": 1.6336206896551724, "no_speech_prob": 0.109619140625, "words": null}, {"id": 233, "seek": 161960, "start": 1607.3200000000002, "end": 1613.44, "text": " precedente il primo consiste nell'eliminare le ricerche che non diano risultati che \u00e8 appunto", "tokens": [51200, 16969, 1576, 1930, 38671, 49066, 44666, 6, 338, 4395, 543, 476, 21040, 260, 1876, 947, 2107, 274, 6254, 2253, 723, 6908, 947, 4873, 724, 24052, 51506], "temperature": 0.0, "avg_logprob": -0.18104931520759512, "compression_ratio": 1.6336206896551724, "no_speech_prob": 0.109619140625, "words": null}, {"id": 234, "seek": 161960, "start": 1613.44, "end": 1619.6000000000001, "text": " il problema da cui siamo partiti il bacino di scelta infatti riduce la componente di casualit\u00e0", "tokens": [51506, 1930, 12395, 1120, 22929, 33459, 644, 8707, 1930, 6857, 2982, 1026, 795, 338, 1328, 1536, 21515, 3973, 4176, 635, 4026, 1576, 1026, 13052, 12445, 51814], "temperature": 0.0, "avg_logprob": -0.18104931520759512, "compression_ratio": 1.6336206896551724, "no_speech_prob": 0.109619140625, "words": null}, {"id": 235, "seek": 164604, "start": 1619.92, "end": 1626.8000000000002, "text": " permettendo di evitare di selezionare parole poco adatte utilizzate in modi inconsueti o poco comuni", "tokens": [50380, 21540, 3999, 1026, 1073, 270, 543, 1026, 369, 20336, 313, 543, 26783, 10639, 614, 30466, 40355, 473, 294, 1072, 72, 22039, 15382, 72, 277, 10639, 11040, 72, 50724], "temperature": 0.0, "avg_logprob": -0.17905406049779943, "compression_ratio": 1.7260869565217392, "no_speech_prob": 0.0002269744873046875, "words": null}, {"id": 236, "seek": 164604, "start": 1626.8000000000002, "end": 1633.6000000000001, "text": " in pi\u00f9 per\u00f2 otteniamo anche un secondo vantaggio che ci apre un nuovo orizzonte di possibilit\u00e0 le", "tokens": [50724, 294, 10589, 12673, 4337, 1147, 7415, 11585, 517, 41601, 371, 394, 30763, 947, 6983, 1882, 265, 517, 49348, 420, 8072, 10219, 1026, 24145, 12445, 476, 51064], "temperature": 0.0, "avg_logprob": -0.17905406049779943, "compression_ratio": 1.7260869565217392, "no_speech_prob": 0.0002269744873046875, "words": null}, {"id": 237, "seek": 164604, "start": 1633.6000000000001, "end": 1639.0800000000002, "text": " regole di votazione che abbiamo aggiunto infatti ci permettono di applicare le pi\u00f9 disparate", "tokens": [51064, 1121, 4812, 1026, 3478, 12928, 947, 22815, 42254, 24052, 1536, 21515, 6983, 20696, 1756, 78, 1026, 2580, 543, 476, 10589, 14548, 473, 51338], "temperature": 0.0, "avg_logprob": -0.17905406049779943, "compression_ratio": 1.7260869565217392, "no_speech_prob": 0.0002269744873046875, "words": null}, {"id": 238, "seek": 164604, "start": 1639.0800000000002, "end": 1646.0400000000002, "text": " regolazioni al nostro motore di ricerca cambiare le regole ci permetter\u00e0 di cambiare il risultato di", "tokens": [51338, 1121, 401, 27569, 419, 35779, 2184, 418, 1026, 21040, 36127, 19569, 543, 476, 1121, 4812, 6983, 20696, 391, 1467, 1026, 19569, 543, 1930, 2253, 723, 2513, 1026, 51686], "temperature": 0.0, "avg_logprob": -0.17905406049779943, "compression_ratio": 1.7260869565217392, "no_speech_prob": 0.0002269744873046875, "words": null}, {"id": 239, "seek": 167388, "start": 1646.08, "end": 1651.8, "text": " poco o di tanto a seconda delle necessit\u00e0 se ad esempio prediligeremo regole che si basano su un", "tokens": [50366, 10639, 277, 1026, 10331, 257, 1150, 64, 16485, 2688, 12445, 369, 614, 33627, 3852, 388, 328, 323, 3280, 1121, 4812, 947, 1511, 987, 3730, 459, 517, 50652], "temperature": 0.0, "avg_logprob": -0.20270646869071893, "compression_ratio": 1.6919642857142858, "no_speech_prob": 0.2447509765625, "words": null}, {"id": 240, "seek": 167388, "start": 1651.8, "end": 1656.84, "text": " criterio di autorevolezza dei testi in cui cerchiamo il risultato sar\u00e0 di maggiore", "tokens": [50652, 9912, 1004, 1026, 1476, 418, 3080, 20336, 2394, 13874, 1500, 72, 294, 22929, 10146, 339, 7415, 1930, 2253, 723, 2513, 41338, 1026, 463, 22771, 418, 50904], "temperature": 0.0, "avg_logprob": -0.20270646869071893, "compression_ratio": 1.6919642857142858, "no_speech_prob": 0.2447509765625, "words": null}, {"id": 241, "seek": 167388, "start": 1656.84, "end": 1662.96, "text": " attendibilit\u00e0 mentre se prediligeremo testi pi\u00f9 antichi il linguaggio sar\u00e0 pi\u00f9 arcaico e cos\u00ec via", "tokens": [50904, 6888, 11607, 12445, 49601, 369, 3852, 388, 328, 323, 3280, 1500, 72, 10589, 2511, 18543, 1930, 21766, 30763, 41338, 10589, 594, 496, 2789, 308, 23278, 5766, 51210], "temperature": 0.0, "avg_logprob": -0.20270646869071893, "compression_ratio": 1.6919642857142858, "no_speech_prob": 0.2447509765625, "words": null}, {"id": 242, "seek": 167388, "start": 1662.96, "end": 1673.8799999999999, "text": " siamo dunque giunti a saper generare dei testi in linguaggio naturale partendo da un gruppo di", "tokens": [51210, 33459, 10234, 1077, 1735, 2760, 72, 257, 262, 2332, 1337, 543, 13874, 1500, 72, 294, 21766, 30763, 40877, 644, 3999, 1120, 517, 47477, 78, 1026, 51756], "temperature": 0.0, "avg_logprob": -0.20270646869071893, "compression_ratio": 1.6919642857142858, "no_speech_prob": 0.2447509765625, "words": null}, {"id": 243, "seek": 169836, "start": 1673.88, "end": 1681.3200000000002, "text": " parole e attenendoci ad una serie di indicazioni o regole ma quello che vogliamo fare in realt\u00e0 non", "tokens": [50364, 26783, 308, 951, 268, 3999, 537, 614, 2002, 23030, 1026, 4694, 27569, 277, 1121, 4812, 463, 22813, 947, 31273, 49926, 11994, 294, 47512, 2107, 50736], "temperature": 0.0, "avg_logprob": -0.19019886566834016, "compression_ratio": 1.6796536796536796, "no_speech_prob": 0.11907958984375, "words": null}, {"id": 244, "seek": 169836, "start": 1681.3200000000002, "end": 1687.44, "text": " \u00e8 solo creare un software in grado di ciarlare all'infinito il nostro scopo \u00e8 programmare un", "tokens": [50736, 4873, 6944, 1197, 543, 517, 4722, 294, 677, 1573, 1026, 6983, 6843, 543, 439, 6, 259, 5194, 3528, 1930, 35779, 795, 404, 78, 4873, 1461, 15455, 517, 51042], "temperature": 0.0, "avg_logprob": -0.19019886566834016, "compression_ratio": 1.6796536796536796, "no_speech_prob": 0.11907958984375, "words": null}, {"id": 245, "seek": 169836, "start": 1687.44, "end": 1693.2800000000002, "text": " bot che dialoghi con il proprio utente seguendo il classico approccio botta e risposta quindi", "tokens": [51042, 10592, 947, 19308, 4954, 416, 1930, 28203, 2839, 1576, 8878, 3999, 1930, 1508, 2789, 2075, 66, 8529, 10592, 1328, 308, 2253, 79, 8638, 15727, 51334], "temperature": 0.0, "avg_logprob": -0.19019886566834016, "compression_ratio": 1.6796536796536796, "no_speech_prob": 0.11907958984375, "words": null}, {"id": 246, "seek": 169836, "start": 1693.2800000000002, "end": 1698.3600000000001, "text": " dobbiamo fare in modo che il software sia in grado di capire ci\u00f2 che gli viene detto anche se qui", "tokens": [51334, 360, 6692, 7415, 11994, 294, 16664, 947, 1930, 4722, 25176, 294, 677, 1573, 1026, 1410, 621, 6983, 4293, 947, 17161, 19561, 41031, 11585, 369, 1956, 51588], "temperature": 0.0, "avg_logprob": -0.19019886566834016, "compression_ratio": 1.6796536796536796, "no_speech_prob": 0.11907958984375, "words": null}, {"id": 247, "seek": 172292, "start": 1698.3600000000001, "end": 1704.68, "text": " capire \u00e8 fra due virgolette belle grandi nel nostro caso infatti capire vuol dire in realt\u00e0", "tokens": [50364, 1410, 621, 4873, 6600, 3462, 4107, 70, 401, 3007, 28770, 45155, 15373, 35779, 9666, 1536, 21515, 1410, 621, 9732, 401, 1264, 294, 47512, 50680], "temperature": 0.0, "avg_logprob": -0.1747419702897378, "compression_ratio": 1.5916666666666666, "no_speech_prob": 0.1776123046875, "words": null}, {"id": 248, "seek": 172292, "start": 1704.68, "end": 1710.3200000000002, "text": " selezionare semplicemente le parole pi\u00f9 importanti della richiesta ed utilizzarle come gruppo di", "tokens": [50680, 369, 20336, 313, 543, 4361, 4770, 16288, 476, 26783, 10589, 1021, 72, 11618, 4593, 38804, 1257, 40355, 36153, 808, 47477, 78, 1026, 50962], "temperature": 0.0, "avg_logprob": -0.1747419702897378, "compression_ratio": 1.5916666666666666, "no_speech_prob": 0.1776123046875, "words": null}, {"id": 249, "seek": 172292, "start": 1710.3200000000002, "end": 1716.48, "text": " partenza per indirizzare la ricerca cos\u00ec come l'abbiamo descritta fino ad ora valutare l'input", "tokens": [50962, 644, 23691, 680, 1016, 347, 8072, 543, 635, 21040, 36127, 23278, 808, 287, 6, 10797, 7415, 7471, 18579, 64, 42560, 614, 33714, 1323, 325, 543, 287, 6, 259, 2582, 51270], "temperature": 0.0, "avg_logprob": -0.1747419702897378, "compression_ratio": 1.5916666666666666, "no_speech_prob": 0.1776123046875, "words": null}, {"id": 250, "seek": 172292, "start": 1716.48, "end": 1722.92, "text": " in questo modo non solo ci permetter\u00e0 di creare testi che suonino naturali ma che siano anche", "tokens": [51270, 294, 10263, 16664, 2107, 6944, 6983, 20696, 391, 1467, 1026, 1197, 543, 1500, 72, 947, 459, 266, 2982, 3303, 72, 463, 947, 262, 6254, 11585, 51592], "temperature": 0.0, "avg_logprob": -0.1747419702897378, "compression_ratio": 1.5916666666666666, "no_speech_prob": 0.1776123046875, "words": null}, {"id": 251, "seek": 174804, "start": 1722.92, "end": 1729.8400000000001, "text": " sensati rispetto a quanto richiesto dall'utente per effettuare questa scrematura esistono vari", "tokens": [50364, 2923, 6908, 2253, 42801, 257, 17820, 4593, 6495, 78, 43351, 6, 325, 1576, 680, 1244, 42747, 543, 16540, 795, 2579, 19660, 785, 468, 8957, 3034, 50710], "temperature": 0.0, "avg_logprob": -0.18719362146129795, "compression_ratio": 1.6212765957446809, "no_speech_prob": 0.287353515625, "words": null}, {"id": 252, "seek": 174804, "start": 1729.8400000000001, "end": 1735.3200000000002, "text": " metodi e tanto per capire il concetto te ne descrivo uno dei pi\u00f9 semplici che ho visto anche", "tokens": [50710, 1131, 30727, 308, 10331, 680, 1410, 621, 1930, 1588, 23778, 535, 408, 2189, 3080, 8526, 13874, 10589, 4361, 4770, 72, 947, 1106, 17558, 11585, 50984], "temperature": 0.0, "avg_logprob": -0.18719362146129795, "compression_ratio": 1.6212765957446809, "no_speech_prob": 0.287353515625, "words": null}, {"id": 253, "seek": 174804, "start": 1735.3200000000002, "end": 1742.0, "text": " applicare durante un workshop qualche mese fa anche se nella realt\u00e0 quello di chat gpt \u00e8 pi\u00f9", "tokens": [50984, 2580, 543, 14427, 517, 13541, 38737, 275, 1130, 2050, 11585, 369, 23878, 47512, 22813, 1026, 5081, 290, 662, 4873, 10589, 51318], "temperature": 0.0, "avg_logprob": -0.18719362146129795, "compression_ratio": 1.6212765957446809, "no_speech_prob": 0.287353515625, "words": null}, {"id": 254, "seek": 174804, "start": 1742.0, "end": 1748.04, "text": " complesso di cos\u00ec il processo consiste in pratica nell'utilizzare un dizionario che cataloga le", "tokens": [51318, 1209, 5557, 1026, 23278, 1930, 27939, 49066, 294, 28844, 2262, 44666, 6, 20835, 8072, 543, 517, 12098, 313, 4912, 947, 19746, 64, 476, 51620], "temperature": 0.0, "avg_logprob": -0.18719362146129795, "compression_ratio": 1.6212765957446809, "no_speech_prob": 0.287353515625, "words": null}, {"id": 255, "seek": 177488, "start": 1748.04, "end": 1754.48, "text": " parole di una lingua in base all'utilit\u00e0 le parole meno utili come ad esempio gli articoli vengono", "tokens": [50364, 26783, 1026, 2002, 22949, 4398, 294, 3096, 439, 6, 20835, 12445, 476, 26783, 40236, 2839, 2312, 808, 614, 33627, 17161, 15228, 9384, 371, 1501, 8957, 50686], "temperature": 0.0, "avg_logprob": -0.19538551485427072, "compression_ratio": 1.6378600823045268, "no_speech_prob": 0.1051025390625, "words": null}, {"id": 256, "seek": 177488, "start": 1754.48, "end": 1760.32, "text": " scartate una dopo l'altra fino a raggiungere una frase spesso sgrammaticata ma questo non importa", "tokens": [50686, 795, 446, 473, 2002, 35196, 287, 6, 38865, 42560, 257, 17539, 7834, 1063, 323, 2002, 38406, 637, 5557, 262, 1342, 25915, 3274, 463, 10263, 2107, 33218, 50978], "temperature": 0.0, "avg_logprob": -0.19538551485427072, "compression_ratio": 1.6378600823045268, "no_speech_prob": 0.1051025390625, "words": null}, {"id": 257, "seek": 177488, "start": 1760.32, "end": 1767.76, "text": " che soddisfi per\u00f2 un certo livello di importanza una volta effettuata questa operazione possiamo", "tokens": [50978, 947, 15047, 67, 4937, 72, 12673, 517, 22261, 1621, 1913, 1026, 974, 20030, 2002, 18765, 1244, 42747, 3274, 16540, 2208, 12928, 44758, 51350], "temperature": 0.0, "avg_logprob": -0.19538551485427072, "compression_ratio": 1.6378600823045268, "no_speech_prob": 0.1051025390625, "words": null}, {"id": 258, "seek": 177488, "start": 1767.76, "end": 1774.8799999999999, "text": " considerare il risultato come input di partenza per la nostra generazione del testo \u00e8 controintuitivo", "tokens": [51350, 1949, 543, 1930, 2253, 723, 2513, 808, 4846, 1026, 644, 23691, 680, 635, 34311, 1337, 12928, 1103, 1500, 78, 4873, 1583, 686, 1983, 6340, 51706], "temperature": 0.0, "avg_logprob": -0.19538551485427072, "compression_ratio": 1.6378600823045268, "no_speech_prob": 0.1051025390625, "words": null}, {"id": 259, "seek": 180292, "start": 1774.88, "end": 1785.92, "text": " ma funziona il nostro bot sembrerebbe a questo punto completo almeno da un punto di vista teorico", "tokens": [50364, 463, 49345, 21758, 1930, 35779, 10592, 4361, 1443, 323, 39042, 257, 10263, 14326, 40135, 419, 43232, 1120, 517, 14326, 1026, 22553, 40238, 2789, 50916], "temperature": 0.0, "avg_logprob": -0.20059120950398143, "compression_ratio": 1.7104072398190044, "no_speech_prob": 0.00609588623046875, "words": null}, {"id": 260, "seek": 180292, "start": 1785.92, "end": 1792.48, "text": " ma se hai provato ad utilizzare chat gpt o hai letto un po di esperimenti fatti da altri saprai", "tokens": [50916, 463, 369, 21822, 1439, 2513, 614, 40355, 543, 5081, 290, 662, 277, 21822, 718, 1353, 517, 714, 1026, 10045, 2328, 72, 283, 21515, 1120, 33707, 18985, 34554, 51244], "temperature": 0.0, "avg_logprob": -0.20059120950398143, "compression_ratio": 1.7104072398190044, "no_speech_prob": 0.00609588623046875, "words": null}, {"id": 261, "seek": 180292, "start": 1792.48, "end": 1797.8400000000001, "text": " certamente che esso \u00e8 in grado di fare molto di pi\u00f9 che rispondere con un testo sensato ad una", "tokens": [51244, 5351, 3439, 947, 2097, 78, 4873, 294, 677, 1573, 1026, 11994, 16394, 1026, 10589, 947, 2253, 79, 33447, 416, 517, 1500, 78, 2923, 2513, 614, 2002, 51512], "temperature": 0.0, "avg_logprob": -0.20059120950398143, "compression_ratio": 1.7104072398190044, "no_speech_prob": 0.00609588623046875, "words": null}, {"id": 262, "seek": 180292, "start": 1797.8400000000001, "end": 1802.92, "text": " domanda \u00e8 in grado di eseguire compiti come scrivere poesie rispondere in altre lingue", "tokens": [51512, 3285, 5575, 4873, 294, 677, 1573, 1026, 785, 1146, 43612, 715, 8707, 808, 5545, 5887, 714, 279, 414, 2253, 79, 33447, 294, 34983, 22949, 622, 51766], "temperature": 0.0, "avg_logprob": -0.20059120950398143, "compression_ratio": 1.7104072398190044, "no_speech_prob": 0.00609588623046875, "words": null}, {"id": 263, "seek": 182672, "start": 1803.2, "end": 1809.3600000000001, "text": " formulare una lista di istruzioni enunciandole come farebbe dante nella divina commedia e tante", "tokens": [50378, 49990, 543, 2002, 27764, 1026, 1418, 894, 89, 15273, 465, 11228, 1806, 306, 808, 11994, 39042, 274, 2879, 23878, 3414, 1426, 800, 14212, 308, 256, 2879, 50686], "temperature": 0.0, "avg_logprob": -0.19885023598963358, "compression_ratio": 1.6521739130434783, "no_speech_prob": 0.001956939697265625, "words": null}, {"id": 264, "seek": 182672, "start": 1809.3600000000001, "end": 1815.1000000000001, "text": " altre cose simili sono questi forse gli aspetti che pi\u00f9 di tutti hanno tratto in inganno tante", "tokens": [50686, 34983, 30261, 1034, 2312, 9259, 29729, 337, 405, 17161, 16817, 12495, 947, 10589, 1026, 19822, 26595, 21507, 1353, 294, 3957, 13484, 256, 2879, 50973], "temperature": 0.0, "avg_logprob": -0.19885023598963358, "compression_ratio": 1.6521739130434783, "no_speech_prob": 0.001956939697265625, "words": null}, {"id": 265, "seek": 182672, "start": 1815.1000000000001, "end": 1820.48, "text": " persone dando l'impressione che per svolgere compiti del genere sia necessaria una sorta di", "tokens": [50973, 29944, 29854, 287, 6, 36107, 68, 947, 680, 262, 9646, 34899, 715, 8707, 1103, 41553, 25176, 2688, 9831, 2002, 33425, 1026, 51242], "temperature": 0.0, "avg_logprob": -0.19885023598963358, "compression_ratio": 1.6521739130434783, "no_speech_prob": 0.001956939697265625, "words": null}, {"id": 266, "seek": 182672, "start": 1820.48, "end": 1826.72, "text": " intelligenza simile a quella umana ma in verit\u00e0 per raggiungere un tale livello di complessit\u00e0", "tokens": [51242, 4359, 3213, 2394, 1034, 794, 257, 32234, 1105, 2095, 463, 294, 1306, 12445, 680, 17539, 7834, 1063, 323, 517, 17172, 1621, 1913, 1026, 1209, 442, 12445, 51554], "temperature": 0.0, "avg_logprob": -0.19885023598963358, "compression_ratio": 1.6521739130434783, "no_speech_prob": 0.001956939697265625, "words": null}, {"id": 267, "seek": 185604, "start": 1826.72, "end": 1833.52, "text": " al nostro bot non serve pensare non gli serve ragionare n\u00e9 inventare alcunch\u00e9 basta solo che", "tokens": [50364, 419, 35779, 10592, 2107, 4596, 6099, 543, 2107, 17161, 4596, 17539, 313, 543, 7024, 7962, 543, 20005, 1680, 526, 45282, 6944, 947, 50704], "temperature": 0.0, "avg_logprob": -0.2374415865568357, "compression_ratio": 1.6939655172413792, "no_speech_prob": 0.2039794921875, "words": null}, {"id": 268, "seek": 185604, "start": 1833.52, "end": 1839.96, "text": " noi aumentiamo il numero di testi a cui attingere da una parte e il numero di regole del sistema di", "tokens": [50704, 22447, 17128, 7415, 1930, 46839, 1026, 1500, 72, 257, 22929, 412, 783, 323, 1120, 2002, 6975, 308, 1930, 46839, 1026, 1121, 4812, 1103, 13245, 1026, 51026], "temperature": 0.0, "avg_logprob": -0.2374415865568357, "compression_ratio": 1.6939655172413792, "no_speech_prob": 0.2039794921875, "words": null}, {"id": 269, "seek": 185604, "start": 1839.96, "end": 1847.84, "text": " voting dall'altra per il numero di testi beh openai sfruttando un super elaboratore realizzato", "tokens": [51026, 10419, 43351, 6, 38865, 680, 1930, 46839, 1026, 1500, 72, 1540, 1269, 1301, 262, 5779, 13478, 1806, 517, 1687, 16298, 43148, 957, 8072, 2513, 51420], "temperature": 0.0, "avg_logprob": -0.2374415865568357, "compression_ratio": 1.6939655172413792, "no_speech_prob": 0.2039794921875, "words": null}, {"id": 270, "seek": 185604, "start": 1847.84, "end": 1856.04, "text": " appositamente da microsoft ha potuto dare in passo a chat gpt una quantit\u00e0 enorme di dati non che pare", "tokens": [51420, 724, 9598, 3439, 1120, 3123, 7856, 324, 1847, 8262, 8955, 294, 38159, 257, 5081, 290, 662, 2002, 4426, 12445, 33648, 1026, 1137, 72, 2107, 947, 7448, 51830], "temperature": 0.0, "avg_logprob": -0.2374415865568357, "compression_ratio": 1.6939655172413792, "no_speech_prob": 0.2039794921875, "words": null}, {"id": 271, "seek": 188464, "start": 1856.56, "end": 1861.92, "text": " tutto il web disponibile fino a qualche mese fa mentre noi dal canto nostro per il nostro", "tokens": [50390, 23048, 1930, 3670, 23311, 30898, 42560, 257, 38737, 275, 1130, 2050, 49601, 22447, 11702, 393, 1353, 35779, 680, 1930, 35779, 50658], "temperature": 0.0, "avg_logprob": -0.19800204576038924, "compression_ratio": 1.7432950191570882, "no_speech_prob": 0.0004239082336425781, "words": null}, {"id": 272, "seek": 188464, "start": 1861.92, "end": 1867.32, "text": " esperimento mentale dobbiamo semplicemente immaginare di avere a disposizione una biblioteca", "tokens": [50658, 10045, 10030, 3074, 1220, 360, 6692, 7415, 4361, 4770, 16288, 3397, 559, 259, 543, 1026, 37914, 257, 15885, 35740, 2002, 34344, 1370, 496, 50928], "temperature": 0.0, "avg_logprob": -0.19800204576038924, "compression_ratio": 1.7432950191570882, "no_speech_prob": 0.0004239082336425781, "words": null}, {"id": 273, "seek": 188464, "start": 1867.32, "end": 1873.3999999999999, "text": " che comprenda gran parte dello scibile umano cartaceo o digitale che sia per il numero di", "tokens": [50928, 947, 30765, 64, 9370, 6975, 368, 1913, 2180, 65, 794, 1105, 3730, 5467, 617, 78, 277, 14293, 1220, 947, 25176, 680, 1930, 46839, 1026, 51232], "temperature": 0.0, "avg_logprob": -0.19800204576038924, "compression_ratio": 1.7432950191570882, "no_speech_prob": 0.0004239082336425781, "words": null}, {"id": 274, "seek": 188464, "start": 1873.3999999999999, "end": 1879.72, "text": " regole invece il discorso \u00e8 un po pi\u00f9 complesso sarebbe umanamente impossibile progettare tutte", "tokens": [51232, 1121, 4812, 36344, 1930, 2983, 284, 539, 4873, 517, 714, 10589, 1209, 5557, 38706, 39042, 1105, 282, 3439, 38802, 30898, 447, 847, 83, 543, 38632, 51548], "temperature": 0.0, "avg_logprob": -0.19800204576038924, "compression_ratio": 1.7432950191570882, "no_speech_prob": 0.0004239082336425781, "words": null}, {"id": 275, "seek": 188464, "start": 1879.72, "end": 1884.6399999999999, "text": " quelle necessarie a coprire ogni possibile combinazione di richieste potrebbe sempre", "tokens": [51548, 29237, 2688, 289, 414, 257, 2971, 38920, 33189, 50184, 38514, 12928, 1026, 4593, 6495, 68, 1847, 39487, 9553, 51794], "temperature": 0.0, "avg_logprob": -0.19800204576038924, "compression_ratio": 1.7432950191570882, "no_speech_prob": 0.0004239082336425781, "words": null}, {"id": 276, "seek": 190876, "start": 1884.8400000000001, "end": 1890.96, "text": " arrivare qualcuno a chiedere di progettare un codice di leggi per una societ\u00e0 in cui le", "tokens": [50374, 30697, 543, 32101, 12638, 257, 417, 1091, 323, 1026, 447, 847, 83, 543, 517, 17656, 573, 1026, 476, 22771, 680, 2002, 14051, 1467, 294, 22929, 476, 50680], "temperature": 0.0, "avg_logprob": -0.18779205356802897, "compression_ratio": 1.6724890829694323, "no_speech_prob": 0.0267486572265625, "words": null}, {"id": 277, "seek": 190876, "start": 1890.96, "end": 1897.2, "text": " giraffe sono la specie pi\u00f9 evoluta e dominante ad esempio quindi appare subito chiaro che stilare a", "tokens": [50680, 14703, 23629, 9259, 635, 1608, 414, 10589, 1073, 2308, 64, 308, 8859, 2879, 614, 33627, 15727, 724, 543, 1422, 3528, 47454, 78, 947, 342, 388, 543, 257, 50992], "temperature": 0.0, "avg_logprob": -0.18779205356802897, "compression_ratio": 1.6724890829694323, "no_speech_prob": 0.0267486572265625, "words": null}, {"id": 278, "seek": 190876, "start": 1897.2, "end": 1902.8000000000002, "text": " mano un catalogo completo di regole \u00e8 praticamente irrealizzabile considerando che la loro quantit\u00e0", "tokens": [50992, 18384, 517, 19746, 78, 40135, 1026, 1121, 4812, 4873, 45734, 3418, 9342, 8072, 33288, 1949, 1806, 947, 635, 28810, 4426, 12445, 51272], "temperature": 0.0, "avg_logprob": -0.18779205356802897, "compression_ratio": 1.6724890829694323, "no_speech_prob": 0.0267486572265625, "words": null}, {"id": 279, "seek": 190876, "start": 1902.8000000000002, "end": 1908.76, "text": " sarebbe enorme e la complessit\u00e0 di una singola regola potrebbe anche essere notevole ma la", "tokens": [51272, 38706, 39042, 33648, 308, 635, 1209, 442, 12445, 1026, 2002, 1522, 4711, 1121, 4711, 1847, 39487, 11585, 19799, 3637, 3080, 306, 463, 635, 51570], "temperature": 0.0, "avg_logprob": -0.18779205356802897, "compression_ratio": 1.6724890829694323, "no_speech_prob": 0.0267486572265625, "words": null}, {"id": 280, "seek": 193424, "start": 1908.76, "end": 1915.84, "text": " soluzione \u00e8 in realt\u00e0 molto pi\u00f9 semplice di quanto possa sembrare serve infatti un bel po di", "tokens": [50364, 1404, 3334, 5328, 4873, 294, 47512, 16394, 10589, 4361, 564, 573, 1026, 17820, 41564, 20775, 35559, 4596, 1536, 21515, 517, 989, 714, 1026, 50718], "temperature": 0.0, "avg_logprob": -0.22553065616004872, "compression_ratio": 1.6302521008403361, "no_speech_prob": 0.429443359375, "words": null}, {"id": 281, "seek": 193424, "start": 1915.84, "end": 1921.0, "text": " potenza di calcolo ma si pu\u00f2 fare in modo che il bot generi da solo tutte le regole di cui ha", "tokens": [50718, 1847, 23691, 1026, 2104, 46086, 463, 1511, 26526, 11994, 294, 16664, 947, 1930, 10592, 1337, 72, 1120, 6944, 38632, 476, 1121, 4812, 1026, 22929, 324, 50976], "temperature": 0.0, "avg_logprob": -0.22553065616004872, "compression_ratio": 1.6302521008403361, "no_speech_prob": 0.429443359375, "words": null}, {"id": 282, "seek": 193424, "start": 1921.0, "end": 1928.08, "text": " bisogno il concetto \u00e8 noto come auto apprendimento non \u00e8 nulla di nuovo nel campo dei large language", "tokens": [50976, 40505, 1771, 1930, 1588, 23778, 4873, 406, 78, 808, 8399, 724, 4542, 10030, 2107, 4873, 18184, 64, 1026, 49348, 15373, 29691, 13874, 2416, 2856, 51330], "temperature": 0.0, "avg_logprob": -0.22553065616004872, "compression_ratio": 1.6302521008403361, "no_speech_prob": 0.429443359375, "words": null}, {"id": 283, "seek": 193424, "start": 1928.08, "end": 1934.24, "text": " model e supergio funziona in questo modo si mette a lavorare un sistema su un gruppo di regole", "tokens": [51330, 2316, 308, 1687, 17862, 49345, 21758, 294, 10263, 16664, 1511, 1131, 975, 257, 29241, 543, 517, 13245, 459, 517, 47477, 78, 1026, 1121, 4812, 51638], "temperature": 0.0, "avg_logprob": -0.22553065616004872, "compression_ratio": 1.6302521008403361, "no_speech_prob": 0.429443359375, "words": null}, {"id": 284, "seek": 196060, "start": 1934.48, "end": 1941.4, "text": " presso che casuali e utilizzando una selezione di testi dalla base dati si fa in modo che il", "tokens": [50376, 1183, 539, 947, 13052, 72, 308, 40355, 1806, 2002, 23264, 19706, 1026, 1500, 72, 35566, 3096, 1137, 72, 1511, 2050, 294, 16664, 947, 1930, 50722], "temperature": 0.0, "avg_logprob": -0.21948013573049385, "compression_ratio": 1.6875, "no_speech_prob": 0.1707763671875, "words": null}, {"id": 285, "seek": 196060, "start": 1941.4, "end": 1948.24, "text": " sistema corregga poco a poco le regole so che sembra impossibile ma facciamo un semplice esempio", "tokens": [50722, 13245, 29731, 33462, 10639, 257, 10639, 476, 1121, 4812, 370, 947, 20775, 424, 38802, 30898, 463, 1915, 42052, 517, 4361, 564, 573, 33627, 51064], "temperature": 0.0, "avg_logprob": -0.21948013573049385, "compression_ratio": 1.6875, "no_speech_prob": 0.1707763671875, "words": null}, {"id": 286, "seek": 196060, "start": 1948.24, "end": 1954.6, "text": " prendiamo la prima frase della divina commedia che tutti conosciamo che nel mezzo del cammin", "tokens": [51064, 9866, 7415, 635, 19507, 38406, 11618, 3414, 1426, 800, 14212, 947, 19822, 49892, 42052, 947, 15373, 385, 35130, 1103, 1945, 2367, 51382], "temperature": 0.0, "avg_logprob": -0.21948013573049385, "compression_ratio": 1.6875, "no_speech_prob": 0.1707763671875, "words": null}, {"id": 287, "seek": 196060, "start": 1954.6, "end": 1960.6, "text": " di nostra vita mi ritrovai per una selva oscura che la dritta via era smarrita l'idea \u00e8 quella", "tokens": [51382, 1026, 34311, 32712, 2752, 11289, 24088, 1301, 680, 2002, 5851, 2757, 3003, 66, 2991, 947, 635, 1224, 21870, 5766, 4249, 899, 2284, 2786, 287, 6, 482, 64, 4873, 32234, 51682], "temperature": 0.0, "avg_logprob": -0.21948013573049385, "compression_ratio": 1.6875, "no_speech_prob": 0.1707763671875, "words": null}, {"id": 288, "seek": 198648, "start": 1960.6000000000001, "end": 1967.0000000000002, "text": " di provare a cercare le parole della frase ad esempio cercando nel cammin di nostra ci", "tokens": [50364, 1026, 1439, 543, 257, 10146, 5685, 476, 26783, 11618, 38406, 614, 33627, 36099, 1806, 15373, 1945, 2367, 1026, 34311, 6983, 50684], "temperature": 0.0, "avg_logprob": -0.18399532292490808, "compression_ratio": 1.6849315068493151, "no_speech_prob": 0.11907958984375, "words": null}, {"id": 289, "seek": 198648, "start": 1967.0000000000002, "end": 1973.4800000000002, "text": " aspetteremo di individuare la parola vita ma con le regole casuali impostate inizialmente", "tokens": [50684, 16817, 3093, 323, 3280, 1026, 2461, 84, 543, 635, 971, 4711, 32712, 463, 416, 476, 1121, 4812, 13052, 72, 47804, 473, 294, 590, 831, 4082, 51008], "temperature": 0.0, "avg_logprob": -0.18399532292490808, "compression_ratio": 1.6849315068493151, "no_speech_prob": 0.11907958984375, "words": null}, {"id": 290, "seek": 198648, "start": 1973.4800000000002, "end": 1979.72, "text": " immaginiamo che il nostro llm tiri fuori per qualche motivo la parola nonna chiss\u00e0 da quale", "tokens": [51008, 3397, 559, 259, 7415, 947, 1930, 35779, 4849, 76, 256, 12988, 8536, 7386, 680, 38737, 35804, 635, 971, 4711, 2107, 629, 417, 891, 1467, 1120, 421, 1220, 51320], "temperature": 0.0, "avg_logprob": -0.18399532292490808, "compression_ratio": 1.6849315068493151, "no_speech_prob": 0.11907958984375, "words": null}, {"id": 291, "seek": 198648, "start": 1979.72, "end": 1986.4800000000002, "text": " testo a questo punto essendo in fase di auto apprendimento l'algoritmo confronter\u00e0 automaticamente", "tokens": [51320, 1500, 78, 257, 10263, 14326, 2097, 3999, 294, 33931, 1026, 8399, 724, 4542, 10030, 287, 6, 20422, 50017, 3280, 1497, 2044, 391, 1467, 12509, 3439, 51658], "temperature": 0.0, "avg_logprob": -0.18399532292490808, "compression_ratio": 1.6849315068493151, "no_speech_prob": 0.11907958984375, "words": null}, {"id": 292, "seek": 201096, "start": 1986.48, "end": 1992.64, "text": " la risposta nonna con la parola vita che sa essere quella giusta si accorger\u00e0 che le due non", "tokens": [50364, 635, 2253, 79, 8638, 2107, 629, 416, 635, 971, 4711, 32712, 947, 601, 19799, 32234, 1735, 28652, 1511, 1317, 284, 1321, 1467, 947, 476, 3462, 2107, 50672], "temperature": 0.0, "avg_logprob": -0.16519765670482928, "compression_ratio": 1.7106382978723405, "no_speech_prob": 0.0655517578125, "words": null}, {"id": 293, "seek": 201096, "start": 1992.64, "end": 1999.48, "text": " coincidono e che quindi la ricerca ha prodotto un risultato sbagliato e come conseguenza cambier\u00e0", "tokens": [50672, 13001, 327, 8957, 308, 947, 15727, 635, 21040, 36127, 324, 15792, 18838, 517, 2253, 723, 2513, 262, 17282, 2081, 2513, 308, 808, 12706, 23691, 18751, 811, 1467, 51014], "temperature": 0.0, "avg_logprob": -0.16519765670482928, "compression_ratio": 1.7106382978723405, "no_speech_prob": 0.0655517578125, "words": null}, {"id": 294, "seek": 201096, "start": 1999.48, "end": 2005.88, "text": " leggermente alcune regole e riprover\u00e0 andr\u00e0 avanti cos\u00ec a provare e riprovare per centinaia di volte", "tokens": [51014, 1676, 1321, 4082, 20005, 2613, 1121, 4812, 308, 12782, 340, 331, 1467, 293, 39212, 1305, 11520, 23278, 257, 1439, 543, 308, 12782, 24088, 543, 680, 1489, 1426, 654, 1026, 37801, 51334], "temperature": 0.0, "avg_logprob": -0.16519765670482928, "compression_ratio": 1.7106382978723405, "no_speech_prob": 0.0655517578125, "words": null}, {"id": 295, "seek": 201096, "start": 2005.88, "end": 2010.96, "text": " finch\u00e9 la parola che viene fuori dalla ricerca non sar\u00e0 effettivamente vita ripetendo questa operazione", "tokens": [51334, 962, 11131, 635, 971, 4711, 947, 19561, 8536, 7386, 35566, 21040, 36127, 2107, 41338, 1244, 3093, 23957, 32712, 12782, 302, 3999, 16540, 2208, 12928, 51588], "temperature": 0.0, "avg_logprob": -0.16519765670482928, "compression_ratio": 1.7106382978723405, "no_speech_prob": 0.0655517578125, "words": null}, {"id": 296, "seek": 203604, "start": 2011.44, "end": 2016.92, "text": " per un numero sufficiente di volte su un numero sufficiente di esempi dove sufficiente vuol dire", "tokens": [50388, 680, 517, 46839, 11563, 68, 1026, 37801, 459, 517, 46839, 11563, 68, 1026, 32340, 72, 23287, 11563, 68, 9732, 401, 1264, 50662], "temperature": 0.0, "avg_logprob": -0.1848958282283059, "compression_ratio": 1.7297297297297298, "no_speech_prob": 0.09796142578125, "words": null}, {"id": 297, "seek": 203604, "start": 2016.92, "end": 2024.6000000000001, "text": " milioni o addirittura miliardi il catalogo delle regole diverr\u00e0 sempre pi\u00f9 grande e accurato e nel", "tokens": [50662, 1962, 15273, 277, 909, 347, 593, 2991, 1962, 72, 38126, 1930, 19746, 78, 16485, 1121, 4812, 3414, 260, 39212, 9553, 10589, 8883, 308, 5771, 2513, 308, 15373, 51046], "temperature": 0.0, "avg_logprob": -0.1848958282283059, "compression_ratio": 1.7297297297297298, "no_speech_prob": 0.09796142578125, "words": null}, {"id": 298, "seek": 203604, "start": 2024.6000000000001, "end": 2029.96, "text": " momento in cui noi chiederemo al nostro bot di scrivere la ricetta della carbonara in terzine", "tokens": [51046, 9333, 294, 22929, 22447, 417, 1091, 323, 3280, 419, 35779, 10592, 1026, 5545, 5887, 635, 21040, 16593, 11618, 5954, 2419, 294, 1796, 89, 533, 51314], "temperature": 0.0, "avg_logprob": -0.1848958282283059, "compression_ratio": 1.7297297297297298, "no_speech_prob": 0.09796142578125, "words": null}, {"id": 299, "seek": 203604, "start": 2029.96, "end": 2036.04, "text": " dantesche lui sar\u00e0 in grado di selezionare una serie di parole che si adattino a rispondere", "tokens": [51314, 274, 9327, 1876, 8783, 41338, 294, 677, 1573, 1026, 369, 20336, 313, 543, 2002, 23030, 1026, 26783, 947, 1511, 614, 1591, 2982, 257, 2253, 79, 33447, 51618], "temperature": 0.0, "avg_logprob": -0.1848958282283059, "compression_ratio": 1.7297297297297298, "no_speech_prob": 0.09796142578125, "words": null}, {"id": 300, "seek": 206600, "start": 2036.04, "end": 2046.0, "text": " alla nostra domanda. Infine giuro \u00e8 l'ultimo passaggio abbiamo finito dobbiamo mettere ora", "tokens": [50364, 11591, 34311, 3285, 5575, 13, 11537, 533, 1735, 7052, 4873, 287, 6, 723, 6934, 1320, 30763, 22815, 962, 3528, 360, 6692, 7415, 27812, 323, 33714, 50862], "temperature": 0.0, "avg_logprob": -0.1782852497875181, "compression_ratio": 1.625514403292181, "no_speech_prob": 0.0301971435546875, "words": null}, {"id": 301, "seek": 206600, "start": 2046.0, "end": 2053.24, "text": " tutto insieme e ricapitolare il processo. Il nostro bot riceve un testo in input e lo prepara facendolo", "tokens": [50862, 23048, 1028, 44940, 308, 21040, 569, 21086, 543, 1930, 27939, 13, 4416, 35779, 10592, 5090, 303, 517, 1500, 78, 294, 4846, 308, 450, 8231, 64, 1915, 521, 7902, 51224], "temperature": 0.0, "avg_logprob": -0.1782852497875181, "compression_ratio": 1.625514403292181, "no_speech_prob": 0.0301971435546875, "words": null}, {"id": 302, "seek": 206600, "start": 2053.24, "end": 2059.04, "text": " passare attraverso una rete neurale che come una versione potentissima dei dizionari menzionati", "tokens": [51224, 1320, 543, 951, 424, 331, 539, 2002, 319, 975, 12087, 1220, 947, 808, 2002, 3037, 68, 27073, 891, 4775, 13874, 12098, 313, 3504, 1706, 89, 313, 6908, 51514], "temperature": 0.0, "avg_logprob": -0.1782852497875181, "compression_ratio": 1.625514403292181, "no_speech_prob": 0.0301971435546875, "words": null}, {"id": 303, "seek": 206600, "start": 2059.04, "end": 2066.0, "text": " prima seleziona le parole pi\u00f9 importanti assegnando a ciascuna un valore di importanza appunto un peso", "tokens": [51514, 19507, 369, 20336, 21758, 476, 26783, 10589, 1021, 72, 5907, 4568, 1806, 257, 269, 4609, 66, 5051, 517, 1323, 418, 1026, 974, 20030, 724, 24052, 517, 28149, 51862], "temperature": 0.0, "avg_logprob": -0.1782852497875181, "compression_ratio": 1.625514403292181, "no_speech_prob": 0.0301971435546875, "words": null}, {"id": 304, "seek": 209324, "start": 2066.72, "end": 2073.36, "text": " una volta ottenuto questo elenco di parole pesate esso viene utilizzato per avviare una ricerca nel", "tokens": [50400, 2002, 18765, 4337, 1147, 8262, 10263, 806, 268, 1291, 1026, 26783, 9262, 473, 2097, 78, 19561, 40355, 2513, 680, 1305, 4917, 543, 2002, 21040, 36127, 15373, 50732], "temperature": 0.0, "avg_logprob": -0.1744552741356946, "compression_ratio": 1.7035398230088497, "no_speech_prob": 0.00013136863708496094, "words": null}, {"id": 305, "seek": 209324, "start": 2073.36, "end": 2080.76, "text": " large language model che grazie ai pesi riesce anche a selezionare quali regole far prevalere", "tokens": [50732, 2416, 2856, 2316, 947, 1295, 3283, 9783, 9262, 72, 23932, 384, 11585, 257, 369, 20336, 313, 543, 4101, 72, 1121, 4812, 1400, 22239, 323, 51102], "temperature": 0.0, "avg_logprob": -0.1744552741356946, "compression_ratio": 1.7035398230088497, "no_speech_prob": 0.00013136863708496094, "words": null}, {"id": 306, "seek": 209324, "start": 2080.76, "end": 2087.96, "text": " durante l'esecuzione. Al termine di tutto questo processo la ricerca produce una parola questa", "tokens": [51102, 14427, 287, 6, 1130, 49789, 5328, 13, 967, 1433, 533, 1026, 23048, 10263, 27939, 635, 21040, 36127, 5258, 2002, 971, 4711, 16540, 51462], "temperature": 0.0, "avg_logprob": -0.1744552741356946, "compression_ratio": 1.7035398230088497, "no_speech_prob": 0.00013136863708496094, "words": null}, {"id": 307, "seek": 209324, "start": 2087.96, "end": 2093.24, "text": " parola viene aggiunta al testo in input e tutto il giro ricomincia da capo considerando l'elenco", "tokens": [51462, 971, 4711, 19561, 42254, 46380, 419, 1500, 78, 294, 4846, 308, 23048, 1930, 1735, 340, 21040, 6981, 2755, 1120, 1410, 78, 1949, 1806, 287, 6, 14818, 1291, 51726], "temperature": 0.0, "avg_logprob": -0.1744552741356946, "compression_ratio": 1.7035398230088497, "no_speech_prob": 0.00013136863708496094, "words": null}, {"id": 308, "seek": 211852, "start": 2093.2400000000002, "end": 2099.92, "text": " aggiornato ad ogni iterazione il testo diventa pi\u00f9 lungo di una parola finch\u00e9 non viene generato", "tokens": [50364, 42254, 1865, 2513, 614, 33189, 17138, 12928, 1930, 1500, 78, 3414, 8938, 10589, 16730, 78, 1026, 2002, 971, 4711, 962, 11131, 2107, 19561, 1337, 2513, 50698], "temperature": 0.0, "avg_logprob": -0.17624628153585253, "compression_ratio": 1.5274725274725274, "no_speech_prob": 0.0174407958984375, "words": null}, {"id": 309, "seek": 211852, "start": 2099.92, "end": 2112.6400000000003, "text": " un testo di risposta con le caratteristiche richieste. Chiaramente ho dovuto sorvolare", "tokens": [50698, 517, 1500, 78, 1026, 2253, 79, 8638, 416, 476, 1032, 1161, 468, 9304, 4593, 6495, 68, 13, 761, 9448, 3439, 1106, 30870, 8262, 9359, 9646, 543, 51334], "temperature": 0.0, "avg_logprob": -0.17624628153585253, "compression_ratio": 1.5274725274725274, "no_speech_prob": 0.0174407958984375, "words": null}, {"id": 310, "seek": 211852, "start": 2112.6400000000003, "end": 2118.5200000000004, "text": " su tanti aspetti e semplificarne altri ma tutto sommato a questo punto se mi sono spiegato a", "tokens": [51334, 459, 256, 11520, 16817, 12495, 308, 4361, 564, 25625, 716, 33707, 463, 23048, 41854, 2513, 257, 10263, 14326, 369, 2752, 9259, 637, 20408, 2513, 257, 51628], "temperature": 0.0, "avg_logprob": -0.17624628153585253, "compression_ratio": 1.5274725274725274, "no_speech_prob": 0.0174407958984375, "words": null}, {"id": 311, "seek": 214456, "start": 2118.52, "end": 2126.36, "text": " dovere dovrebbe essere chiaro un fatto abbastanza importante e cio\u00e8 che un bot come chat gpt o in", "tokens": [50364, 360, 5887, 30870, 39487, 19799, 47454, 78, 517, 23228, 16903, 525, 20030, 9416, 308, 41827, 947, 517, 10592, 808, 5081, 290, 662, 277, 294, 50756], "temperature": 0.0, "avg_logprob": -0.24371188297504331, "compression_ratio": 1.5904255319148937, "no_speech_prob": 0.239013671875, "words": null}, {"id": 312, "seek": 214456, "start": 2126.36, "end": 2136.08, "text": " generale un llm come gpt o bardo quello che sia non crea proprio nulla semplicemente imita \u00e8 di", "tokens": [50756, 1337, 1220, 517, 4849, 76, 808, 290, 662, 277, 7685, 78, 22813, 947, 25176, 2107, 1197, 64, 28203, 18184, 64, 4361, 4770, 16288, 566, 2786, 4873, 1026, 51242], "temperature": 0.0, "avg_logprob": -0.24371188297504331, "compression_ratio": 1.5904255319148937, "no_speech_prob": 0.239013671875, "words": null}, {"id": 313, "seek": 214456, "start": 2136.08, "end": 2144.56, "text": " fatto un selezionatore di parole su base statistica molto grande molto potente ma niente pi\u00f9 di questo", "tokens": [51242, 23228, 517, 369, 20336, 313, 43148, 1026, 26783, 459, 3096, 16012, 2262, 16394, 8883, 16394, 1847, 1576, 463, 297, 8413, 10589, 1026, 10263, 51666], "temperature": 0.0, "avg_logprob": -0.24371188297504331, "compression_ratio": 1.5904255319148937, "no_speech_prob": 0.239013671875, "words": null}, {"id": 314, "seek": 217328, "start": 2144.56, "end": 2152.48, "text": " copia manipola e unisce testi che gi\u00e0 esistono non \u00e8 minimamente in grado di pensare o di formulare", "tokens": [50364, 2971, 654, 9258, 4711, 308, 517, 49596, 1500, 72, 947, 30469, 785, 468, 8957, 2107, 4873, 4464, 3439, 294, 677, 1573, 1026, 6099, 543, 277, 1026, 49990, 543, 50760], "temperature": 0.0, "avg_logprob": -0.18776260028366282, "compression_ratio": 1.7692307692307692, "no_speech_prob": 0.0288543701171875, "words": null}, {"id": 315, "seek": 217328, "start": 2152.48, "end": 2157.88, "text": " idee ma nemmeno di capire il senso dei testi che riceve in input o di quelli che genera in output", "tokens": [50760, 49742, 463, 408, 2174, 5808, 1026, 1410, 621, 1930, 3151, 539, 13874, 1500, 72, 947, 5090, 303, 294, 4846, 277, 1026, 631, 16320, 947, 1337, 64, 294, 5598, 51030], "temperature": 0.0, "avg_logprob": -0.18776260028366282, "compression_ratio": 1.7692307692307692, "no_speech_prob": 0.0288543701171875, "words": null}, {"id": 316, "seek": 217328, "start": 2157.88, "end": 2165.44, "text": " ed \u00e8 questo forse il punto cruciale di tutto l'episodio per come \u00e8 stato ampiamente descritto", "tokens": [51030, 1257, 4873, 10263, 337, 405, 1930, 14326, 11462, 68, 1026, 23048, 287, 6, 595, 271, 378, 1004, 680, 808, 4873, 29657, 18648, 16855, 7471, 18579, 78, 51408], "temperature": 0.0, "avg_logprob": -0.18776260028366282, "compression_ratio": 1.7692307692307692, "no_speech_prob": 0.0288543701171875, "words": null}, {"id": 317, "seek": 217328, "start": 2165.44, "end": 2173.2799999999997, "text": " per come \u00e8 stato posto in termini grafici e per come \u00e8 stato pubblicizzato e diffuso chat gpt", "tokens": [51408, 680, 808, 4873, 29657, 2183, 78, 294, 1433, 3812, 1295, 1786, 72, 308, 680, 808, 4873, 29657, 1535, 11489, 8072, 2513, 308, 7593, 24431, 5081, 290, 662, 51800], "temperature": 0.0, "avg_logprob": -0.18776260028366282, "compression_ratio": 1.7692307692307692, "no_speech_prob": 0.0288543701171875, "words": null}, {"id": 318, "seek": 220288, "start": 2173.28, "end": 2180.44, "text": " trasmette un'enorme sicurezza la sicurezza che trasmette una persona molto intelligente ed esperta", "tokens": [50364, 504, 14774, 3007, 517, 6, 268, 687, 68, 33579, 540, 26786, 635, 33579, 540, 26786, 947, 504, 14774, 3007, 2002, 12184, 16394, 5613, 1576, 1257, 10045, 1328, 50722], "temperature": 0.0, "avg_logprob": -0.19974661571485502, "compression_ratio": 1.7433628318584071, "no_speech_prob": 0.042694091796875, "words": null}, {"id": 319, "seek": 220288, "start": 2180.44, "end": 2187.44, "text": " dell'argomento di cui sta parlando ma la verit\u00e0 \u00e8 che si tratta solamente di una facciata una bugia", "tokens": [50722, 19781, 6, 289, 30851, 15467, 1026, 22929, 11135, 971, 16201, 463, 635, 1306, 12445, 4873, 947, 1511, 504, 18405, 27814, 1026, 2002, 1915, 537, 3274, 2002, 7426, 654, 51072], "temperature": 0.0, "avg_logprob": -0.19974661571485502, "compression_ratio": 1.7433628318584071, "no_speech_prob": 0.042694091796875, "words": null}, {"id": 320, "seek": 220288, "start": 2187.44, "end": 2194.6800000000003, "text": " sorretta unicamente dal fatto che statisticamente molto spesso una parola ne segue un'altra rosso", "tokens": [51072, 9359, 1505, 1328, 517, 23653, 11702, 23228, 947, 29588, 3439, 16394, 637, 5557, 2002, 971, 4711, 408, 33850, 517, 6, 38865, 18953, 539, 51434], "temperature": 0.0, "avg_logprob": -0.19974661571485502, "compression_ratio": 1.7433628318584071, "no_speech_prob": 0.042694091796875, "words": null}, {"id": 321, "seek": 220288, "start": 2194.6800000000003, "end": 2202.88, "text": " di sera ecco se hai pensato bel tempo si spera hai applicato lo stesso principio ho voluto fare", "tokens": [51434, 1026, 15021, 11437, 1291, 369, 21822, 6099, 2513, 989, 8972, 1511, 24152, 64, 21822, 2580, 2513, 450, 44413, 34308, 1106, 1996, 8262, 11994, 51844], "temperature": 0.0, "avg_logprob": -0.19974661571485502, "compression_ratio": 1.7433628318584071, "no_speech_prob": 0.042694091796875, "words": null}, {"id": 322, "seek": 222900, "start": 2202.88, "end": 2209.8, "text": " tutto questo discorso e provare a descrivere come funziona il sistema gpt perch\u00e9 ritengo importante", "tokens": [50364, 23048, 10263, 2983, 284, 539, 308, 1439, 543, 257, 2189, 5887, 808, 49345, 21758, 1930, 13245, 290, 662, 14303, 11289, 30362, 9416, 50710], "temperature": 0.0, "avg_logprob": -0.21448863365433432, "compression_ratio": 1.6523605150214593, "no_speech_prob": 0.00164794921875, "words": null}, {"id": 323, "seek": 222900, "start": 2209.8, "end": 2216.6400000000003, "text": " che chi ci ha e ci avr\u00e0 a che fare in qualche modo tenga sempre bene a mente i suoi limiti", "tokens": [50710, 947, 13228, 6983, 324, 308, 6983, 1305, 39212, 257, 947, 11994, 294, 38737, 16664, 36031, 9553, 2537, 257, 26577, 741, 459, 4869, 4948, 72, 51052], "temperature": 0.0, "avg_logprob": -0.21448863365433432, "compression_ratio": 1.6523605150214593, "no_speech_prob": 0.00164794921875, "words": null}, {"id": 324, "seek": 222900, "start": 2216.6400000000003, "end": 2223.32, "text": " viviamo in un periodo storico molto importante stiamo attraversando un momento fantastico per", "tokens": [51052, 11005, 7415, 294, 517, 2896, 78, 5967, 2789, 16394, 9416, 342, 7415, 951, 424, 840, 1806, 517, 9333, 5456, 78, 680, 51386], "temperature": 0.0, "avg_logprob": -0.21448863365433432, "compression_ratio": 1.6523605150214593, "no_speech_prob": 0.00164794921875, "words": null}, {"id": 325, "seek": 222900, "start": 2223.32, "end": 2229.0, "text": " ci\u00f2 che riguarda il progresso tecnologico anche e soprattutto nel campo del machine learning fino", "tokens": [51386, 6983, 4293, 947, 8329, 16981, 64, 1930, 447, 70, 29652, 20105, 1132, 2789, 11585, 308, 50002, 15373, 29691, 1103, 3479, 2539, 42560, 51670], "temperature": 0.0, "avg_logprob": -0.21448863365433432, "compression_ratio": 1.6523605150214593, "no_speech_prob": 0.00164794921875, "words": null}, {"id": 326, "seek": 225452, "start": 2229.0, "end": 2235.12, "text": " a pochi anni fa mancavano gli strumenti hardware ma ora ci sono le risorse in termini di ricerca", "tokens": [50364, 257, 714, 8036, 31164, 2050, 587, 496, 85, 3730, 17161, 1056, 2206, 72, 8837, 463, 33714, 6983, 9259, 476, 2253, 18699, 294, 1433, 3812, 1026, 21040, 36127, 50670], "temperature": 0.0, "avg_logprob": -0.17869318425655364, "compression_ratio": 1.6623376623376624, "no_speech_prob": 0.1729736328125, "words": null}, {"id": 327, "seek": 225452, "start": 2235.12, "end": 2241.2, "text": " quantit\u00e0 di dati addestramento e potenza di calcolo non oso neanche immaginare cosa accadr\u00e0", "tokens": [50670, 4426, 12445, 1026, 1137, 72, 909, 377, 34706, 308, 1847, 23691, 1026, 2104, 46086, 2107, 3003, 78, 408, 22806, 3397, 559, 259, 543, 10163, 1317, 345, 39212, 50974], "temperature": 0.0, "avg_logprob": -0.17869318425655364, "compression_ratio": 1.6623376623376624, "no_speech_prob": 0.1729736328125, "words": null}, {"id": 328, "seek": 225452, "start": 2241.2, "end": 2248.52, "text": " tra dieci anni ma \u00e8 proprio per questo motivo che dobbiamo essere consapevoli questi llm stanno", "tokens": [50974, 944, 978, 537, 31164, 463, 4873, 28203, 680, 10263, 35804, 947, 360, 6692, 7415, 19799, 1014, 41153, 85, 9384, 29729, 4849, 76, 342, 13484, 51340], "temperature": 0.0, "avg_logprob": -0.17869318425655364, "compression_ratio": 1.6623376623376624, "no_speech_prob": 0.1729736328125, "words": null}, {"id": 329, "seek": 225452, "start": 2248.52, "end": 2254.52, "text": " venendo integrati in moltissimi strumenti che utilizziamo anche noi ogni giorno e che utilizzano", "tokens": [51340, 6138, 3999, 3572, 6908, 294, 10739, 891, 10121, 1056, 2206, 72, 947, 40355, 7415, 11585, 22447, 33189, 42202, 308, 947, 40355, 3730, 51640], "temperature": 0.0, "avg_logprob": -0.17869318425655364, "compression_ratio": 1.6623376623376624, "no_speech_prob": 0.1729736328125, "words": null}, {"id": 330, "seek": 228152, "start": 2254.52, "end": 2261.08, "text": " le persone che prendono le decisioni pertanto dobbiamo abituarci tutti ad usarli correttamente", "tokens": [50364, 476, 29944, 947, 9866, 8957, 476, 3537, 72, 13269, 5857, 360, 6692, 7415, 410, 6380, 289, 537, 19822, 614, 14745, 2081, 1181, 14313, 3439, 50692], "temperature": 0.0, "avg_logprob": -0.17159091396765275, "compression_ratio": 1.6905829596412556, "no_speech_prob": 0.1708984375, "words": null}, {"id": 331, "seek": 228152, "start": 2261.08, "end": 2267.68, "text": " il prima possibile \u00e8 questo il momento di porci le domande giuste come utenti di iniziare a", "tokens": [50692, 1930, 19507, 50184, 4873, 10263, 1930, 9333, 1026, 1515, 537, 476, 3285, 11123, 1735, 41389, 808, 2839, 23012, 1026, 294, 24300, 543, 257, 51022], "temperature": 0.0, "avg_logprob": -0.17159091396765275, "compression_ratio": 1.6905829596412556, "no_speech_prob": 0.1708984375, "words": null}, {"id": 332, "seek": 228152, "start": 2267.68, "end": 2274.48, "text": " sviluppare i giusti anticorpi altrimenti ci troveremo catapultati in un mondo che non capiremo", "tokens": [51022, 17342, 388, 10504, 543, 741, 1735, 381, 72, 49172, 18703, 72, 4955, 30591, 72, 6983, 4495, 5887, 3280, 3857, 569, 723, 6908, 294, 517, 40499, 947, 2107, 1410, 621, 3280, 51362], "temperature": 0.0, "avg_logprob": -0.17159091396765275, "compression_ratio": 1.6905829596412556, "no_speech_prob": 0.1708984375, "words": null}, {"id": 333, "seek": 228152, "start": 2274.48, "end": 2281.52, "text": " come funziona e di cui non sappiamo utilizzare correttamente gli oggetti le applicazioni reali", "tokens": [51362, 808, 49345, 21758, 308, 1026, 22929, 2107, 46938, 7415, 40355, 543, 1181, 14313, 3439, 17161, 5360, 847, 7317, 476, 2580, 27569, 957, 72, 51714], "temperature": 0.0, "avg_logprob": -0.17159091396765275, "compression_ratio": 1.6905829596412556, "no_speech_prob": 0.1708984375, "words": null}, {"id": 334, "seek": 230732, "start": 2281.52, "end": 2289.04, "text": " gi\u00e0 si vedono microsoft sta correndo ad integrare gpt nel suo motore di ricerca bing in office 365", "tokens": [50364, 30469, 1511, 14267, 8957, 3123, 7856, 11135, 1181, 46501, 614, 16200, 35559, 290, 662, 15373, 34197, 2184, 418, 1026, 21040, 36127, 272, 278, 294, 3398, 22046, 50740], "temperature": 0.0, "avg_logprob": -0.23408829564348274, "compression_ratio": 1.5767634854771784, "no_speech_prob": 0.12408447265625, "words": null}, {"id": 335, "seek": 230732, "start": 2289.04, "end": 2296.16, "text": " google fa lo stesso con bard in gmail nella sua suite da ufficio e in realt\u00e0 pare anche che i", "tokens": [50740, 20742, 2050, 450, 44413, 416, 7685, 294, 290, 11799, 23878, 8233, 14205, 1120, 344, 3341, 1004, 308, 294, 47512, 7448, 11585, 947, 741, 51096], "temperature": 0.0, "avg_logprob": -0.23408829564348274, "compression_ratio": 1.5767634854771784, "no_speech_prob": 0.12408447265625, "words": null}, {"id": 336, "seek": 230732, "start": 2296.16, "end": 2301.94, "text": " risultati siano molto incoraggianti perch\u00e9 no? noi per\u00f2 dobbiamo evitare di abbandonarci alla", "tokens": [51096, 2253, 723, 6908, 262, 6254, 16394, 7121, 46893, 11520, 14303, 572, 30, 22447, 12673, 360, 6692, 7415, 1073, 270, 543, 1026, 410, 4235, 266, 289, 537, 11591, 51385], "temperature": 0.0, "avg_logprob": -0.23408829564348274, "compression_ratio": 1.5767634854771784, "no_speech_prob": 0.12408447265625, "words": null}, {"id": 337, "seek": 230732, "start": 2301.94, "end": 2307.32, "text": " pigrizia ed accontentarci immediatamente di delegare le nostre decisioni a questi sistemi", "tokens": [51385, 8120, 24959, 654, 308, 67, 1317, 896, 32067, 537, 3640, 25354, 1026, 15824, 543, 476, 10397, 265, 3537, 72, 257, 29729, 10555, 13372, 51654], "temperature": 0.0, "avg_logprob": -0.23408829564348274, "compression_ratio": 1.5767634854771784, "no_speech_prob": 0.12408447265625, "words": null}, {"id": 338, "seek": 233636, "start": 2307.8, "end": 2315.88, "text": " dobbiamo capire e ricordare che chiss\u00e0 quello che sta facendo siamo sempre noi bard o gpt per", "tokens": [50388, 360, 6692, 7415, 1410, 621, 308, 21040, 765, 543, 947, 417, 891, 1467, 22813, 947, 11135, 1915, 3999, 33459, 9553, 22447, 7685, 277, 290, 662, 680, 50792], "temperature": 0.0, "avg_logprob": -0.21612149393447092, "compression_ratio": 1.6724890829694323, "no_speech_prob": 0.00757598876953125, "words": null}, {"id": 339, "seek": 233636, "start": 2315.88, "end": 2322.6000000000004, "text": " quanto possano diventare sofisticati almeno per ora non hanno idea di quello che fanno e per i", "tokens": [50792, 17820, 1402, 3730, 3414, 317, 543, 37259, 3142, 6908, 419, 43232, 680, 33714, 2107, 26595, 1558, 1026, 22813, 947, 283, 13484, 308, 680, 741, 51128], "temperature": 0.0, "avg_logprob": -0.21612149393447092, "compression_ratio": 1.6724890829694323, "no_speech_prob": 0.00757598876953125, "words": null}, {"id": 340, "seek": 233636, "start": 2322.6000000000004, "end": 2329.1200000000003, "text": " fini per i quali sono stati pensati in effetti nemmeno \u00e8 importante che lo capiscano per tutti", "tokens": [51128, 40634, 680, 741, 4101, 72, 9259, 2219, 72, 6099, 6908, 294, 1244, 12495, 408, 2174, 5808, 4873, 9416, 947, 450, 1410, 5606, 3730, 680, 19822, 51454], "temperature": 0.0, "avg_logprob": -0.21612149393447092, "compression_ratio": 1.6724890829694323, "no_speech_prob": 0.00757598876953125, "words": null}, {"id": 341, "seek": 233636, "start": 2329.1200000000003, "end": 2336.36, "text": " questi motivi usarli come base di partenza per qualcosa pu\u00f2 rivelarsi veramente utile in termini", "tokens": [51454, 29729, 5426, 72, 14745, 2081, 808, 3096, 1026, 644, 23691, 680, 42400, 26526, 367, 36504, 32742, 50079, 2839, 794, 294, 1433, 3812, 51816], "temperature": 0.0, "avg_logprob": -0.21612149393447092, "compression_ratio": 1.6724890829694323, "no_speech_prob": 0.00757598876953125, "words": null}, {"id": 342, "seek": 236184, "start": 2336.4, "end": 2343.1200000000003, "text": " di produttivit\u00e0 di comodit\u00e0 eccetera ma prendere per buone le loro creazioni senza", "tokens": [50366, 1026, 15792, 13478, 592, 12445, 1026, 395, 378, 12445, 29613, 20269, 463, 9866, 323, 680, 758, 546, 476, 28810, 1197, 27569, 36208, 50702], "temperature": 0.0, "avg_logprob": -0.2439236127667957, "compression_ratio": 1.401197604790419, "no_speech_prob": 0.0297393798828125, "words": null}, {"id": 343, "seek": 236184, "start": 2343.1200000000003, "end": 2349.76, "text": " valutarle prima attentamente beh questo potrebbe rivelarsi una follia", "tokens": [50702, 1323, 32142, 306, 19507, 30980, 3439, 1540, 10263, 1847, 39487, 367, 488, 2200, 7691, 2002, 25483, 654, 51034], "temperature": 0.0, "avg_logprob": -0.2439236127667957, "compression_ratio": 1.401197604790419, "no_speech_prob": 0.0297393798828125, "words": null}, {"id": 344, "seek": 236184, "start": 2349.76, "end": 2361.84, "text": " bene anche oggi l'episodio \u00e8 giunto al termine io non ho pi\u00f9 voce ma spero di", "tokens": [51034, 2537, 11585, 34768, 287, 6, 595, 271, 378, 1004, 4873, 1735, 24052, 419, 1433, 533, 19785, 2107, 1106, 10589, 1650, 384, 463, 24152, 78, 1026, 51638], "temperature": 0.0, "avg_logprob": -0.2439236127667957, "compression_ratio": 1.401197604790419, "no_speech_prob": 0.0297393798828125, "words": null}, {"id": 345, "seek": 238600, "start": 2361.84, "end": 2367.32, "text": " averti portato come al solito un contenuto interessante e spero anche di averlo spiegato", "tokens": [50364, 1305, 911, 72, 2436, 2513, 808, 419, 1404, 3528, 517, 21795, 8262, 24372, 308, 24152, 78, 11585, 1026, 18247, 752, 637, 20408, 2513, 50638], "temperature": 0.0, "avg_logprob": -0.1822916626393258, "compression_ratio": 1.6289592760180995, "no_speech_prob": 0.1844482421875, "words": null}, {"id": 346, "seek": 238600, "start": 2367.32, "end": 2373.7200000000003, "text": " in maniera sufficientemente chiara perch\u00e9 l'argomento \u00e8 bel lungi dall'essere semplice", "tokens": [50638, 294, 587, 10609, 11563, 16288, 13228, 2419, 14303, 287, 6, 289, 30851, 15467, 4873, 989, 16730, 72, 43351, 6, 442, 323, 4361, 564, 573, 50958], "temperature": 0.0, "avg_logprob": -0.1822916626393258, "compression_ratio": 1.6289592760180995, "no_speech_prob": 0.1844482421875, "words": null}, {"id": 347, "seek": 238600, "start": 2373.7200000000003, "end": 2380.04, "text": " prima di chiudere come ormai di consuetudine ringrazio edoardo e carlo per la loro donazione", "tokens": [50958, 19507, 1026, 13228, 532, 323, 808, 420, 76, 1301, 1026, 1014, 15382, 532, 533, 4875, 30695, 1004, 1257, 78, 12850, 308, 1032, 752, 680, 635, 28810, 500, 12928, 51274], "temperature": 0.0, "avg_logprob": -0.1822916626393258, "compression_ratio": 1.6289592760180995, "no_speech_prob": 0.1844482421875, "words": null}, {"id": 348, "seek": 238600, "start": 2380.04, "end": 2386.0, "text": " mensile e se anche tu apprezzi quello che faccio ti invito a fare come loro e dimostrarlo", "tokens": [51274, 10923, 794, 308, 369, 11585, 2604, 724, 265, 4313, 72, 22813, 947, 1915, 8529, 8757, 1048, 3528, 257, 11994, 808, 28810, 308, 5013, 555, 5352, 752, 51572], "temperature": 0.0, "avg_logprob": -0.1822916626393258, "compression_ratio": 1.6289592760180995, "no_speech_prob": 0.1844482421875, "words": null}, {"id": 349, "seek": 241104, "start": 2386.0, "end": 2392.48, "text": " concretamente ricorda nessuna cifra \u00e8 troppo bassa e puoi star certo che verr\u00e0 utilizzata", "tokens": [50364, 39481, 3439, 21040, 765, 64, 39787, 5051, 269, 351, 424, 4873, 4495, 27000, 10136, 64, 308, 2362, 4869, 3543, 22261, 947, 1306, 39212, 40355, 3274, 50688], "temperature": 0.0, "avg_logprob": -0.18877840570428156, "compression_ratio": 1.6331877729257642, "no_speech_prob": 0.387939453125, "words": null}, {"id": 350, "seek": 241104, "start": 2392.48, "end": 2398.68, "text": " per migliorare questo progetto la verit\u00e0 \u00e8 che io ho tante idee ma ho anche capito che non", "tokens": [50688, 680, 6186, 75, 1973, 543, 10263, 447, 847, 1353, 635, 1306, 12445, 4873, 947, 19785, 1106, 256, 2879, 49742, 463, 1106, 11585, 1410, 3528, 947, 2107, 50998], "temperature": 0.0, "avg_logprob": -0.18877840570428156, "compression_ratio": 1.6331877729257642, "no_speech_prob": 0.387939453125, "words": null}, {"id": 351, "seek": 241104, "start": 2398.68, "end": 2403.8, "text": " posso fare tutto da solo ti anticipo gi\u00e0 che il primo obiettivo a cui sto lavorando \u00e8 quello", "tokens": [50998, 22501, 11994, 23048, 1120, 6944, 8757, 10416, 78, 30469, 947, 1930, 38671, 1111, 1684, 83, 6340, 257, 22929, 22784, 29241, 1806, 4873, 22813, 51254], "temperature": 0.0, "avg_logprob": -0.18877840570428156, "compression_ratio": 1.6331877729257642, "no_speech_prob": 0.387939453125, "words": null}, {"id": 352, "seek": 241104, "start": 2403.8, "end": 2411.04, "text": " di eliminare la pubblicit\u00e0 per rimuovere il tracciamento la profilazione ma un po di supporto", "tokens": [51254, 1026, 7892, 543, 635, 1535, 11489, 12445, 680, 15982, 84, 5179, 323, 1930, 504, 43870, 8824, 635, 1740, 388, 12928, 463, 517, 714, 1026, 1406, 78, 51616], "temperature": 0.0, "avg_logprob": -0.18877840570428156, "compression_ratio": 1.6331877729257642, "no_speech_prob": 0.387939453125, "words": null}, {"id": 353, "seek": 243836, "start": 2411.04, "end": 2418.4, "text": " \u00e8 indispensabile sul sito pensieriincodice.it trovi tutti i link utili per donazioni affiliazioni", "tokens": [50364, 4873, 42937, 33288, 17603, 1394, 78, 6099, 45980, 4647, 378, 573, 13, 270, 4495, 4917, 19822, 741, 2113, 2839, 2312, 680, 500, 27569, 2096, 24169, 89, 15273, 50732], "temperature": 0.0, "avg_logprob": -0.1930397708307613, "compression_ratio": 1.6406926406926408, "no_speech_prob": 0.28076171875, "words": null}, {"id": 354, "seek": 243836, "start": 2418.4, "end": 2425.2799999999997, "text": " gruppo e canale telegram eccetera a proposito di telegram l'ingresso nel gruppo \u00e8 impostato su", "tokens": [50732, 47477, 78, 308, 393, 1220, 4304, 1342, 29613, 20269, 257, 7532, 3528, 1026, 4304, 1342, 287, 6, 278, 29652, 15373, 47477, 78, 4873, 47804, 2513, 459, 51076], "temperature": 0.0, "avg_logprob": -0.1930397708307613, "compression_ratio": 1.6406926406926408, "no_speech_prob": 0.28076171875, "words": null}, {"id": 355, "seek": 243836, "start": 2425.2799999999997, "end": 2432.48, "text": " autorizzazione perch\u00e9 purtroppo su telegram c'\u00e8 un serio problema di bot ti consiglio quindi di", "tokens": [51076, 19510, 8072, 12928, 14303, 1864, 38604, 27000, 459, 4304, 1342, 269, 6, 1462, 517, 49531, 12395, 1026, 10592, 8757, 40233, 19987, 15727, 1026, 51436], "temperature": 0.0, "avg_logprob": -0.1930397708307613, "compression_ratio": 1.6406926406926408, "no_speech_prob": 0.28076171875, "words": null}, {"id": 356, "seek": 243836, "start": 2432.48, "end": 2438.36, "text": " scrivermi se vuoi entrare per velocizzare le procedure di verifica mi trovi facilmente", "tokens": [51436, 5545, 331, 3057, 369, 9732, 4869, 22284, 265, 680, 1241, 752, 537, 4313, 543, 476, 10747, 1026, 1306, 43377, 2752, 4495, 4917, 10217, 4082, 51730], "temperature": 0.0, "avg_logprob": -0.1930397708307613, "compression_ratio": 1.6406926406926408, "no_speech_prob": 0.28076171875, "words": null}, {"id": 357, "seek": 246476, "start": 2438.6800000000003, "end": 2444.84, "text": " cercando chiocciola valerio galano direttamente nella casella di ricerca telegram infine non", "tokens": [50380, 36099, 1806, 13228, 905, 537, 4711, 1323, 260, 1004, 7660, 3730, 1264, 6319, 3439, 23878, 1389, 3505, 1026, 21040, 36127, 4304, 1342, 1536, 533, 2107, 50688], "temperature": 0.0, "avg_logprob": -0.16777012358277532, "compression_ratio": 1.6784140969162995, "no_speech_prob": 0.2471923828125, "words": null}, {"id": 358, "seek": 246476, "start": 2444.84, "end": 2452.0, "text": " dimenticare di condividere l'episodio con amici parenti gruppi eccetera come al solito far crescere", "tokens": [50688, 274, 2328, 299, 543, 1026, 2224, 1843, 323, 287, 6, 595, 271, 378, 1004, 416, 669, 8787, 2596, 72, 47477, 72, 29613, 20269, 808, 419, 1404, 3528, 1400, 20964, 15312, 51046], "temperature": 0.0, "avg_logprob": -0.16777012358277532, "compression_ratio": 1.6784140969162995, "no_speech_prob": 0.2471923828125, "words": null}, {"id": 359, "seek": 246476, "start": 2452.0, "end": 2458.28, "text": " gli ascoltatori \u00e8 sempre l'obiettivo primario e a te non costa nulla grazie dunque per aver", "tokens": [51046, 17161, 15526, 4837, 39842, 4873, 9553, 287, 6, 996, 1684, 83, 6340, 2886, 4912, 308, 257, 535, 2107, 2063, 64, 18184, 64, 1295, 3283, 10234, 1077, 680, 18247, 51360], "temperature": 0.0, "avg_logprob": -0.16777012358277532, "compression_ratio": 1.6784140969162995, "no_speech_prob": 0.2471923828125, "words": null}, {"id": 360, "seek": 246476, "start": 2458.28, "end": 2464.76, "text": " ascoltato fin qui grazie alla mia voce per aver retto fino alla fine ci sentiamo ad un prossimo", "tokens": [51360, 15526, 4837, 2513, 962, 1956, 1295, 3283, 11591, 21290, 1650, 384, 680, 18247, 1533, 1353, 42560, 11591, 2489, 6983, 2279, 7415, 614, 517, 48794, 6934, 51684], "temperature": 0.0, "avg_logprob": -0.16777012358277532, "compression_ratio": 1.6784140969162995, "no_speech_prob": 0.2471923828125, "words": null}, {"id": 361, "seek": 248300, "start": 2464.76, "end": 2471.28, "text": " episodio e non dimenticare mai che un informatico risolve problemi a volte anche usando il computer", "tokens": [50364, 39200, 1004, 308, 2107, 274, 2328, 299, 543, 12698, 947, 517, 1356, 2399, 78, 2253, 37361, 1154, 72, 257, 37801, 11585, 29798, 1930, 3820, 50690], "temperature": 0.0, "avg_logprob": -0.20688657407407407, "compression_ratio": 1.2375, "no_speech_prob": 0.055755615234375, "words": null}], "language": "Italian"}