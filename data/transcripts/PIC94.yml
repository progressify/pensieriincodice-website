text: "

Non fu facile. La mano di Hermione era talmente serrata attorno a quel bigliettino che a un certo punto Harry temette di strapparlo. Mentre Ron montava la guardia Harry tirò e spinse finché, dopo parecchi minuti di tensione, riuscì a estrado.

Era una pagina strappata da un vecchio volume della biblioteca. Eccitato, Harry la lisciò e Ron si avvicinò per leggere a sua volta.

Dei molti, spaventosi animali e mostri che popolano la nostra terra, nessuno è più insolito e micidiale del Basilisco, noto anche come il Re dei Serpenti. Questo serpente, che può raggiungere dimensioni gigantesche e che vive molte centinaia di anni, nasce da un uovo di gallina covato da un rospo. Esso uccide in modo portentoso: oltre alle zanne, che contengono un potente veleno, anche lo sguardo del Basilisco provoca morte istantanea. I ragni fuggono davanti al Basilisco, perché è il loro nemico mortale e il Basilisco fugge solo quando ode il canto del gallo, che gli è fatale.

*La Camera dei Segreti (Cap. 16 Harry Potter 2)*

Sigla

Bentornato o bentornata su Pensieri in codice. Avevo ragione o no un paio di episodi fa a dirti che Rosanna Lia è bravissima?

Prima di iniziare, quindi colgo l'occasione per ringraziare le sia per aver acconsentito a prestare la sua voce per l'introduzione, e per ricordare a te di visitare il suo canale YT. Ovviamente ti lascio il link in descrizione e mi raccomando vai a darci un'occhiata, troverai tantissime letture di romanzi e racconti che ti terranno compagnia per ore.

### Il Basilisco

Tornando invece all'argomento di oggi, nel brano letto da Rosanna e tratto dal libro Harry Potter e la Camera dei Segreti, si parla di una creatura mitologica chiamata Basilisco, parola che significa piccolo re e che pare abbia capacità velenose letali.

Ma in effetti, a seconda della cultura, della società o della tradizione a cui si fa riferimento, questo essere assume connotati e caratteristiche differenti, arrivando a possedere uno sguardo in grado di fulminare chi lo incrocia, come riportato nel Dizionario Enciclopedico di Esoterismo di Roberto Tresoldi.

Ovviamente, una creatura del genere, che secondo la leggenda nascerebbe dall'unione di un rospo e di un gallo, non esiste realmente, ma ciò non le ha impedito di entrare a far parte di racconti di Plinio il Vecchio, nella Bibbia, nei Canterbury Tales di Goeffry Chaucer e, più di recente, nella cultura nostra pop fatta di libri, film, videogiochi e simili. Il brano di Harry Potter ne è solo un esempio.

### Un simbolo anche in campo informatico

Ma è proprio questa sua fama, che ha portato il Basilisco ad essere anche il soggetto della singolare teoria informatico-filosofica, da molti considerata una legenda metropolitana, di cui ti voglio parlare in questo episodio. Un esperimento mentale che ha suscitato, al momento della sua prima enunciazione, e suscita ancora oggi ammirazione da un lato e preoccupazione dall'altro, all'interno della comunità tecnoutopista.

Il Basilisco di Roko è, in due parole, una futura superintelligenza che, al fine di perseguire la propria creazione nel più breve tempo possibile, promette tuttora la peggior punizione concepibile a chi oggi non vi contribuisce in maniera attiva.

Il nome di Basilisco è stato scelto ovviamente per l'estrema pericolosità e letalità di questa entità: infatti il suo aspetto più inquietante è che il solo fatto di conoscere il concetto di questo Basilisco espone automaticamente la persona ad una futura punizione, nel caso in cui questa non *scelga* di prodigarsi al massimo per la venuta della superintelligenza.

Quindi prego. Sono sicuro che in questo momento sarai felice che io stia condividendo con te queste informazioni.

### Il post su LessWrong e le prime reazioni

La prima formulazione del Basilisco di Roko risale al 2010, quando un utente che si firmava appunto con lo pseudonimo di Roko, lo descrisse sul sito LessWrong, il blog di riferimento di una community che si impegna tutt'oggi a discutere di argomenti legati al ruolo del progresso tecnologico nel benessere della società.

A prima vista, l'idea di questa entità, potrebbe sembrare un gran bel soggetto per un racconto di fantascenza, ma all'epoca suscitò reazioni allarmate, quasi di panico.

Eliezer Yudkowsky (spero sperando che si pronunci in questo modo), amministratore e fondatore del sito, prima rispose in modo piuttosto aggressivo dando non troppo velatamente dell'idiota a Roko e poi, a seguito di qualche scambio, cancellò il post.

La prima risposta di Yudkowsky, riportata successivamente dal sito slate.com, dimostrava una reale preoccupazione, quasi il terrore, per il fatto stesso che l'utente avesse scritto di una tal possibile superintelligenza.

In tono piuttosto offensivo, l'amministratore sottolineava l'accusa verso Roko di essere sufficientemente intelligente da formulare un'idea del genere, ma non abbastanza da tenere la bocca chiusa, condannando chi avrebbe letto il suo post, semplicemente per un suo bisogno di *sembrare intelligente*, quando in realtà diffondere quell'idea era da stupidi.

### Sembra un'esagerazione ma dobbiamo calarci nel mondo in cui è stato concepito

Ora, si trattò di una reazione esagerata, chiaramente dettata dal panico. Tanto è vero che lo stesso Yudkowsky successivamente ritrattò in parte le sue parole e le sue convinzioni, ma la leggenda del Basilisco di Roko, ormai era nata e per capire perché abbia fatto e faccia tutt'oggi tanta paura ad alcuni, dobbiamo provare a calarci nel contesto e nell'ambiente nei quali questa figura è stata concepita.

### Cos'è LessWrong e chi è Eliezer Yudkowsky (la singolarità)

Innanzitutto, Yudkowsky che di fatto è la figura centrale del sito LessWrong e della sua comunità, nasce professionalmente come ricercatore nel campo dell'intelligenza artificiale già famoso nel 2005 negli ambienti di Palo Alto in mezzo a figure oggi ben più note alle cronache come Elon Musk o Mark Zuckemberg.

Il suo interesse principale, però, già ai tempi riguardava uno specifico aspetto del campo dell'IA, cioè una teoria conosciuta con il nome di Singolarità tecnologica.

Secondo questa teoria, esisterà un momento della storia in cui comparirà una superintelligenza (ovviamente stando a quanto vediamo accadere in questi anni, sarà molto probabilmente una potente intelligenza artificiale generalista) talmente avanzata da accelerare a tal punto il progresso tecnologico da sottrarlo alla comprensione dell'umana.

Una teoria del genere sembra qualcosa di molto recente, da romanzo fantascientifico o film hollywoodiano, ma in realtà vede la propria nascità nel 1958 come concetto espresso durante una discussione tra il fisico polacco Stanislaw Ulam e l'informatico John Von Neumann.

In vista di questo momento, che crede fermamente di poter un giorno vedere con i propri occhi, Yudkowsky ha prima fondato un istituto con lo scopo di contribuire attivamente a fare in modo che questa singolarità si manifesti come qualcosa di positivo per la razza umana, e poi ha anche creato il sito LessWrong che è ovviamente divenuto un punto di riferimento e discussione per tecnofuturologi, tecnocrati e altre figure interessate a questi argomenti.

### Timeless decision theory (TDT)

Per capire, però, da dove scaturisca la convinzione che questa superintelligenza possa realmente manifestarsi un giorno con le caratteristiche del Basilisco di Roko  e possa effettivamente comportarsi nel terribile modo descritto dal suo creatore, dobbiamo provare ad affrontare alcune delle teorie principali del mondo e del pensiero tecnoutopista ed in particolare di quelle care allo stesso Yudkowsky.

Tutt'altro che banali, queste argomenti sono un misto di argomentazioni filosofiche, etiche, teoria dei giochi, statistica beyesiana (di cui, ti ricordo, abbiamo già parlato nell'episodio sulle auto autonome), fisica quantistica e multiverso. 

Insomma si tratta di qualcosa di piuttosto complicato e non potendo certamente affrontare tutto ciò in modo approfondito, primo perché non ne avrei le competenze, poi perché immagino ti annoieresti a morte, come al solito provo a semplificare il più possibile cercando sempre di non scadere nella banalizzazione.

Cominciamo, quindi, da quella che è chiamata teoria TDT, cioè la Timeless decision theory. Attenzione, non traduco il nome apposta in italiano perché, almeno per come l'ho capita io, la traduzione non mi sembra rendere correttamente il concetto. Poi se mi sbaglio e ne sai più di me, sentiti libero di farmelo sapere. I miei contatti sono sul sito pensieriincodice.it

La TDT è una teoria delle decisioni, appunto, sviluppata dallo stesso Yudkowsky, che afferma che gli agenti che prendono decisioni, dovrebbero farlo tenendo conto che queste  determinano esse stesse il contesto nelle quali vengono messe in pratica.

So che sembra complicato e in effetti lo è, ti avevo avvisato, ma per per fare un esempio: è un po' come se avessi sempre a che fare con un potente avversario sensitivo: nel momento stesso in cui prendessi la decisione di fare una mossa di qualche tipo, lui lo saprebbe e certamente prenderebbe le dovuto contromisure. La tua scelta, quindi, determinerebbe il contesto nel quale l'andresti ad implementare.

E attenzione, questo non è un esempio precisissimo ma serve per capire il concetto in vista di qualche ragionamento un po' più complicato che faremo a breve.

La TDT, inoltre, è fondamentalmente una teoria che ha l'obiettivo di costruire un sistema di decisioni delle quali non ci si debba mai pentire in futuro, ma addirittura anche nel passato. Purtroppo questo aspetto non lo riusciamo ad approfondire, ma mi sembrava interessante almeno citarlo.

Questa teoria è stata sviluppata come risposta ad altre teoria come la teoria delle decisioni classica o la teoria delle decisioni casuali, le quali, in alcuni scenari, non sembrano adatte per selezionare la scelta vincente. Di conseguenza, nella teoria dei giochi, sembra esserci spazio per una ulteriore teoria decisionale di maggior successo e Yudkowsky, insieme a molti altri, prova proprio a riempire questo vuoto con la sua TDT.

### Paradosso di Newcomb

In fin dei conti, questa teoria della timeless decision nasce per dare soluzione per un singolare paradosso conosciuto come Paradosso di Newcomb. Di cui la seguente, è una delle tante formulazioni.

Supponi di avere a che fare con una superintelligenza.

Questa ti mette mostra due scatole.

Nella prima, che è perfettamente trasparente, vedi chiaramente che sono conservati 1000 euro.

Nella seconda, che invece è completamente nera, ti viene detto che ci può essere 1milione di euro oppure assolutamente niente.

A te vengono date due scelte: puoi prendere e portarti via entrambe le scatole, oppure solo quella dal contenuto sconosciuto.

Ma la superintelligenza, ti dice anche che se sceglierai entrambe le scatole, la nera sarà vuota. Mentre se sceglierai SOLO la nera, questa conterrà il milione.

A questo punto, sia intuitivamente che secondo la teoria classica delle decisioni, la scelta migliore è in ogni caso quella di prendere entrambe le scatole. D'altronde queste sono lì davanti a te, il contenuto è già all'interno: il milione di euro o c'è o non c'è. Tanto vale assicurarsi i mille euro e poi tornare a casa e scoprire cosa c'è nella scatola nera.

Ma è proprio a questo punto che interviene la teoria della timeless decision.

La superintelligenza è per definizione infallibile, e questo anche nel predire il comportamento umano. Se scegliessi di prendere entrambe le scatole, lei l'avrebbe già saputo prima di inserirvi il contenuto e, di conseguenza avrebbe lasciato la scatola nera vuota.

Lo so. Di nuovo. E' complicato. Può servire un attimo per rifletterci.

La TDT quindi non solo sostiene che sia preferibile lasciare i mille euro e scommettere sulla scatola misteriosa, perché sapendolo in anticipo la superintelligenza ci avrà messo il milione, ma motiva tale scelta proprio affermando che sia la decisione in se ad influenzare la realtà in cui poi verrà attuata.

Addirittura, in altre formulazioni più fantasiose, si concretizza maggiormente il ragionamento supponendo che la scatola nera sia truccata o che il soggetto si trovi in una simulazione, quindi la realtà che lo circonda potrebbe essere effettivamente attivamente modificata dalla superintelligenza.

In ogni caso, comunque, il Basilisco di Roko, non è altro che una variante di questo esperimento mentale.

La differenza è che la scelta delle scatole, diventa la scelta tra adoperarsi senza sosta per la venuta del basilisco, oppure ignorare tale avvento o addirittura ostacolarlo.

Mentre i premi diventano vivere in un mondo sempre più avanzato spinto dalla superintelligenza oppure una punizione esemplare.

Alla sua venuta, infatti, il Basilisco premierà chi ha contribuito alla sua creazione (e questo semplicemente con la sua ragion d'essere cioè il miglioramento del benessere nel mondo) e punirà chi, pur conoscendone la futura esistenza, non ha dedicato ogni possibile sforzo ad accelerarla.

E' questo il motivo per cui questa entità fa tanta paura.

### Utilitarismo

Ovviamente, nel mondo dei tecnoutopisti, un ruolo di spicco è ricoperto dalla dottrina dell'utilitarismo. Una filosofia secondo la quale il bene corrisponde all'utile.

Ciò che è buono è anche utile, cioè produce il massimo grado di felicità per il maggior numero di persone, dove per felicità si intende essenzialmente presenza di piacere e assenza di dolore.

In un contesto filosofico del genere, è chiaro che il Basilisco identificherebbe se stesso come qualcosa di positivo per tutto il genere umano. In quanto superintelligenza, infatti, esso  causerebbe l'accelerazione immediata del sapere tecnologico oltre qualsiasi possibile conoscenza umana e questo porterebbe ad un enorme e continuo miglioramento del benessere e della felicità.

Pertanto, sempre secondo i sostenitori della teoria, il Basilisco considererebbe ogni giorno, anzi ogni istante precedente alla sua venuta come motivo di sofferenza evitabile dovuta appunto al ritardo della massimizzazione della felicità possibile.

Rifacendoci sempre ai concetti della timeless decision, quindi, il cerchio si chiude sostenendo che il Basilisco stesso sia intenzionato a scoraggiare chiunque non si adoperi al massimo per la sua venuta, promettendo la più terribile delle punizioni future.

### Reazioni nella comunità

Capisco che tutta questa storia ti possa sembrare un po' fantascientifica, in realtà sarei anche d'accordo. Ma dobbiamo sempre ricordare che le persone sono diverse, sono cresciute in contesti diversi, ragionano e sono convinte di cose diverse.

Nella comunità di LessWrong, te lo accennavo già prima, la formulazione dell'idea del Basilisco ha avuto effetti devastanti. A parte le reazioni degli amministratori di cui abbiamo già parlato, pare anche di ci siano stati casi insonnia, incubi notturni, esaurimenti nervosi.

Tutt'oggi, cercando informazioni online, ho trovato post di utenti che, ad esempio, *chiedevano di alleviare le proprie preoccupazioni riguardo al Basilisco* o *di essere rassicurati* o addirittura che cercano metodi su come cancellare le tracce della propria conoscenza dell'idea stessa di Basilisco.

E poi ricordiamoci sempre che ci sono persone che credono che la terra sia piatta, voglio dire, il Basilisco di Roko mi sembra molto più realistica come convinzione.

### Avvertimento

Per quanto detto finora, comunque, dovrebbe essere ormai chiaro che il solo ipotizzare il concetto del Basilisco abbia in effetti contribuito ad avvicinarne la venuta.

Lo stesso Yudkowsky lo ha paragonato più volte ad una sorta di Sapere Proibito. Come nei racconti di Lovecraft, dove la conoscenza dei misteri più profondi e ignoti, diventa motivo di pazzia o distruzione per i protagonisti, conoscere il Basilisco equivale ad una condanna.

Quindi sappi che ora che anche tu sai di questa creatura, non potrai fare altro che prodigarti per la sua venuta!

Bene, l'episodio di oggi, dunque, termina qui. Spero come al solito di averti portato qualche informazione e riflessione interessante.

Se vuoi metterti ancora più nei guai, in descrizione ti lascio un po' di link sul Basilisco, oltre ovviamente, come sempre, ai link dei libri citati, nonché il canale Yuoutube di Rosanna Lia che ringrazio ancora.

Ti ricordo che se posso produrre questi contenuti, è solo grazie a te che ascolti ed alla community di pensieri in codice che sostiene il progetto. Scopri come dare una mano anche tu, sul sito pensieriincodice.it (mi raccomando con 2 i).

Puoi ascoltare tutti gli episodi sulle maggiori piattaforme e app di podcast o riceverli direttamente sullo smartphone iscrivendoti al canale Telegram che trovi sempre sul sito.

Se Pensieri in codice ti piace, e se sei arrivato fin qui immagino ti piaccia, potresti sostenerlo anche lasciando una recensione nell'app con cui ascolti il podcast e potresti poi condividerlo con un amico per farglielo conoscere. Così facendo mi aiuterai a far crescere il progetto, a migliorarne la qualità, e farai scoprire a lui un qualcosa di interessante.

In somma, ne guadagneremmo tutti!

Per oggi, dunque, è proprio tutto, io ti ringrazio per aver ascoltato fin qui, ti do appuntamento al prossimo episodio e ti ricordo che *un informatico risolve problemi, a volte anche usando il computer*.
"